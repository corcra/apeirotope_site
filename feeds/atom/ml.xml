<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>apeirotope - ml</title><link href="/" rel="alternate"></link><link href="feeds/atom/ml.xml" rel="self"></link><id>/</id><updated>2018-06-03T00:00:00+01:00</updated><entry><title>yes, but did it work? evaluating variational inference</title><link href="ml/2018-06-03-yes-but-did-it-work-vi.html" rel="alternate"></link><published>2018-06-03T00:00:00+01:00</published><updated>2018-06-03T00:00:00+01:00</updated><author><name>corcra</name></author><id>tag:None,2018-06-03:ml/2018-06-03-yes-but-did-it-work-vi.html</id><summary type="html">&lt;p&gt;This post is about the paper &lt;a href="https://arxiv.org/abs/1802.02538"&gt;Yes, but Did It Work?: Evaluating Variational Inference&lt;/a&gt; by &lt;em&gt;Yuling Yao, Aki Vehtari, Daniel Simpson, Andrew Gelman&lt;/em&gt;, which will appear at ICML 2018. I'm going to try to summarise/explain the paper in my own words, largely for my own benefit. I'm also going …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This post is about the paper &lt;a href="https://arxiv.org/abs/1802.02538"&gt;Yes, but Did It Work?: Evaluating Variational Inference&lt;/a&gt; by &lt;em&gt;Yuling Yao, Aki Vehtari, Daniel Simpson, Andrew Gelman&lt;/em&gt;, which will appear at ICML 2018. I'm going to try to summarise/explain the paper in my own words, largely for my own benefit. I'm also going to do this without writing any mathematical formulae, because I don't remember how to do LaTeX with my website, and I don't feel like shaving that particular yak right now.&lt;/p&gt;
&lt;p&gt;After the accepted ICML papers were announced, I went through it hunting for relevant work. I've decided it's a better use of my time to read papers that have been accepted somewhere, rather than drowning under the firehouse of my arXiv RSS feed. This paper ticked two boxes: variational inference, and knowing if it worked. It also ticked a third, secret box of "titles that make it sound like the paper will have been written in a casual, conversational style, eschewing the tradition of appearing smarter by obfuscating the point".&lt;/p&gt;
&lt;p&gt;Single-line summary: &lt;strong&gt;they describe two diagnostics for evaluating the variational posterior, with different properties and use-cases&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;So let's talk about these two diagnostics.&lt;/p&gt;
&lt;h3&gt;Pareto Smoothed Importance Sampling (PSIS)&lt;/h3&gt;
&lt;p&gt;At this point I realised the auther overlap between this paper and &lt;a href="https://arxiv.org/abs/1507.04544"&gt;Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC&lt;/a&gt;, which in turn builds on &lt;a href="https://arxiv.org/abs/1507.02646"&gt;Pareto Smoothed Importance Sampling&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So what is PSIS and how is it useful for evaluating VI?&lt;/p&gt;
&lt;p&gt;Importance sampling is a technique which enables us to estimate expectations under a distribution which is difficult to sample from (the target distribution), using an approximating &lt;em&gt;proposal distribution&lt;/em&gt;. You sample from your proposal distribution (which is easy to sample from), then &lt;em&gt;weight&lt;/em&gt; those samples by the ratio of target distribution to the proposal distribution (evaluated at the sample point). These weights are called importance ratios.&lt;/p&gt;
&lt;p&gt;Pareto smoothing comes in because in the event that the proposal distribution is a poor fit to the target distribution, these weights can have a very high variance. The proposal distribution is the denominator in the importance ratio, so if you imagine that this distribution is a lot thinner than the target distribution - that is, it's near zero in regions where the target distribution is not, you can end up with some very large importance ratios - high variance. This means that you would need a &lt;em&gt;lot&lt;/em&gt; of samples to estimate the expectation value of interest. Pareto smoothing is a way to control this variance. It builds on the idea of simply truncating the importance ratios (&lt;a href="https://experts.umich.edu/en/publications/truncated-importance-sampling"&gt;Truncated Importance Sampling, Ionides 2008&lt;/a&gt;) by instead fitting a Pareto distribution to them.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Side note: Part of the motivation of using the Pareto distribution at this point, I think, is to use its fitted parameters to do&lt;/em&gt; diagnostics &lt;em&gt;on the proposal distribution. This is exactly what "Yes, But Did It Work?" is doing, but they already talk about it in the original PSIS paper, so I guess part of the novelty of this ICML paper is bringing it explicitly to the VI area. More about VI when I'm done with this Pareto stuff.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;So how does fitting a Pareto distribution to the importance ratios help? In practice, you fit the Pareto distribution, and then instead of simply &lt;em&gt;truncating&lt;/em&gt; the top M importance ratios (M is chosen empirically/arbitrarily) you &lt;em&gt;replace&lt;/em&gt; them using the inverse cumulative density function of the Pareto distribution you fit. This replacement operates on the ranks of these importance ratios (so the smallest of the M, the second-smallest and so on), replacing those with what you'd get in a Pareto distribution ranked by CDF. This reminds me of rank-based inverse-normal transformations I've seen used in genetics (weirdly difficult to find papers about this, &lt;a href="https://cran.r-project.org/web/packages/RNOmni/vignettes/RNOmni.html"&gt;here&lt;/a&gt; is an R vignette). They argue that this produces an IS estimate that is less biased than what you get using truncated IS. Moreover, you can inspect the parameters of the fitted Pareto distribution to do diagnostics.&lt;/p&gt;
&lt;p&gt;The reason they use a &lt;em&gt;Pareto&lt;/em&gt; distribution to model the top M importance ratios is because It Is Known. Rather, it is shown in &lt;a href="https://projecteuclid.org/download/pdf_1/euclid.aos/1176343003"&gt;Pickands, 1975&lt;/a&gt; to be an appropriate choice. To be specific, they use a &lt;em&gt;generalised&lt;/em&gt; Pareto distribution. This distribution has three parameters (location, scale, shape), and it has the property that it has finite moments up to order 1/k, where k is the shape parameter. That means that if k &amp;gt; 0.5, the variance of the importance ratios is infinite, but if k &amp;lt; 1 at least the mean exists. They point to 0.5 &amp;lt; k &amp;lt; 0.7 as a regime where the importance sampling procedure exhibits a practicaly useful convergence rate.
Side note: I don't quite see where the jump from modelling the variance of the &lt;em&gt;tail&lt;/em&gt; of the importance ratios to modelling &lt;em&gt;all&lt;/em&gt; the importance ratios happened. I suppose if you observe that your tail has a finite variance, then you must have finite variance in the rest of the values, but I would have expected an additional step to extend the conclusions made about the fit of the Pareto distribution to the rest of the importance ratios.&lt;/p&gt;
&lt;p&gt;Now, relating this back to variational inference is straight forward: replace "target distribution" with "variational posterior". PSIS, via the shape parameter of the fitted Pareto distribution, gives us a diagnostic for how well the variational posterior fits with the true posterior.&lt;/p&gt;
&lt;p&gt;But wait... don't we need the true posterior to calculate the importance ratios? Isn't this circular? The answer is that you can use the &lt;em&gt;joint&lt;/em&gt; distribution (p(z, x) rather than p(z|x)) because the estimate of k is invariant to a constant multiplicative factor, which will be p(x).&lt;/p&gt;
&lt;p&gt;The diagnostic approach is thus:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Run VI, get variational distribution q(z) approximating p(z|x).&lt;/li&gt;
&lt;li&gt;Sample a bunch of zs from q(z)&lt;/li&gt;
&lt;li&gt;Calculate p(z, x) for all the zs (remember, x is known - it is a specific dataset), and get the importance ratios p(z, x)/q(z)&lt;/li&gt;
&lt;li&gt;Fit a generalised Pareto distribution to the largest M importance ratios&lt;/li&gt;
&lt;li&gt;Report the (estimated) shape parameter k&lt;/li&gt;
&lt;li&gt;If k &amp;gt; 0.7, the VI approximation is not reliable&lt;/li&gt;
&lt;li&gt;If k &amp;lt; 0.5, the VI approximation is good, and PSIS can additionally be used to calculate further divergence measures&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;They touch on two other points in this paper, regarding PSIS:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The shape parameter k is invariant under reparametrisation, but reparametrisation can influence the VI procedure and produce better/worse proposal distributions. So looking at k can help guide reparametrisation efforts&lt;/li&gt;
&lt;li&gt;Marginal PSIS diagnostics are not useful. These marginal diagnostics would be doing the above procedure, but instead of sampling full zs, sampling only 1 dimension at a time. Compared to PSIS diagnostic evaluated from the joint distribution, these marginal ks are never larger (usually smaller) than k, and can be misleading. Also, this means you need access to the marginal distribution p(z_i, x) (or p(z_i | x)) to get the importance ratios, which may be unavailable. So don't do it.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Variational Simulation-Based Calibration Diagnostic (VSBC)&lt;/h3&gt;
&lt;p&gt;The PSIS diagnostic looks at the &lt;em&gt;full&lt;/em&gt; approximate posterior. However, sometimes you don't need to properly approximate the full posterior, and can get away with producing useful point estimates. VSBC evaluates the quality of point estimates. It is based on &lt;a href="http://www.stat.columbia.edu/~gelman/research/published/Cook_Software_Validation.pdf"&gt;Validation of Software for Bayesian Models Using Posterior Quantiles&lt;/a&gt; (Cook, 2006).&lt;/p&gt;
&lt;p&gt;The key observation from (Cook et al., 2006) is going to be fun to explain with no proper equations. Let's try: suppose we have access to p(z), p(x|z) and p(z|x) (this will be approximated by p(z) shortly). We simulate an x by first sampling from z, then p(x|z). Now, we then sample multiple z's from p(z|x). We can ask what fraction of those sampled z's are smaller than the original z - we call this the calibration probability. Now, if we were to do this multiple times (picking a z, then x, then multiple resampled z's) we would get a distribution of calibration probabilities. And that should be uniform. I &lt;em&gt;think&lt;/em&gt; this is Cook's observation.&lt;/p&gt;
&lt;p&gt;So to relate this to VI, we can perform the above procedure, replacing the true posterior p(z|x) with the approximate posterior q(x). (This means we have to do a full VI step for each dataset x we sample!) We could then in principle ask how far the distribution of calibration probabilities deviates from normal, but in this paper they suggest (following on from other literature) to instead measure how &lt;em&gt;asymmetric&lt;/em&gt; this probability is.&lt;/p&gt;
&lt;p&gt;Thus, the VSBC diagnostic is to test for asymmetry in the distribution of calibration probabilities. They do this using a Kolmogorov-Smirnov test between the distribution of probabilities and one minus that distribution. More specifically, they actually focus on &lt;em&gt;marginal&lt;/em&gt; probabilities - so where I said 'z' above, imagine this is one dimension of z. Thus, they look at marginal calibration probabilities. This is necessary because z &amp;lt; z' only makes sense for scalars.&lt;/p&gt;
&lt;p&gt;So running the diagnostic means running VI multiple times over simulated datasets. If your generative model of the data is poor, this diagnostic won't tell you much about how your VI scheme will work on real data, or indeed on a given instance of real data, since VSBC gives average performance. An advantage of VSBC over PSIS is that it looks at marginals, so you can potentially identify &lt;em&gt;which&lt;/em&gt; dimensions in z are problematic during fitting.&lt;/p&gt;
&lt;h3&gt;Applications, etc.&lt;/h3&gt;
&lt;p&gt;Given these two diagnostics, they then show how they can be used in a couple of different settings - Bayesian linear regression, logistic regression, a hierarchical model (the famous Eight-School model), and a cancer classification application. In all cases, they use mean-field Gaussian automatic differentiation variational inference.&lt;/p&gt;
&lt;p&gt;The big question for me and probably a lot of other users of variational inference is how well these can be applied to the types of posteriors we try to approximate using hideous neural networks. VSBC may be computationally impractical because it puts the whole VI procedure inside an inner loop, although it's easily parallelisable. High-dimensional posteriors are problematic for importance sampling and thus PSIS, although I don't know what "high" is - 10, 100? 1000??  Multimodality in the posterior is also a challenge, as they point out in the discussion - the VI approximation could completely miss a mode, but the PSIS diagnostic would nonetheless indicate all is well. They suggest to use PSIS to evaluate some other divergence (such as a KL divergence) to diagnose this case.&lt;/p&gt;
&lt;p&gt;In summary, this has been a post about evaluating variational inference using two diagnostics - Pareto-smoothed importance sampling, and variational simulation-based calibration. At its core this paper feels like an application of previous/existing work to a slightly new domain (variational inference). I'm curious to try these diagnostics on my own variational posteriors. Code is seemingly available (maybe just for PSIS) - R package (&lt;a href="https://cran.r-project.org/web/packages/loo/index.html"&gt;loo&lt;/a&gt;), and also a &lt;a href="https://github.com/avehtari/PSIS"&gt;Python/Matlab port&lt;/a&gt;.&lt;/p&gt;</content><category term="ml"></category><category term="papers"></category><category term="variational inference"></category><category term="evaluation"></category></entry><entry><title>NIPS 2017</title><link href="ml/2017-12-20-nips2017.html" rel="alternate"></link><published>2017-12-20T00:00:00+00:00</published><updated>2017-12-20T00:00:00+00:00</updated><author><name>corcra</name></author><id>tag:None,2017-12-20:ml/2017-12-20-nips2017.html</id><summary type="html">&lt;p&gt;&lt;em&gt;I'm continuing my tradition of summarising conferences I attend. Previous posts: &lt;a href="ml/2016-12-16-nips2016_b.html"&gt;NIPS 2016&lt;/a&gt;, &lt;a href="ml/2015-12-14-nips2015.html"&gt;NIPS 2015&lt;/a&gt;, &lt;a href="ml/2016-02-17-aaai2016.html"&gt;AAAI 2016&lt;/a&gt;, &lt;a href="ml/2016-07-05-icml2016.html"&gt;ICML 2016&lt;/a&gt;. I also went to AAAI 2017 to present my &lt;a href="https://arxiv.org/abs/1607.04903"&gt;work on unitary recurrent neural networks&lt;/a&gt;, but didn't write a summary.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This was my third time attending NIPS, but my first time …&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;em&gt;I'm continuing my tradition of summarising conferences I attend. Previous posts: &lt;a href="ml/2016-12-16-nips2016_b.html"&gt;NIPS 2016&lt;/a&gt;, &lt;a href="ml/2015-12-14-nips2015.html"&gt;NIPS 2015&lt;/a&gt;, &lt;a href="ml/2016-02-17-aaai2016.html"&gt;AAAI 2016&lt;/a&gt;, &lt;a href="ml/2016-07-05-icml2016.html"&gt;ICML 2016&lt;/a&gt;. I also went to AAAI 2017 to present my &lt;a href="https://arxiv.org/abs/1607.04903"&gt;work on unitary recurrent neural networks&lt;/a&gt;, but didn't write a summary.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This was my third time attending NIPS, but my first time attending NIPS with jetlag. The advantage of jetlag is that it provides a topic of small talk less agonisingly self aware than the weather (weather readily avoided by waking up at 6am). The downside of jetlag is me standing glassy-eyed in front of a poster, trying to formulate intelligent thoughts but just yawning really, really obviously. &lt;/p&gt;
&lt;p&gt;After a few days of complaining about the jetlag I realised I was probably exhausted because &lt;em&gt;NIPS is exhausting&lt;/em&gt;. The problem is early mornings, listening to talks, bumping into people I know, talking to people I don't know, having meetings, talking to recruiters, talking over dinner, going to poster sessions, talking at posters, finding people who I had previously talked to as strangers but who are now acquaintances and talking to them again, and so on. Having gone twice before did not teach me moderation, and I was hoarse by Thursday. I also experienced an interesting fluctuation in my desire to do research, which I have depicted in the following graph: &lt;em&gt;(enthusiasm has since returned, luckily)&lt;/em&gt;&lt;/p&gt;
&lt;figure style="display: block; float: none; margin: auto; width: 50vw;"&gt;
&lt;img src="images/2017/nips/graph.jpg" style="width: 35vw;"&gt;
&lt;figcaption&gt;
Figure 1: We observe that research enthusiasm of the PhD student is a nonlinear function of Days of NIPS (dNIPS), with two local maxima attained towards the ends of day 3 and 5. Data beyond day 6 could not be reliably collected due to hostility from the test subject.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This analysis clearly indicates that the optimal length of NIPS (including tutorials and workshops) is three days. Recent work (private communication) suggests that "taking breaks" can prolong the research-excitement peak, sustaining the individual beyond the end of the conference, providing hope for 2018. When I got back to Zurich I slept for 7 hours, arose for 7 (during which time I did a roller derby exam, but that's another blog post), then went back to bed for another 10. My body had no idea what was going on.&lt;/p&gt;
&lt;p&gt;As in 2016, I'll organise this by topic. This post is rather long, but each section is largely independent so feel free to pick and choose.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#tutorials"&gt;Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#wiml"&gt;Women in Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Main Conference&lt;ul&gt;
&lt;li&gt;&lt;a href="#invited"&gt;Invited Talks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#spotlights"&gt;Spotlights and Orals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#posters"&gt;Posters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#ml4h"&gt;Machine Learning for Health&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a name="tutorials"&gt;&lt;/a&gt;Tutorials&lt;/h2&gt;
&lt;p&gt;The first day of WiML actually coincided with the tutorials, so I was only able to attend those in the morning. I went to &lt;a href="https://optimaltransport.github.io/"&gt;A Primer on Optimal Transport&lt;/a&gt;. I then got &lt;a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases#Frequency_illusion"&gt;Baader-Meinhof'd&lt;/a&gt; about it for the rest of the conference.&lt;/p&gt;
&lt;p&gt;&lt;img src="images/2017/nips/skating.png" style="float: right; width: 24vw; margin: 1.5vw 1.5vw 1.5vw 1.5vw;"&gt;&lt;/p&gt;
&lt;p&gt;I was twenty minutes late to the tutorial. This is decided to commute to the conference on roller skates (see frame from snapchat selfie video, right), and on the first day I misjudged how long it would take (my Airbnb was about 3 miles away). &lt;/p&gt;
&lt;p&gt;Unfortunately missing the start of a tutorial, especially a mathematical tutorial, can be fatal. I arrived in the middle of an explanation of how Kantorovich's formulation of optimal transport relates to Monge's formulation and I had no reference for what was going on. I tried to sneakily look things up on Wikipedia to catch up, but all was lost and I came away from the tutorial with only an intuitive understanding of the optimal transport problem, and that Wasserstein barycentres are better than l2 averages for combining distributions, usually. In case you missed it, here are the &lt;a href="https://www.dropbox.com/s/55tb2cf3zipl6xu/aprimeronOT.pdf?dl=0"&gt;slides (pdf)&lt;/a&gt;. I said to myself that I'd go and learn optimal transport real quick and give a coherent summary of it here, but I also want to write this post before I graduate.&lt;/p&gt;
&lt;h2&gt;&lt;a name="wiml"&gt;&lt;/a&gt;Women in Machine Learning Workshop&lt;/h2&gt;
&lt;p&gt;WiML took place on the tutorial day (Monday), and also on symposia day (Thursday). I am not sure why they split it up like this.&lt;/p&gt;
&lt;p&gt;Last year I said that 15% of the 6000 NIPS attendees were women. I don't recall them releasing statistics about attendee demographics this year, but apparently 10% of unique authors amongst submissions were women (amongst accepted submissions? unknown), so the gender situation in ML is still pretty dire. Fixing this is a hard problem and not really my area of expertise (except for what I know from invariably being involved in conversations about Women in STEM), but I'm pretty sure events like this help. Why do I think that? Well, this year was the first instance of the &lt;a href="https://blackinai.github.io/"&gt;Black in AI&lt;/a&gt; workshop, and while I didn't attend (I was at the healthcare workshop), even seeing people tweeting about it made me way more aware of the work being done by Black researchers. So hopefully WiML also alerts people to the existence of good work getting done by women. Oh, and travel grants! I could imagine in this era of NIPS-selling-out-rapidly that pre-purchasing tickets to redistribute to minority groups could also play a part in promoting diversity. Weird to think of women as minority group, but apparently we only comprise &lt;a href="https://data.worldbank.org/indicator/SP.POP.TOTL.FE.ZS"&gt;49.58%&lt;/a&gt; of the world's population these days.&lt;/p&gt;
&lt;h3&gt;Interesting talks/posters:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;(contributed talk) &lt;a href="https://www.linkedin.com/in/peyton-greenside-298a5881"&gt;Peyton Greenside&lt;/a&gt; spoke about using graph convolutional networks to model Hi-C and also ATAC-seq data. I wanted to talk to her at the poster session, and once again (&lt;a href="http://apeiroto.pe/ml/nips-2016.html"&gt;this happened last year too&lt;/a&gt;) her poster was on the other side of the board to mine. You can find her talk at 1:14 into &lt;a href="https://www.facebook.com/WomenInMachineLearning/videos/1956846487664316/"&gt;this video&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(invited talk) &lt;a href="http://www.cs.mcgill.ca/~jpineau/"&gt;Joelle Pineau&lt;/a&gt; spoke about &lt;strong&gt;Improving health-care: challenges and opportunities for reinforcement learning&lt;/strong&gt;. The talk focused on &lt;em&gt;slow and small research&lt;/em&gt;: research with small sample sizes, acquired slowly. She spoke about designing treatment strategies for epilepsy, probably referencing this paper: &lt;a href="http://www.cs.mcgill.ca/~jpineau/files/panuccio-expneur13.pdf"&gt;Adaptive Control of Epileptiform Excitability in an &lt;em&gt;in vivo&lt;/em&gt; Model of Limbic Seizures&lt;/a&gt; (or &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4884089/"&gt;this one&lt;/a&gt; but I can't find the PDF). The idea is that brain stimulation can prevent seizures (cool!), and you can use reinforcement learning to build a controller (controlling the frequency of applied stimulation) to achieve the same level of seizure control while minimising the required amount of stimulation. One lesson she highlighted from this work is that models (in the 'animal model' sense) are important (they use a seizure model from mouse brain cells, I think), and having existing baselines to build from also helps. She also described some work on bandits to do cancer treatment optimisation, which I think I actually already wrote about in my &lt;a href="http://apeiroto.pe/ml/icml-2016-not-by-the-day.html"&gt;ICML 2016 post&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;(invited talk) &lt;a href="http://theory.stanford.edu/~nmishra/"&gt;Nina Mishra&lt;/a&gt; spoke about &lt;strong&gt;Time-Critical Machine Learning&lt;/strong&gt;. She spoke about anomaly detection on huge streams of data, using &lt;a href="http://proceedings.mlr.press/v48/guha16.html"&gt;Random Cut Forests&lt;/a&gt;, and she spoke about machine learning in medical emergencies (probably this paper: &lt;a href="http://theory.stanford.edu/~nmishra/Papers/timeCriticalSearch.pdf"&gt;Time-Critical Search&lt;/a&gt;). When faced with a medical emergency, people will ring the relevant emergency number, and then, a lot of people will turn to Google for help. This isn't always the most efficient way to get useful information, so they did some work on trying to detect (using search query and other metadata such as time, location, query history) whether or not a person was in an emergency situation, with the intention to give more relevant results. Someone asked if it wouldn't be easier to just make a special emergency-search app, but Nina pointed out that nobody wants to download an app in an emergency situation. (I do wonder if phones could come with such an app by default, but making that standard is a whole other challenge). She &lt;em&gt;did&lt;/em&gt; however describe a possible emergency app, which I think was called Samaritan (reminding me of the very cool &lt;a href="https://www.goodsamapp.org/"&gt;GoodSAM app&lt;/a&gt;), that guides a user through performing CPR. Part of the procedure involves putting the phone on the person's chest and using its accelerometer to guide CPR compressions. Nice use of ubiquitous smartphone tech.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Regarding the poster sessions, I spent all of the Monday session presenting my poster (see the Healthcare workshop below), and much of the Thursday session talking at my friend's poster (&lt;a href="https://arxiv.org/abs/1712.00643"&gt;Learning the Probability of Activation in the Presence of Latent Spreaders&lt;/a&gt;) and sneaking peeks at the &lt;em&gt;Interpretable Machine Learning&lt;/em&gt; symposium - video of a panel session &lt;a href="https://www.youtube.com/watch?v=kruwzfvKt3w"&gt;here&lt;/a&gt;, and video of the debate &lt;a href="https://www.youtube.com/watch?v=2hW05ZfsUUo"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Roundtables&lt;/h3&gt;
&lt;p&gt;As in previous years, the roundtables were one of the highlights of WiML for me. It's a great opportunity to meet senior scientists I might not otherwise be able to, and also to get to know some of the other WiML attendees.&lt;/p&gt;
&lt;p&gt;I ended up going to four tables - two career-based, two topic-based:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Choosing between academia and industry&lt;/em&gt; - I went to the same topic last year, but this time the table mentors were both in academia, so I got a somewhat different perspective. This is also a question I've spoken to people about and thought about, so I didn't learn much, but it's useful to have one's thoughts externally validated. The gist is that academia gives more freedom, at the cost of stability, potentially having to teach, having to supervise students, and having to &lt;s&gt;beg for money&lt;/s&gt; write grants. Not all of these are necessarily negatives - some people like teaching and supervising (nobody likes writing grants). Meanwhile, industry may limit research freedom, but provides &lt;em&gt;more&lt;/em&gt; stability, and (usually) freedom from having to run your own lab with all that entails.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Establishing collaborators/long-term career planning&lt;/em&gt; - the roundtable I attended wasn't especially enlightening on this topic, but the talk from &lt;a href="http://raiahadsell.com/index.html"&gt;Raia Hadsell&lt;/a&gt; touched on it, and gave some good long-term career advice. The advice was this (taken from one of her slides):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you like to go deep, make some room for novelty and risk.&lt;/li&gt;
&lt;li&gt;If you are a renaissance woman, try going deep.&lt;/li&gt;
&lt;li&gt;NIPS and WiML are &lt;em&gt;your&lt;/em&gt; community - be a participant.&lt;/li&gt;
&lt;li&gt;speak loudly. ask questions. be strong&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I'd not self-identify as a 'renaissance woman' (I go for 'attempted polymath'), but I tend to aim for &lt;em&gt;multifaceted&lt;/em&gt; (see the name of this website), so the advice to go deep was hard to hear, and therefore useful. (I just love when people tell me things I don't want to hear, it's why I use twitter.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Generative models&lt;/em&gt; - a lot of this roundtable consisted of me discussing evaluation of GANs with Ian Goodfellow. This was a bit selfish because it's a topic of direct relevance to my &lt;a href="https://arxiv.org/abs/1706.02633"&gt;current work on recurrent GANs for medical data&lt;/a&gt; (see also below) and maybe less interesting to others. However, I also think evaluation is one of the most interesting GAN-related questions right now. There's understandably a lot of focus on the GAN objective and optimisation procedure, thinking about convergence and stability and so on, but optimisation without evaluation seems foolish.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;Machine learning for healthcare&lt;/em&gt; - we discussed some of the big challenges facing MLHC, like data sharing, causality, and something else I've forgotten but lists should always contain three elements. I've not worked on causality before, but I'm increasingly aware of how causal reasoning (especially counterfactual reasoning) plays a role in trying to understand observational medical data. More about healthcare in the section on the healthcare workshop.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;The Main Conference&lt;/h1&gt;
&lt;h2&gt;&lt;a name="invited"&gt;&lt;/a&gt;Invited Talks&lt;/h2&gt;
&lt;figure&gt;
&lt;img src="images/2017/nips/longbeach.jpg"&gt;
&lt;figcaption&gt;
Long Beach in December: not bad
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;&lt;a href="https://research.google.com/pubs/JohnPlatt.html"&gt;John Platt&lt;/a&gt; spoke about &lt;strong&gt;Powering the next 100 years&lt;/strong&gt; (&lt;a href="https://youtu.be/L1jLpkvKPh0?t=1727"&gt;video&lt;/a&gt;), which was less environmentalist than I was hoping, and more about economics (also important, less exciting). He also spoke about nuclear fusion, which is very exciting, and possibly important (in the future). One issue I had with the premise of this talk is that I don't think we should be &lt;em&gt;trying&lt;/em&gt; to expand US power usage to the rest of the world - the US uses disproportionately much energy relative to other developed nations  (even with high standards of living, see also the &lt;a href="https://en.wikipedia.org/wiki/2000-watt_society"&gt;2000-watt society&lt;/a&gt;), so while it would be nice if we &lt;em&gt;could&lt;/em&gt;, I would personally rather focus on minimising our energy consumption until it is sustainable to consume more. But anyway, assuming the premise, they use machine learning to optimise both the economics of power usage, and for identifying promising (and safe) experiments to run on fusion reactors.&lt;/p&gt;
&lt;p&gt;I missed &lt;a href="http://www.psi.toronto.edu/~frey/"&gt;Brendan Frey&lt;/a&gt;'s talk about reprogramming the human genome, and &lt;em&gt;also&lt;/em&gt; &lt;a href="https://keysduplicated.com/~ali/"&gt;Ali Rahimi&lt;/a&gt;'s talk for the &lt;strong&gt;Test of Time Award&lt;/strong&gt;. I sorely regret missing the latter talk because people kept asking me about it. I had to wait until I got back to Zurich to rectify the matter, but having now watched it (available &lt;a href="https://www.youtube.com/watch?v=ORHFOnaEzPc"&gt;here&lt;/a&gt;), I get the fuss. &lt;/p&gt;
&lt;p&gt;So, regarding &lt;strong&gt;Rahimi's talk&lt;/strong&gt;: Yann LeCun quickly posted &lt;a href="https://www.facebook.com/yann.lecun/posts/10154938130592143"&gt;a response&lt;/a&gt;, and Ferenc Huszár posted &lt;a href="http://www.inference.vc/my-thoughts-on-alchemy/"&gt;another response&lt;/a&gt;, and I should make a separate blog post to add my incredibly important opinions on the matter, but I'll just cram them right in here. Ali Rahimi's talk claimed that much of machine learning these days is alchemy - people are building models that work, seemingly by magic, which we don't quite understand. As a relative newcomer (remember, only my third NIPS) I can't hark back to any golden days of rigour and understanding, but I can certainly say that the things he suggested - simple experiments, simple theorems - are appealing.&lt;/p&gt;
&lt;p&gt;My take: We should not make unsubstantiated claims in science. We should design experiments to test claims we make about our models, and we should not accept speculatory claims from others as fact. How often do papers today fail by these measures? Rahimi's talk implies this happens often enough to be worth calling out. I &lt;em&gt;feel&lt;/em&gt; like I have read papers which make unsubstantiated claims, or over-explain their results, or introduce poorly-defined concepts, but I can't recall any to mind, so my claim must remain purely &lt;em&gt;speculative&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;What really resonated with me from Rahimi and also Huszár's points is that &lt;em&gt;empiricism does not imply lack of rigour&lt;/em&gt;. A lot of what I do is quite empirical. A lot of what I do is somewhat applied. I've struggled with feeling like it's less scientific as a result. I've felt like I am "just" doing engineering. But the best way I have come to understand this work, which was captured in this point about empiricism, is that rigour does not need to be &lt;em&gt;mathematical&lt;/em&gt; (forgive me, I am a former theoretical physicist, so this has taken me some time to realise). Experimental design is also rigorous when done well. Building a model to solve a problem may be a kind of engineering, but trying to &lt;em&gt;understand&lt;/em&gt; it afterwards, forming hypotheses about its behaviour and then testing them - this can, and indeed should, be done rigorously. Otherwise, you show that a model exists which can achieve a certain performance on a certain task on a certain dataset, and little else.&lt;/p&gt;
&lt;p&gt;The next talk I actually attended was &lt;strong&gt;The Trouble with Bias&lt;/strong&gt; from &lt;a href="http://www.katecrawford.net/"&gt;Kate Crawford&lt;/a&gt; (video &lt;a href="https://www.youtube.com/watch?v=fMym_BKWQzk"&gt;here&lt;/a&gt;). This was a great talk, and I'm glad it got a prime spot in the program. Not only was her public speaking skill commendable (the slides just vanished near the end and she barely skipped a beat), but the talk was really interesting. I admit I was worried I'd already know most of the contents, since I read things about bias on a semi-regular basis (somehow). Even if I'd known everything she was going to say (which I didn't), I'd consider this talk a good distillation and overview of the pressing issues. She made an illuminating distinction which I shall now paraphrase.&lt;/p&gt;
&lt;p&gt;When it comes to bias, there are harms of &lt;em&gt;allocation&lt;/em&gt; and harms of &lt;em&gt;representation&lt;/em&gt;. Biased allocation is easy to see - someone got a loan someone else didn't, someone got bail and someone else didn't, etc. These are concrete and tangible, immediate, and easy to quantify. &lt;em&gt;Representation&lt;/em&gt; on the other hand relates to impressions and stereotypes. Google searches for 'CEO' returning all white men is a &lt;em&gt;representational&lt;/em&gt; bias, and its effect is much harder to measure. Images of Black people being labelled as 'gorillas' is &lt;em&gt;representational&lt;/em&gt; bias and while clearly hurtful, the impact of &lt;em&gt;allocation&lt;/em&gt; is not immediately obvious. Many people generally accept that this kind of representation is bad, but can we blame it for any &lt;em&gt;particular&lt;/em&gt; instance of allocation bias? Usually not. Representational bias is diffuse across culture, difficult to measure, and may not have any immediately obvious impacts. An example from me: We as a society are starting to suspect that something about how women are represented in society may be influencing the rates of women going on to study STEM subjects. This representational bias may be slowly manifesting as a tangible absence of female engineers, but it is difficult to formalise or prove that these observations are causally related. And of course, machine learning algorithms (like literally any algorithm) can be biased in either of these ways (and presumably more). Once again: &lt;a href="https://www.youtube.com/watch?v=fMym_BKWQzk"&gt;watch the talk&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://people.eecs.berkeley.edu/~pabbeel/"&gt;Pieter Abbeel&lt;/a&gt; spoke about &lt;strong&gt;Deep Learning for Robotics&lt;/strong&gt; - really, (deep) reinforcement learning for robotics. Probably the most important takeaway from this talk was the 1 second clip of Dota 2 1v1 mid he showed, establishing an important moment in both Dota 2 and NIPS keynote history. The non-Dota content of the talk was largely focused about meta-reinforcement learning, or 'learning to reinforcement learn', and architectures to achieve this. The idea is that you want to build agents which can adapt quickly to new environments, as humans do. One interesting idea was 'Hindsight Experience Replay', which assumes whatever ended up happening was actually the goal, and deriving reward from that. &lt;/p&gt;
&lt;figure style="width: 20vw;"&gt;
&lt;img src="images/2017/nips/skinner.jpg"&gt;
&lt;figcaption&gt;
Reinforcement learning agent re-evaluating its experience.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;This converts the usually sparse reward in RL to plentiful reward signals, given the Q-function is augmented with a notion of a goal. He used the cake metaphor that everyone loved from Yann LeCun's keynote at NIPS last year, converting the cherry on top of a cake to multiple cherries on a cake. People can't get enough of the cake joke. It's Portal all over again.&lt;/p&gt;
&lt;p&gt;I missed the talks from &lt;a href="https://getoor.soe.ucsc.edu/"&gt;Lise Getoor&lt;/a&gt;, &lt;a href="http://www.princeton.edu/~yael/"&gt;Yael Niv&lt;/a&gt;, and &lt;a href="https://www.stats.ox.ac.uk/~teh/"&gt;Yee Whye Teh&lt;/a&gt; because there is only so much time in a day.&lt;/p&gt;
&lt;h2&gt;&lt;a name="spotlights"&gt;&lt;/a&gt; Spotlights and Orals&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;First, a brief rant.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I was quite impressed by the quality of the spotlights and orals this year. Coming from the rather low bar of 'mumbling at a slide covered in equations' of previous years, I was glad to see that many presenters really put time into preparing their talk. These talks give people the opportunity to explain their work to potentially &lt;em&gt;thousands&lt;/em&gt; of fellow researchers, so giving a terrible talk is insulting both to the audience and to the people who didn't get that opportunity.&lt;/p&gt;
&lt;p&gt;I've thought about the implications of having an additional selection process for determining orals and spotlights. There's a trade-off between highlighting really good papers (with possibly terrible speakers) and highlighting less meritorious work (with a good communicator). There's also a challenge of being fair to non-native English speakers when assessing presentation quality - it would not be acceptable to condemn a talk on the basis of the speaker's command of English. &lt;/p&gt;
&lt;p&gt;I try to assess talks by how much they have considered the audience - considering what the audience already knows, what may be obvious (or not, usually), what the really important things in the work are, and what can be skipped without degrading the story. But how to do this without (subconsciously) judging the fluency of the speaker's language and delivery is not entirely clear. I'm sure there is already bias in how the quality of one's English influences paper acceptance (either through clarity or unknowingly discriminatory reviewers), so adding an additional layer on the presentation quality may exacerbate the issue. On the other hand, communication is really important for scientists, and the conference should do what they can to ensure the content is high quality. Maybe some sort of (optional) pre-conference speaking workshop for those invited to give orals and spotlights?&lt;/p&gt;
&lt;p&gt;Ranting aside, a selection of talks I took note of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1703.04389"&gt;Bayesian Optimisation with Gradients&lt;/a&gt; - &lt;em&gt;Jian Wu, Matthias Poloczek, Andrew Gordon Wilson, Peter I. Frazier&lt;/em&gt;.  Augment Bayesian optimisation using gradient information - 'derivative-enabled knowledge-gradient (dKG)'. They put a Gaussian process prior over the function to be optimised, resulting in a multi-output GP for both function and gradient (the gradient of a GP is a GP). It works better than methods not using derivatives, but I rarely have access to derivatives when I'm doing hyperparameter optimisation in deep networks, so I'm not sure how useful it would be for me.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1705.07874"&gt;A Unified Approach to Interpreting Model Predictions&lt;/a&gt; - &lt;em&gt;Scott Lundberg, Su-In Lee&lt;/em&gt;. The framework is called 'SHAP' (SHapley Additive exPlanations). The idea is to interpret the model by assigning features importance values for a given prediction. This work unifies six existing methods by proposing a notion of a 'additive feature attribution method'. They also find that their approach agrees well with human-derived feature attribution scores.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1709.01894"&gt;Convolutional Gaussian Processes&lt;/a&gt; - &lt;em&gt;Mark van der Wilk, Carl Edward Rasmussen, James Hensman&lt;/em&gt;. They consider a &lt;em&gt;patch-response&lt;/em&gt; function, which maps from image patches to real values, and place a Gaussian process prior on this function. Considering the sum of the patch-response function on all patches of the image as another function, its prior is also a Gaussian process. Computational complexity is a huge barrier here, which they address by using inducing points in the &lt;em&gt;patch&lt;/em&gt; space, corresponding to using inter-domain inducing points (an idea which is already understood, if not by me).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1703.06856"&gt;Counterfactual Fairness&lt;/a&gt; - &lt;em&gt;Matt J. Kusner, Joshua R. Loftus, Chris Russell, Ricardo Silva&lt;/em&gt;. Consider predictors as counterfactually fair if they produce the same result if a sensitive attribute were different. This means that any nodes downstream (in the causal graph) of that sensitive attribute may also be different. This implies that a predictor will necessarily be counterfactually fair if it is only a function of nodes which are &lt;em&gt;not&lt;/em&gt; descendants of the sensitive attribute, unsurprisingly enough. They address the fact that this is rarely feasible (almost everything in a person's life may be affected by their race, for example), by considering other models. For example, using residuals of variables, after accounting for (using a linear model) the sensitive attributes. One nitpick: I take issue with the example they give in Figure 2 (level 2). They introduce a latent variable which is predictive of success (GPA, LSAT, first year law school average grade) independent of sex and race, and call this &lt;em&gt;knowledge&lt;/em&gt;. I think this is a weird choice - &lt;em&gt;surely&lt;/em&gt; knowledge is affected by sex/race, if only by influencing available educational opportunities and ability to study unimpeded (for example, the need to work during school/college, the need to look after family members). I am trying to think of another name for this node which is &lt;em&gt;not&lt;/em&gt; plausibly influenced by sex or race, some sort of intrinsic attribute of the person - 'grit'? 'general intelligence'? 'luck'? (But who wants to base law school admissions on luck?) I can't imagine the authors were intending to make any kind of political statement about the nature of knowledge here, but it seems like a weird error(?) in a paper dealing with social issues.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1708.02183"&gt;Multiresolution Kernel Approximation for Gaussian Process Regression&lt;/a&gt; - &lt;em&gt;Yi Ding, Risi Kondor, Jonathan Eskreis-Winkler&lt;/em&gt;. The popular method for scaling GPs is to approximate the kernel function using a low-rank approximation (the Nyström approximation). There are some issues with that: is a low-rank approximation reasonable? Which part of the eigenvalue spectrum of K' (that is, K + sigma I, which appears in the MAP estimate of the function) is the most important? This work proposes and develops a different kind of kernel approximation, depending on the data, where local factorisations are used, and it can be assumed that 'distant clusters [of data] only interact in a low rank fashion'. My cursory skim of the paper wasn't enough to get exactly what they're doing, but I love to see work questioning common practices and trying to understand/improve on them.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1705.08933"&gt;Doubly Stochastic Variational Inference for Deep Gaussian Processes&lt;/a&gt; - &lt;em&gt;Hugh Salimbeni, Marc Deisenroth&lt;/em&gt;. Why do I always end up reading about GPs? I'm not even using them (right now?!). The tl;dr on this paper is that they got deep (that is, multi-layer generalisations of) GPs to work. Previously they didn't work particularly well because the variational posterior required each layer to be independent, an assumption which this work drops by introducing a new variational inference procedure (hence the title). They show that this model works even on datasets with a billion examples.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1705.09655"&gt;Style Transfer from Non-Parallel Text by Cross-Alignment&lt;/a&gt; - &lt;em&gt;Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakola&lt;/em&gt;. Separate content from style, in text. This is interesting to me because, like &lt;em&gt;years ago&lt;/em&gt;, (2014) we had discussed using language embeddings to remove stylistic choices from the language of doctors, to try to standardise text across multiple authors. I'm not saying we have any claim whatsoever to the idea - ideas are cheap, implementation matters - but I'm interested to see that someone has - sort of - achieved something like what we wanted. They assume they have corpora with roughly the same &lt;em&gt;content&lt;/em&gt; distribution but different &lt;em&gt;style&lt;/em&gt; distributions, and try to learn a latent representation (which they formulate using a probabilistic model).  I have a big armchair-linguist issue with the idea that style is independent of content, because if you consider content as meaning then a &lt;em&gt;lot&lt;/em&gt; of meaning is conveyed through &lt;em&gt;how&lt;/em&gt; someone says something, and indeed even in their examples, they consider 'sentiment' as style, in which case I actually don't know what they mean by content. They actually mention in the introduction that one can only hope to approximately separate style and content even with parallel data, but they never really clearly define what they mean by 'content' of a sentence.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/6827-deep-multi-task-gaussian-processes-for-survival-analysis-with-competing-risks"&gt;Deep Multi-task Gaussian Processes for Survival Analysis with Competing Risks&lt;/a&gt; - &lt;em&gt;Ahmed M. Alaa · Mihaela van der Schaar&lt;/em&gt;. The risks are competing because the patient can only die from one thing. The model attempts to produce survival times (time-to-event) using a deep, multi-task (since multiple risks) Gaussian process. They use an intrinsic coregionalisation model for the kernel functions to account for multiple outputs, which models task(=output) dependence independently of input dependence, but simplifies calculations a lot (I tried to build a more complicated multi-task kernel function once and it was a big mess). They also point out that using a deep GP alleviates some dependence on the exact form of the kernel function. This work (unsurprisingly) uses the 'old' (2013) work on deep GPs, so I wonder how much it would benefit from the improved deep GPs (see above).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1705.10915"&gt;Unsupervised Learning of Disentangled Representations from Video&lt;/a&gt; - &lt;em&gt;Emily Denton, Vighnesh Birodkar&lt;/em&gt;. They want to separate time-varying and stationary parts of a video. Then you can predict future frames by applying a LSTM to the time-varying components. That's pretty neat! How do they achieve this? They use four networks - two encoders (one for scene (stationary information), one for pose (time-varying)), a decoder which maps pose and scene vectors to produce a frame, and a scene discriminator which tries to tell if pose vectors came from the same video. They construct loss terms to impose their constraints (separating time-varying and static elements), including some interesting adversarial loss terms.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a name="posters"&gt;&lt;/a&gt; Posters&lt;/h2&gt;
&lt;figure style="width: 40vw; float: none; display: block; margin: auto;"&gt;
&lt;img src="images/2017/nips/posters.jpg"&gt;
&lt;figcaption&gt;
The quiet poster hall on Monday morning.
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;My experience of the poster sessions suffered the most as a result of jetlag, so I ended up looking at far fewer posters than I would have liked (even accounting for my eternally overambitious plans for poster sessions). This was also the first year where I got invited to ~cool parties~, so I went to some of those, too.&lt;/p&gt;
&lt;p&gt;The hall for the posters included what seemed like gratuitous space between rows, but it filled up rapidly (the crowd at the Capsules poster was sizeable). I admit I always think about roller derby these days when I'm trying to get past crowds of people, but hip checking strangers isn't a great way to do poster sessions (I &lt;em&gt;assume&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;My poster session strategy is the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;before the conference: go through the list of papers and note the interesting ones&lt;/li&gt;
&lt;li&gt;don't leave any time to actually read the papers&lt;/li&gt;
&lt;li&gt;forget about the list, fight through crowds of large men to peer at poster titles&lt;/li&gt;
&lt;li&gt;eventually, learn things&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A humble plea to poster presenters: please don't stand directly in front of your poster while you're talking about it, I can't see and I don't want to get so close to you that you start talking to me.&lt;/p&gt;
&lt;p&gt;Here's a little caveat about this part of the blog post: I didn't visit all these posters. I'm just taking the opportunity to mention more interesting papers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1612.09328"&gt;The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process&lt;/a&gt; - &lt;em&gt;Hongyuan Mei, Jason Eisner&lt;/em&gt;. Alongside optimal transport, Hawkes processes appeared in my radar of possibly-interesting terms this NIPS, so I decided to take a look at this paper. I got so engrossed that I realised I was actually &lt;em&gt;reading&lt;/em&gt; the paper (I usually do a cursory skim to produce these summaries), so I've had to stop myself in the interest of giving other papers a chance. In short: a Hawkes process is a kind of non-homogeneous Poisson process (the rate of the process can vary in time) where events can &lt;em&gt;increase&lt;/em&gt; the probability of future events (the events are self-exciting). In this work they generalise the Hawkes process (allowing for inhibitory events, for example) and use a &lt;em&gt;continuous-time LSTM&lt;/em&gt; to model the intensity functions of the given events. Also, they use a &lt;em&gt;meme dataset&lt;/em&gt; (amongst others) to train the model, so the paper includes amusing lines like&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"We attribute the poor performance of the [non-neural] Hawkes process to its failure to capture the latent properties of memes, such as their topic, political stance, or interestingness".&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The idea of trying to study memes computationally is funny, because even humans barely understand memes.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure style="display: block; width: 40vw; margin: auto; float: none;"&gt;
&lt;img src="images/2017/nips/rqadsnzazfqz.jpg" 
&lt;figcaption&gt;
Example of a typical "meme"
&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1710.02224"&gt;Dilated Recurrent Neural Networks&lt;/a&gt; - &lt;em&gt;Shiyu Chang, Yang Zhang, Wei Han, Mo Yu, Xiaoxiao Guo, Wei Tan, Xiaodong Cui, Michael Witbrock, Mark Hasegawa-Johnson, Thomas S. Huang&lt;/em&gt;. Like a dilated CNN, but... an RNN. They achieve this using dilated recurrent skip connections. This is different to the usual skip connection (which takes information from some previous state of the RNN) in that it &lt;em&gt;doesn't&lt;/em&gt; rely on the immediately previous state. That's what makes it a dilation. You can stack layers with different dilation lengths to get a sort of 'multiresolution' RNN. If this sounds similar to the &lt;a href="https://arxiv.org/abs/1402.3511"&gt;Clockwork RNN&lt;/a&gt;, you're right, but see section 3.4.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1711.05411"&gt;Z-Forcing: Training Stochastic Recurrent Networks&lt;/a&gt; - &lt;em&gt;Anirudh Goyal, Alessandro Sordoni, Marc-Alexandre Côté, Nan Rosemary Ke, Yoshua Bengio&lt;/em&gt;. Yes, I care a lot about RNNs. I work on (medical) time series data, if that wasn't already apparent. This paper adds to the growing work on combining deterministic RNN architectures with stochastic elements (like state space models), hitting an intractable inference problem, and using variational inference with a RNN-parametrised posterior approximation. So what's new here? They observe that these models can often neglect to use the 'latent' part (the stochastic elements), so they add a regularisation term to the ELBO which 'forces' the latent state at time &lt;em&gt;t&lt;/em&gt; to be predictive of the hidden state of the backwards-running inference network. And this works better, empirically. When I first saw this paper I panicked because the title makes it sound very similar to an idea I have been cooking up, an idea which I got stuck on because I was trying to explain an additional regularisation term in terms of a prior (on &lt;em&gt;something&lt;/em&gt;). But these authors just go ahead and use a regulariser without any probabilistic interpretation, so it's probably fine to do that. Note to self: not everything has to be mathematically beautiful.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1703.04977"&gt;What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?&lt;/a&gt; - &lt;em&gt;Alex Kendall, Yarin Gal&lt;/em&gt;. I first learned about (and immediately loved) aleatoric and epistemic uncertainty in my applied Bayesian statistics class back in Cambridge, so despite not featuring RNNs, I was interested in this work. In this context, aleatoric uncertainty is the uncertainty inherent to the observations, whereas epistemic uncertainty arises from uncertainty about the model parameters (which could in principle be reduced with more training). So this work studies epistemic and aleatoric uncertainty in deep networks (for computer vision), and shows that modelling aleatoric uncertainty improves performance in semantic segmentation and depth regression.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1705.08639"&gt;Fast-Slow Recurrent Neural Networks&lt;/a&gt; - &lt;em&gt;Asier Mujika, Florian Meier, Angelika Steger&lt;/em&gt;. Phew, back to RNNs. This work proposes a RNN architecture attempting to combine the advantages of multiscale RNNs and deep transition RNNs. Basically, it's a 'new model architecture' paper. They show good results on two language modelling tasks, and do further analyses of the properties of their model. Multiscale (temporally speaking) data is extremely common in medicine, so something like MIMIC-III would have been a great test-case for this model as well. Maybe I'll find a masters student to explore this (I obviously don't have time because I spend all my time writing blog posts).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1705.10888"&gt;Identification of Gaussian Process State Space Models&lt;/a&gt; - &lt;em&gt;Stefanos Eleftheriadis, Thomas F.W. Nicholson, Marc Peter Deisenroth, James Hensman&lt;/em&gt;. A lot of work focuses on inferring the latent states of a GP state space model. Here, they (also) look at learning the model itself. An important difference between your typical GP setting and the GP-SSM is that the &lt;em&gt;inputs&lt;/em&gt; to the GP in the latter case are &lt;em&gt;latent&lt;/em&gt; states (of the state space model), so they have to infer &lt;em&gt;both&lt;/em&gt; the latent states &lt;em&gt;and&lt;/em&gt; the transition dynamics (that's the model). They use variational inference with a bidirectional RNN as the recognition network, so you know I'm on board.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1709.02012"&gt;On Fairness and Calibration&lt;/a&gt; - &lt;em&gt;Geoff Pleiss, Manish Raghavan, Felix Wu, Jon Kleinberg, Kilian Q. Weinberger&lt;/em&gt;.  This work seems to be a follow-up to &lt;a href="https://arxiv.org/abs/1609.05807"&gt;this paper&lt;/a&gt; which was written to analyse &lt;a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"&gt;this piece on bias in criminal sentencing from ProPublica&lt;/a&gt; (ProPublica also &lt;a href="https://www.propublica.org/article/bias-in-criminal-risk-scores-is-mathematically-inevitable-researchers-say"&gt;followed up&lt;/a&gt; on this and other research following their investigation). So first up: it's awesome to see academic research and investigative journalism interacting in this way. In the precursor paper they provide an impossibility proof (which is given a simplified geometric proof in this paper) for simultaneously satisfying calibration and equalized odds (equal false positive and false negative rates between groups). As hinted in the precursor paper, relaxing the notion of equalized odds (for example, sacrificing equal false positive rates) may allow you to keep calibration, and that's what they show in this paper.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1705.08821"&gt;Causal Effect Inference with Deep Latent-Variable Models&lt;/a&gt; - &lt;em&gt;Christos Louizos, Uri Shalit, Joris Mooij, David Sontag, Richard Zemel, Max Welling&lt;/em&gt;. The focus of this work is in account for &lt;em&gt;confounders&lt;/em&gt; (by modelling them as latent variables) while doing effect inference, particularly in the presence of noisy proxies of true confounders. They achieve this using a 'causal effect variational autoencoder' (CEVAE).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a name="ml4h"&gt;&lt;/a&gt;Machine Learning for Health (&lt;a href="https://ml4health.github.io/2017/"&gt;ML4H&lt;/a&gt;)&lt;/h1&gt;
&lt;p&gt;I speculate that they're moving away from the previous acronym (MLHC - machine learning for health care) due to a collision with the &lt;a href="http://mucmd.org/"&gt;MLHC conference&lt;/a&gt; (previously abbreviated MUCMD). Apparently MLHC (the conference) will be in Stanford in 2018, which is a shame because I feel I should attend it, but I really didn't enjoy travelling to/from California for NIPS. Also, I think conference organisers should be avoiding the USA (or any other country with restrictive or racist visa policies) if at all possible right now. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Anyway&lt;/em&gt;. The workshop, unrelated to the MLHC conference, was an all-day affair on the Friday of NIPS. There were all the usual things: invited talks, spotlight talks, (frustratingly short) poster sessions, and people crammed into one room for 8 hours. I missed the panel because I was stuck at lunch, and I missed Jure Leskovec's talk because I was ~ networking ~. For the rest, I took some notes.&lt;/p&gt;
&lt;p&gt;Talks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://dbmi.hms.harvard.edu/person/faculty/zak-kohane"&gt;Zak Kohane&lt;/a&gt; - &lt;strong&gt;AI in Medicine That Counts&lt;/strong&gt;. He distinguished between AI that does what doctors do, AI that does what doctors &lt;em&gt;could&lt;/em&gt; do (but don't), and AI that does what doctors can't do. I am reminded of &lt;a href="https://lukeoakdenrayner.wordpress.com/2016/11/27/do-computers-already-outperform-doctors/"&gt;this post&lt;/a&gt; from Luke Oakden-Rayner which distinguishes between tasks we're building ML systems to solve, and tasks which doctors actually do. They're not the same, and Kohane made the point that they need not be, in general. We can see gains in outperforming doctors on e.g. diagnostics, but we can also see gains in doing analyses doctors simply can't do (because they're not computers). Kohane gave an example of a child with ulcerative colitis who was saved from colonectomy after they ran a gene expression analysis on children with similar irritable bowel disease and identified an effective drug (indirubin). He also provided a good comparison between medicine and what Deepmind has been achieving with AlphaZero (on Go and other games). Achievements like AlphaZero make people think AI is about to take over the world (from what I can tell), but medicine is far from AI-led mastery:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it's non-deterministic&lt;/li&gt;
&lt;li&gt;it's not fully observable&lt;/li&gt;
&lt;li&gt;the action space is not discrete&lt;/li&gt;
&lt;li&gt;we have no perfect simulators&lt;/li&gt;
&lt;li&gt;'episodes' in medicine are not short (consider the number of seconds in a typical ICU stay, consider a person's entire life...)&lt;/li&gt;
&lt;li&gt;evaluation is unclear and slow&lt;/li&gt;
&lt;li&gt;trial and error is not an option (outside of controlled trials, and even then the trial is highly constrained)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In his list he also included that we have huge datasets of human play (for games like Go), but I think medicine is getting there towards having large datasets (at least locally), so I don't count this as a &lt;em&gt;fundamental&lt;/em&gt; limitation. He then went on to discuss the money end of medicine, which I'm &lt;em&gt;not&lt;/em&gt; a fan of, but if you're to be pragmatic, you gotta understand the game you're playing. He made a point that we may come up with cool technology to improve medicine in different ways, but unless a business argument can be made for it, it likely won't be adopted. This is more clearly true in the US where healthcare is more of profit-oriented than in other countries (e.g. those with socialised healthcare systems) - ML4H @ Socialised Healthcare edition, anyone? We can have it in a neutral country! &lt;em&gt;(Joking aside, I am legitimately interested in the opportunities for ML to benefit from and improve socialised healthcare systems - data centralisation is an obvious point, but perhaps other types of problems are more immediately pressing in systems like the NHS, than they would be in the USA...)&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/research/people/jchayes/"&gt;Jennifer Chayes&lt;/a&gt; - &lt;strong&gt;Opportunities for Machine Learning in Cancer Immunotherapy&lt;/strong&gt;. The immune system is an incredibly complicated and therefore cool system, and cancer immunotherapy is a very very cool use of the immune system. With the caveat that I'm &lt;em&gt;not&lt;/em&gt; an immunologist, the tl;dr of cancer immunotherapy is: tell your immune system to target and kill cancer cells. This may be what the immune system does already, to some extent. T-cells identify specific antigens, and direct the rest of the immune system to kill cells presenting those antigens. (How do T-cells know what to identify? &lt;a href="https://en.wikipedia.org/wiki/Thymus"&gt;The thymus is the coolest organ you've never heard of.&lt;/a&gt;) So the challenge is to train T-cells to specifically recognise your cancer cells, but there are &lt;em&gt;lots&lt;/em&gt; of possible (neo)antigens. You can formulate this as a matrix completion problem (T-cells v. antigens) to predict the response of new T-cells. She also described work they did for predicting response to checkpoint inhibitors (a type of cancer immunotherapy), highlighting the value of building relatively simple models on small data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.seas.harvard.edu/directory/samurphy"&gt;Susan Murphy&lt;/a&gt; - &lt;strong&gt;Challenges in Developinging Learning Algorithms to Personalise mHealth Treatments&lt;/strong&gt;. This was about the &lt;a href="http://www.heartsteps.net/"&gt;HeartSteps&lt;/a&gt; project, which tries to encourage physical activity in people who have completed cardiac rehabilitation. That is, it's an app that encourages you to go for a walk. This is a problem of sequential decision making. To maximise positive outcome (more time walking), what sort of notifications should the app send, and when? If someone is driving, you shouldn't bother them. If they just walked somewhere, or are in the middle of walking, you shouldn't tell them to go for a walk. They model it as a (contextual) bandit problem, and have to deal with noise in the data, nonstationarity (the expected reward function changes over time), and that there are longer-term delayed effects from actions. Unsurprisingly (to anyone who's used apps that send them push notifications), after a while people just start ignoring them, and the result of interventions diminish. While the intentions in this work are noble, I can see creepy unintended uses of research like this into user engagement (like &lt;a href="https://usedopamine.com/"&gt;this horrible startup&lt;/a&gt;). Technology is always a double-edged sword, but if we have to be subjected to personalised advertising and addiction mechanics in games, and so on, at least fewer people should die of heart disease, right?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://vision.stanford.edu/feifeili/"&gt;Fei-Fei Li&lt;/a&gt; - &lt;strong&gt;Illuminating the Dark Spaces of Healthcare&lt;/strong&gt;. I think that was the title. She spoke about three projects in healthcare that use computer vision, and the room was &lt;em&gt;packed&lt;/em&gt;. At first I thought everyone suddenly loves healthcare, but then I remembered that Fei-Fei Li is famous. The projects were all about activity recognition from non-RGB video (they had depth sensors and IR video if I recall - these alleviate &lt;em&gt;some&lt;/em&gt; privacy concerns). First she spoke about identifying hand-washing to tackle hospital acquired infection. One challenge was in activity recognition given unusual (for research) viewpoints, e.g. cameras on ceilings looking directly down. The second project was about ICU activity recognition, to better understand what people spend time doing in the ICU. The priority here was &lt;em&gt;efficiency&lt;/em&gt;, so they developed methods to analyse video which don't require analysis of every single frame, saving a lot of compute while still achieving high performance (on standard video understanding datasets). Finally, she spoke about applications in independent senior living, such as fall detection. This in particular is challenging due to limited training data and rare events (thankfully). They propose to use domain transfer to aid in the data scarcity issues, but she pointed out that much of this work is still in progress.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://healthsciences.ucsd.edu/som/medicine/divisions/med-genetics/research/Pages/Mesirov-Lab.aspx"&gt;Jill Mesirov&lt;/a&gt; - &lt;strong&gt;From Data to Knowledge&lt;/strong&gt;. I am doubtful this was the title of her talk, but we'll run with it. The topic was medulloblastoma, which is one of the most common forms of paediatric brain tumour. 70% of children &lt;em&gt;survive&lt;/em&gt;, but only 10% go on to leave independent lives. Their focus is in predicting relapse, which they achieve using a probabilistic model incorporating various clinical and genomic features. She then went on to describe a project to identify novel therapeutics for an aggressive subtype of medulloblastoma driven by Myc (this is a gene). Through mouse xenograft experiments and expression profiling, they found this subtype is likely sensitive to CDK-inhibitors, and found they could extend survival (in mice) by 20% with palbociclib, suggesting a candidate treatment. This sort of analysis is sort of 'well known' to me because my lab (alongside machine learning) works on cancer genomics, but I'd also like to pause for a moment to reflect on two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;As with the example from Zak Kohane (about indirubin), a lot of the time (translational) computational biologists are hunting for threads - persistent patterns in the disease which indicate possible vulnerabilities, which they can then follow up by looking for matches in drugs with known targets. If you can optimise any point in that process, you can probably save someone's life, some day.&lt;/li&gt;
&lt;li&gt;A 20% extension in survival is clinically significant, but it's not a cure as we think of it. For mice it's measured in days, for humans probably one or two years if not months. For some cancers, especially brain cancers, this is still where we're at. Fighting cancer is really, really hard.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://research.google.com/pubs/GregCorrado.html"&gt;Greg Corrado&lt;/a&gt;. I just stopped writing down the titles at some point. He spoke about a few different projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Diagnostics: doctors working alongside algorithms to work better/faster. Examples from Google Brain: screening for diabetic retinopathy (on par with ophthamologists), reading breast cancer biopsies.&lt;/li&gt;
&lt;li&gt;Care management/decision support: the idea is to have smart electronic medical records, to help reduce errors and improve care quality. Having observed clinicians interacting with EMRs, I see a lot of potential for improvement here.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;He mentioned challenges with processing medical data because of how messy it is and I just laughed and laughed and then cried (silently). Apparently they built some sort of &lt;a href="https://www.hl7.org/fhir/"&gt;FHIR&lt;/a&gt;-based pipeline to integrate data from six healthcare systems, and it worked well, but I didn't write down what they were doing at the end of the pipeline.
 He also gave a shout-out to Google's newly open-sourced variant caller, &lt;a href="https://www.biorxiv.org/content/early/2016/12/21/092890"&gt;DeepVariant&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.oxford-man.ox.ac.uk/~mvanderschaar/"&gt;Mihaela van der Schaar&lt;/a&gt; - &lt;strong&gt;Dynamical Disease Modelling&lt;/strong&gt;. Her work focuses on &lt;em&gt;dynamical&lt;/em&gt; modelling, assuming some hidden clinical state which informs observable physiological variables. You could approach this using a hidden Markov model, but she observed that transition probabilities typically depend on sojourn times, necessitating a semi-Markov model. Furthermore, patterns of missingness are informative, suggesting to model observation times, e.g. as a Hawkes process. The informativeness of measurements in medicine may not be immediately obvious, but the rationale (at least in the ICU, my area of focus) is that some measurements are only taken when needed, and they're only needed when the doctor suspects something is up. Even if a measurement is routinely performed, the rate of measurement may increase when patients become more critical. So you have a huge case of missing-not-at-random. She also mentioned their work on modelling competing risks, which I described earlier in this blog post.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://buttelab.ucsf.edu/"&gt;Atul Butte&lt;/a&gt; - &lt;strong&gt;Translating a Trillion Points of Data into Diagnostics, Therapies and New Insights in Health and Disease&lt;/strong&gt;. I didn't take notes for this talk, but his slides are &lt;a href="https://www.slideshare.net/atulbutte/atul-butte-nips-2017-ml4h"&gt;here&lt;/a&gt; - I'd recommend slide 29. In case that link at some point goes dead, that slide summarises lessons he's learned in MLHC over the years, and these are (paraphrased):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Solve the problems that health care professionals need solved, don't just guess&lt;/li&gt;
&lt;li&gt;Watch out for models limited by bad inputs (e.g. from patients, from doctors)&lt;/li&gt;
&lt;li&gt;Learn what IRB, HIPAA, BAA, ICD-10 codes, CPT codes, CLIA, and CAP are.&lt;/li&gt;
&lt;li&gt;Learn patience.&lt;/li&gt;
&lt;li&gt;Not everything needs deep learning.&lt;/li&gt;
&lt;li&gt;Having all the data on someone is super rare.&lt;/li&gt;
&lt;li&gt;Health care inefficiency is not about friction. (He made a point that everywhere there's a cost, someone is making money and will push back against losing that money.)&lt;/li&gt;
&lt;li&gt;Data integration &lt;em&gt;can&lt;/em&gt; happen, if there's a business reason for it.&lt;/li&gt;
&lt;li&gt;Platforms and companies are commoditized. (As subpoints to that he suggests the ML people should come with some medical knowledge, to demonstrate we care about healthcare, and so we don't cost medical collaborators time training us.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Another point he made was that there's a &lt;em&gt;lot&lt;/em&gt; of freely-accessible data out there, which is ripe for analysis. And possibly founding startups.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/ratschlab/RGAN/blob/master/presentations/nips_ml4h.pdf"&gt;&lt;img src="images/2017/nips/nips_ml4h.png" style="float: right; width: 30vw; margin: 1.5vw 1.5vw 1.5vw 1.5vw;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned, there were two poster sessions. I spent the first one presenting my poster, and much of the second one talking to people, so I didn't get to &lt;em&gt;see&lt;/em&gt; too many posters. I've described a lot of work from other people in this post, so let me do the same for myself. At WiML and ML4H I was presenting (variations on) this poster: (right)&lt;/p&gt;
&lt;p&gt;Summary of the related paper:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1706.02633"&gt;Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs&lt;/a&gt; - &lt;em&gt;Stephanie L. Hyland (that's me) and Cristóbal Esteban, Gunnar Rätsch&lt;/em&gt;. (For disclosure: the version that was accepted by ML4H was a 4-page version of this preprint, focusing on the medical data and aspects. They asked us to give links to the arXiv versions of our work, but I couldn't in good faith link to the full version as it wasn't reviewed by them. In case you noticed and were wondering why there's no link to the paper the workshop page, it's because of my conscience). &lt;/p&gt;
&lt;p&gt;The motivation for this work was that MLHC struggles with data sharing. Medical data is hard to share, with good reason. But it means a &lt;em&gt;lot&lt;/em&gt; of work in MLHC is completely unreproducible, and nobody can directly build on it, because they don't have access to the data/task a model was built for. This stifles our progress, and MLHC is hard enough already. So wouldn't it be great if we had a &lt;em&gt;synthetic&lt;/em&gt; dataset (without privacy concerns) that we could use to benchmark models and approaches? Shoutout to this related paper with similar motivation from Choi et al.: &lt;a href="https://arxiv.org/abs/1703.06490"&gt;Generating Multi-label Discrete Patient Records using Generative Adversarial Networks&lt;/a&gt; (they focus on binary and count-valued data, hence our focus on real-valued time-series data).&lt;/p&gt;
&lt;p&gt;I'd summarise what we did in this work in three points:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Devise a GAN architecture to generate real-valued time series. We call this a 'recurrent' GAN, or RGAN, because it uses RNNs for both discriminator and generator networks (yes, RNNs!). We also have a conditional version which takes label information, allowing the RGAN to generate data from labels.&lt;/li&gt;
&lt;li&gt;Devise an evaluation scheme for GANs tailored to our setting. We do this by generating a synthetic training dataset from the RCGAN (labels + features), training a classifier (e.g. CNN, random forest) on it, and reporting its performance on a held-out &lt;em&gt;real&lt;/em&gt; test set. We call this the &lt;em&gt;TSTR&lt;/em&gt; (train on synthetic, test on real) score. Since we want to use the RGAN to generate synthetic medical data, the TSTR score is of particular relevance.&lt;/li&gt;
&lt;li&gt;Analyse empirically whether the RGAN is 'overfitting'. By this I mean, we ask (roughly) if the GAN is more likely to produce samples &lt;em&gt;very similar&lt;/em&gt; to training samples than it is to produce other samples (from the same distribution, e.g. the test set). If it is, then we have a problem. Firstly because reproducing the training set is boring and does &lt;em&gt;not&lt;/em&gt; require a GAN, and secondly (more importantly) because reproducing the training data set would constitute a serious privacy breach in our setting.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;On the final point, we also experimented with training the RGAN using differential privacy, &lt;em&gt;just to be extra safe&lt;/em&gt;. If you're willing to sacrifice performance you can get some privacy, but it's a harsh trade-off and requires further research.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I held a small reading group in my lab about interesting contributions from the ML4H workshop, so I'll briefly summarise two papers of interest to me:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1712.00164"&gt;Generative Adversarial Networks for Electronic Health Records: A Framework for Exploring and Evaluating Methods for Predicting Drug-Induced Laboratory Test Trajectories&lt;/a&gt; - &lt;em&gt;Alexandre Yahi, Rami Vanguri, Noémie Elhadad, Nicholas P. Tatonetti&lt;/em&gt;. My reason for interest should be obvious. Also, the first author emailed me to get help with &lt;a href="https://github.com/ratschlab/RGAN/"&gt;our code&lt;/a&gt;, which possibly means they used it. I spent some time answering issues on GitHub and responding to emails, and I'm still quite a junior scientist, so it's really exciting for me to see people taking interest in and actually trying to use my work. Anyways, in this paper, &lt;em&gt;as far a I understand it&lt;/em&gt;, they're generating cholesterol time-course data before and during exposure to statins. They do two interesting things: 1) Clustering patients based on a large set of clinical attributes, then training separate GANs on each cluster. 2) Evaluating the performance of the GAN by measuring how well it 'predicts' cholesterol level during statins exposure. They do this by matching generated samples to the closest real (hopefully test-set) sample based on the &lt;em&gt;pre-exposure&lt;/em&gt; part of the sequence, then measuring the similarity of the synthetic and real samples during statins exposure. This evaluation method seems a little brittle - imagine there are multiple real samples that look similar to the synthetic one, but respond to statins quite differently, but it's an interesting idea.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://arxiv.org/abs/1712.00181"&gt;Personalized Gaussian Processes for Future Prediction of Alzheimer's Disease Progression&lt;/a&gt; - &lt;em&gt;Kelly Peterson, Ognjen (Oggi) Rudovic, Ricardo Guerrero, Rosalind W. Picard&lt;/em&gt;. I haven't spent enough time with this paper to fully understand it, but the most interesting aspects are: fitting a GP model to a source population, and personalising (i.e. tuning) it to an individual based on their observed data to date using domain-adaptive GPs, and using auto-regressive GPs. Various kinds of GPs. No RNNs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;&lt;a name="conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This has been an exceedingly long blog post and I hope you're not as exhausted as I am, but this is basically an accurate depiction of my experience of NIPS. A lot of stuff, all the time. I have not even mentioned the &lt;a href="http://bayesiandeeplearning.org/"&gt;Bayesian Deep Learning workshop&lt;/a&gt;. During the lunch break on the final day I grabbed a burrito and almost fell asleep. I was not the only one. The convention centre by that point was gradually emptying, with scattered people dozing off in chairs, and a prominent left-luggage zone where the registration tables had been. There was a clear sense of winding down, perhaps because the process had already begun for me. I stayed only briefly at the closing party (missing some unpleasantness, it sounds like), and instead walked/skated thoughtfully back to my Airbnb along the beach, pausing to look at the stars and listen to the Pacific Ocean.&lt;/p&gt;
&lt;p&gt;&lt;Img src="images/2017/nips/longbeach_2.jpg" style="display: block; width: 45vw; margin: auto;"&gt;&lt;/p&gt;</content><category term="ml"></category><category term="nips"></category><category term="conference"></category><category term="long beach"></category><category term="california"></category><category term="usa"></category><category term="MLHC"></category></entry><entry><title>NIPS 2016</title><link href="ml/2016-12-16-nips2016_b.html" rel="alternate"></link><published>2016-12-16T00:00:00+00:00</published><updated>2016-12-16T00:00:00+00:00</updated><author><name>corcra</name></author><id>tag:None,2016-12-16:ml/2016-12-16-nips2016_b.html</id><summary type="html">&lt;p&gt;We return for another installment of Stephanie Summarises a Conference. My previous work in this area is &lt;a href="ml/2015-12-14-nips2015.html"&gt;NIPS 2015&lt;/a&gt;, &lt;a href="ml/2016-02-17-aaai2016.html"&gt;AAAI 2016&lt;/a&gt;, and &lt;a href="ml/2016-07-05-icml2016.html"&gt;ICML 2016&lt;/a&gt;. I was pleasantly surprised at NIPS to be asked if I was going to write one of these again. Apparently someone somehow found my blog. Ignorance …&lt;/p&gt;</summary><content type="html">&lt;p&gt;We return for another installment of Stephanie Summarises a Conference. My previous work in this area is &lt;a href="ml/2015-12-14-nips2015.html"&gt;NIPS 2015&lt;/a&gt;, &lt;a href="ml/2016-02-17-aaai2016.html"&gt;AAAI 2016&lt;/a&gt;, and &lt;a href="ml/2016-07-05-icml2016.html"&gt;ICML 2016&lt;/a&gt;. I was pleasantly surprised at NIPS to be asked if I was going to write one of these again. Apparently someone somehow found my blog. Ignorance of this is one of the downsides (??) of not having creepy tracking analytics.&lt;/p&gt;
&lt;p&gt;This time we get a &lt;em&gt;table of contents&lt;/em&gt; so I can be guiltlessly verbose (I fear how long my PhD thesis is going to be):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#wiml"&gt;Women in Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Main Conference&lt;ul&gt;
&lt;li&gt;&lt;a href="#invited"&gt;Invited Talks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#posters"&gt;Posters&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#law"&gt;Machine Learning and the Law&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mlhc"&gt;Machine Learning for Healthcare&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#misc"&gt;Miscellaneous Comments/Observations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a name="wiml"&gt;&lt;/a&gt;Women in Machine Learning Workshop&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;"What are women and how can machine learning stop them?"&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I didn't register for WiML in time last year, so this was my first time attending. I also managed to miss all the Sunday events by arriving to Barcelona at midnight that night. There was a workshop on Effective Communication where I could perhaps have learned how to write shorter blog posts.&lt;/p&gt;
&lt;p&gt;My feelings about having 'woman-only/woman-centric' events are complex, poorly-understood and otherwise beyond the scope of this particular post, but the reality is that women are wildly underrepresented in computer science and machine learning is no exception (about 15% of the 6000-odd NIPS attendees were women, and I don't know what fraction of those were recruiters). I'm so used to being surrounded by men that I barely notice it (except for the occasional realisation that I'm the only woman in a room), so having a large conference hall full of women for this workshop was a bit surreal.&lt;/p&gt;
&lt;h3&gt;Interesting talks/posters:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;(talk) &lt;a href="http://maithraraghu.com/"&gt;Maithra Raghu&lt;/a&gt;, &lt;a href="https://arxiv.org/abs/1606.05336"&gt;On the expressive power of deep neural networks&lt;/a&gt;. They study the expressive power (ability to accurately represent different functions) of neural networks and show that this depends on a quantity they call 'trajectory length'. There's also a companion paper, &lt;a href="https://arxiv.org/abs/1606.05340"&gt;Exponential expressivity in deep neural networks through transient chaos&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;(poster) Niranjani Prasad, Barbara Engelhardt, Li-Fang Cheng, Corey Chivers, Michael Draugelis and Kai Li. &lt;em&gt;A Reinforcement Learning Approach to Weaning of Mechanical Ventilation in ICU&lt;/em&gt;: relevant to my ICU-interests, but this poster was unfortunately on the &lt;em&gt;other side of the board&lt;/em&gt; to mine, so I only got to look at it briefly. They're using MIMIC-III, looking at pneuomnia patients and the question of intubation. A challenge was engineering the reward function, which required consultation with clinicians.&lt;/li&gt;
&lt;li&gt;(poster) Luisa M Zintgraf, Taco S Cohen, Tameem Adel and Max Welling. &lt;em&gt;Visualizing Deep Neural Network Decisions&lt;/em&gt;. They propose a 'prediction difference analysis' method to visualise regions of an image which either support or oppose a particular prediction. This is based on assigning 'relevance' to parts of the input, based on the 'weight of evidence' a particular input gives to a certain class. This is a pre-existing idea, and a cursory glance at the paper doesn't highlight what's novel about their approach - possibly applying it to deep networks? Extending it to analysing the influence of multiple features at a time, possibly?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I accidentally presented my poster for &lt;em&gt;most&lt;/em&gt; of the poster session and therefore missed out on going around to others. This is a compelling argument for having co-authors who can share the load. For the record, the work I was presenting was &lt;a href="https://arxiv.org/abs/1607.04903"&gt;Learning Unitary Operators with Help from u(n)&lt;/a&gt;, which I did with my advisor Gunnar Rätsch, and which will be appearing in AAAI-17. I also presented it at the Geometry in ML workshop at ICML, see my post &lt;a href="ml/2016-07-05-icml2016.html"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Roundtables&lt;/h3&gt;
&lt;p&gt;What I found especially valuable and unique about WiML were the &lt;strong&gt;roundtables&lt;/strong&gt; - one for research advice, one for career guidance. In each one there were subtables for specific topics, with 'experts' to extract wisdom from.&lt;/p&gt;
&lt;p&gt;I shamelessly hogged space at the healthcare research roundtable in the first session to listen to Jennifer Healey. She's a researcher at Intel Labs working on using sensor data for human health. That is, if you have continuous audio recording (as one can get from a phone microphone), you can identify a person coughing, measure qualities of it, its frequency, onset and so on. This information is incredibly valuable for making diagnoses and treatment decisions, and it's the kind of data that one could reasonably imagine everyone collecting in the future. One thing I really enjoyed about the discussion was that she was quite aware of the &lt;em&gt;HORRIFYING PRIVACY IMPLICATIONS&lt;/em&gt; of this kind of data, and the need to avoid storing (and calculating on) this data on The Cloud. I'm really excited about this avenue of healthcare (as I say every time it comes up) and I'm really glad to hear a senior researcher from a big company talking about the importance of the privacy considerations. As was mentioned in the ML and Law symposium, all personal data you collect is a privacy vulnerability. But collecting this data could have such massive positive healthcare implications that 'solving' the privacy problem is really important. Especially if the data is going to end up getting collected anyway...&lt;/p&gt;
&lt;p&gt;The second roundtable I went to (about careers/advice), I spoke to some people at Deepmind about working there (me and everyone else at NIPS, it feels like...), and some other people about how to decide between industry (that is, &lt;em&gt;industrial research&lt;/em&gt;) and academia. Both experts at the industry/academia table were in industry, so I'm not sure I got an unbiased perspective on it. The context for all of this is that I'm a 'late-stage' PhD student (the idea of that is rather scary to me - there's still so much to learn!), so I'm looking for internships (got any spare internships? &lt;a href="https://apeiroto.pe/pages/about.html"&gt;contact me&lt;/a&gt;) and thinking about post-PhD land. The most concrete difference I learned about was that in companies, you may need to send your paper to the legal team before submitting it to a conference, in case they want to patent something first. I'd imagine this also applies to preprints and code and so on. Otherwise, the level of intellectual freedom one enjoys seems to vary, but everyone I spoke to (from a biased sample) seemed largely unconstrained by their industrial ties.&lt;/p&gt;
&lt;p&gt;I'd imagine there's a gulf of misery between brand-new startups that have yet to become overly concerned with Product, and established tech companies with the luxury of blue-skies research labs, where you don't get to do cool things and instead must live in a box desperately trying to demonstrate the commercial viability of your research. I'd also imagine that said box-dwellers don't attend roundtables (how do you fit a round table in a square box?).&lt;/p&gt;
&lt;p&gt;The final notable thing that happened at WiML was me apparently winning a raffle, but being shamefully absent. I was upstairs charging my laptop and catching up with a friend from MLSS, blissfully ignorant of the prize I would never receive.&lt;/p&gt;
&lt;h1&gt;The Main Conference&lt;/h1&gt;
&lt;h2&gt;&lt;a name="invited"&gt;&lt;/a&gt;Invited Talks&lt;/h2&gt;
&lt;p&gt;The main conference opened with a talk (the Posner Lecture) from &lt;strong&gt;Yann LeCun&lt;/strong&gt;. LeCun is famous enough in machine learning that people were excitedly acquiring and then sharing selfies taken with him (a practice I find puzzling), so the things he said will likely echo around the community and I need not repeat them in detail here. In gist he was talking about unsupervised learning (although focusing on a subtle variant he called 'predictive learning'). He used a cake analogy which spawned parodies and further cake references throughout the conference/social media. The analogy is that reward signals (as in reinforcement learning) are the cherry, labels for supervised learning is the icing, and the rest of the cake is essentially unlabelled data which requires unsupervised learning. The growing importance of unsupervised learning is not new, I can say from my intimidating &lt;em&gt;one year&lt;/em&gt; of previous NIPS conferences.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Marc Raibert&lt;/strong&gt; from Boston Dynamics gave an entertaining talk about dynamic legged robots. This featured many YouTube videos I'd already seen, but was happy to gormlessly rewatch. One amusing thing is the fact that they can't use hydraulics in domestic robots, because they leak. That's a great example of a &lt;em&gt;real-world&lt;/em&gt; problem. It might be common knowledge amongst roboticists, but 'you can't use hydraulics because nobody wants oil and stuff on their carpet' would not have occurred to me if I for some reason needed to design a robot. Now, maybe I would not need to design a robot directly, but it's not entirely unlikely that I could design an algorithm making assumptions about the kinds of movements, or the cost of those movements, that a robot could make. And this is why 'domain experts' will always be needed. Probably.&lt;/p&gt;
&lt;p&gt;At the end of the talk, someone asked if Boston Dynamcis uses machine learning. They do not. Maybe they should?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Saket Navlakha&lt;/strong&gt; spoke about 'Engineering Principles from Stable and Developing Brains'. Part of this talk was based on &lt;a href="http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004347"&gt;this PLoS CB paper&lt;/a&gt; where they compare neural network development in the brain to that of engineered networks. In brains, connections are created rapidly and excessively, and then pruned back over time dependent on use (they demonstrate this in mouse models). This is to be contrasted with engineered networks, where adding and removing edges in this way would be seen as wasteful. They demonstrate however that the hyper-creation and then aggressive pruning results in improved network function. They're particularly interested in routing networks, so the applicability to artificial neural networks is not immediately apparent.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Susan Holmes&lt;/strong&gt; gave the Brieman Lecture, which exists to bridge the gap between the statistics and machine learning communities. This was the &lt;em&gt;single&lt;/em&gt; talk of the conference where I took &lt;a href="https://www.evernote.com/shard/s404/sh/0f22b0fa-65c7-44ac-bd55-551349cc6cbf/2f19eb24c584f88e"&gt;notes&lt;/a&gt;, because the relevance of the topic to me and others in my lab overwhelmed the need to preserve precious limited laptop battery. The title of the talk was "Reproducible Research: the case of the Human Microbiome", and so was mostly a story about how to do reproducible research, in the context of microbiome analysis. One really cool thing she mentioned was a web application called &lt;a href="http://joey711.github.io/shiny-phyloseq/"&gt;shiny-phyloseq&lt;/a&gt;, which seems to be an interactive web interface to their phyloseq package. &lt;em&gt;However&lt;/em&gt;, it also (I think) records what you do with the data as you explore, which you can then export as a markdown file to include with your paper. I try to emulate this by pipelining my analysis in bash scripts (or within python), but having something to passively record as you interactively explore data seems additionally very beneficial. The &lt;a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf"&gt;garden of forking paths&lt;/a&gt; is a risk during any data exploration. Also, the garden of forgetting exactly what preprocessing steps you did.&lt;/p&gt;
&lt;p&gt;There was a touching memorial to &lt;a href="http://www.inference.phy.cam.ac.uk/mackay/"&gt;Sir David MacKay&lt;/a&gt; during one of the sessions. It's easy, as an early-stage scientist, to get swept up in the negative aspects of academic culture (looking at you, Publish or Perish) and lose sight of the reasons for doing any of this. Hearing about scientists like MacKay, who both think and care deeply, is genuinely inspirational. The only book on my Christmas wishlist this year is "Information Theory, Inference, and Learning Algorithms".&lt;/p&gt;
&lt;h2&gt;&lt;a name="posters"&gt;&lt;/a&gt;Interesting Papers/Posters&lt;/h2&gt;
&lt;p&gt;Necessarily, a subset of the interesting work.&lt;/p&gt;
&lt;h3&gt;Misc&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1602.03534"&gt;Learning Transferrable Representations for Unsupervised Domain Adaptation&lt;/a&gt; - &lt;em&gt;Ozan Sener · Hyun Oh Song · Ashutosh Saxena · Silvio Savarese&lt;/em&gt; - jointly learn representation, cross-domain transformation as well as labels to do better domain adaptation.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.csail.mit.edu/beenkim/papers/KIM2016NIPS_MMD.pdf"&gt;Examples are not enough, learn to criticize! Criticism for Interpretability&lt;/a&gt; - &lt;em&gt;Been Kim · Oluwasanmi Koyejo · Rajiv Khanna&lt;/em&gt; - this was a great poster and spotlight talk. The idea is this: to help make sense of massive datasets, we ideally identify some 'representative samples' ('prototypes') which we can manually assess and use to generalise about the rest of the data. The danger is that there will be non-stereotypical data points, which are nonetheless represented in the data and should be considered. They call these examples 'criticisms', and describe an approach to generate both prototypes and criticisms from large datasets.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1606.09184"&gt;Disease Trajectory Maps&lt;/a&gt; - &lt;em&gt;Peter Schulam, Raman Arora&lt;/em&gt; - the objective here is to find latent representations of patient trajectories, and then characterise them (i.e. through clustering). They use a fairly complicated probabilistic model to do this, so the more interesting details are in the paper. They also associate the representations with clinical outcomes to prove that they're 'clinically meaningful', comparing with some other methods of representing time series.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1606.03137"&gt;Cooperative Inverse Reinforcement Learning&lt;/a&gt; - &lt;em&gt;Dylan Hadfield-Menell · Stuart J Russell · Pieter Abbeel · Anca Dragan&lt;/em&gt; - in traditional inverse reinforcement learning (IRL), the agent tries to learn the expert's reward function. However, to have benevolent robots, we would like them to maximise rewards &lt;em&gt;for humans&lt;/em&gt;, not themselves. Additionally, in IRL the agent observes assumed-optimal expert trajectories, which may nonetheless be &lt;em&gt;sub&lt;/em&gt;-optimal for learning - one would rather generate teaching, or demonstration trajectories. They formulate a solution to these concerns as a two-player game with learning and acting (deployment) phases.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cushmanlab.fas.harvard.edu/docs/NIPS_2016_Teaching_by_demonstration_w_supplementary.pdf"&gt;Showing versus doing: Teaching by demonstration&lt;/a&gt; - &lt;em&gt;Mark K Ho · Michael Littman · James MacGlashan · Fiery Cushman · Joe Austerweil · Joseph L Austerweil&lt;/em&gt; - this work focuses on the second issue raised in the previous one - how does a &lt;em&gt;teaching&lt;/em&gt; trajectory differ from a &lt;em&gt;doing&lt;/em&gt; trajectory? They formulate it as 'Pedagogical Inverse Reinforcement Learning'd. What's really neat about this work is that they actually did experiments with humans to validate their model's predictions about how people would behave while trying to teach versus simply doing.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1606.02647"&gt;Safe and Efficient Off-Policy Reinforcement Learning&lt;/a&gt; - &lt;em&gt;Remi Munos · Tom Stepleton · Anna Harutyunyan · Marc Bellemare&lt;/em&gt; - 'safety' in this work refers to the capacity of the algorithm to deal with arbitrary 'off-policyness' (that is, the policy to evaluate and the behaviour policy observed need not be close), and 'efficiency' refers to using data ... efficiently. The work seems to combine previous approaches which are either safe or efficient into an algorithm enjoying the benefits of both, with various theoretical results.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1606.04753"&gt;Safe Exploration in Finite Markov Decision Processes with Gaussian Processes&lt;/a&gt; - &lt;em&gt;Matteo Turchetta · Felix Berkenkamp · Andreas Krause&lt;/em&gt; - 'safe' here roughly has its common meaning. They address the issue where an agent, looking to maximise long-term (discounted, perhaps) reward, is willing to tolerate temporary very negative rewards. This is unacceptable for safety-critical agents - they used the example of a Mars rover getting stuck in a crater - so they develop an algorithm (SafeMDP) to &lt;em&gt;safely&lt;/em&gt; explore, avoiding unsafe states/actions using noisy observations from nearby states. They also ensure the agent can't get stuck in states without safe escape routes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Recurrent Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1605.07571"&gt;Sequential Neural Models with Stochastic Layers&lt;/a&gt; - &lt;em&gt;Marco Fraccaro · Søren Kaae Sønderby · Ulrich Paquet · Ole Winther&lt;/em&gt; - they combine state-space models (uncertainty about states) with recurrent neural networks (sequential, long time dependencies), and describe a variational inference procedure for the model.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1610.09513"&gt;Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences&lt;/a&gt; - &lt;em&gt;Daniel Neil · Michael Pfeiffer · Shih-Chii Liu&lt;/em&gt; - they add a time gate to the LSTM unit, which has a parametrized oscillation frequency, controlling when individual parts of the memory cell can be updated. This allows for irregularly sampled sensor data to be integrated and they demonstrate improved performance on long memory tasks. They also have really nice figures.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1611.00035"&gt;Full-Capacity Unitary Recurrent Neural Networks&lt;/a&gt; - &lt;em&gt;Scott Wisdom · Thomas Powers · John Hershey · Jonathan Le Roux · Les Atlas&lt;/em&gt; - this is pretty relevant for/similar to my &lt;a href="https://arxiv.org/abs/1607.04903"&gt;recent work&lt;/a&gt;, so I'm going to read this paper in detail later. My initial thought upon seeing the poster is that they have some &lt;em&gt;really unnecessary&lt;/em&gt; mathematics in there, which also appears in the manuscript - the entirety of section three in their paper is self-evident. I'm a bit concerned that reviewers might think well-known mathematical facts restated as 'theorems' may constitute novel results. &lt;em&gt;Anyway&lt;/em&gt; cattiness aside, their model is interestingly different to my approach - they optimise on the Stiefel manifold of unitary matrices directly (I optimise in the Lie algebra), although if you define the Riemannian gradient using inner products on the tangent space, this &lt;em&gt;probably&lt;/em&gt; becomes equivalent in some sense. It requires further analysis. Their results seem quite impressive, although they don't do a comprehensive comparison on the same experiments as &lt;a href="https://arxiv.org/abs/1511.06464"&gt;Arjovsky &amp;amp; Shah&lt;/a&gt;, which are the ones I'm familiar with. I had a nice conversation with one of the authors at the poster, which is really what conferences are about.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1608.05745"&gt;RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism&lt;/a&gt; - &lt;em&gt;Edward Choi · Mohammad Taha Bahadori · Joshua Kulas · Jimeng Sun · Andy Schuetz · Walter Stewart&lt;/em&gt; - their focus here is to have an &lt;em&gt;interpretable&lt;/em&gt; model, so the evidence used to make a decision is easily identified. They achieve this using an attention mechanism where the recurrence is on the &lt;em&gt;attention mechanism&lt;/em&gt;, not on the hidden state. I'm not sure why RNNs should be seen as intrinsically uninterpretable (you can get gradients of cost with respect to any input, for example), so I'm going to think about this more. Interpretability is crucial for any medical applications.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a name="law"&gt;&lt;/a&gt;Machine Learning and the Law Symposium&lt;/h2&gt;
&lt;p&gt;I was and remain to be confused by the choice of symposia. The options were: Deep Learning, Recurrent Neural Networks, and ML and the Law. RNNs aren't deep? What was the DL symposium covering? Deep but Not Recurrent Learning? Weight-Sharing Is OK but Not Over Time, Never Over Time? As evidenced by the title of this section, I didn't attend either of them, and I also didn't attend enough of the Counterfactual Reasoning workshop on Saturday to say what would have happened if I had gone to them, but there seems to be a naming/scope issue here. Whatever it was, the RNN Symposium was Hot Shit and had to switch rooms with us ML+Law people during the lunch break. As soon as the room change was announced, people started appearing at the fringes of the Law symposium and may have been inadvertently exposed to some meta-ethics. I'm not sure how this planning error occurred - it is natural to assume that most of the growth in NIPS attendance is coming from &lt;em&gt;DEEP LEARNING&lt;/em&gt;, which should (??) include RNNs, so that symposium was likely to be popular. Maybe they thought enough people would go to the &lt;em&gt;other&lt;/em&gt; DL symposium.&lt;/p&gt;
&lt;p&gt;The real question is - did non-DL non-justice machine learners feel cheated of a symposium? Am I wrong to try to place the RNN symposium inside the DL one?&lt;/p&gt;
&lt;p&gt;Having just published a &lt;a href="https://arxiv.org/abs/1607.04903"&gt;paper (arguably) about RNNs&lt;/a&gt;, I &lt;em&gt;should&lt;/em&gt; have gone to the RNN symposium, but I can't resist thinking about the broader social impact of machine learning. I've also found myself thinking about morality and justice (and therefore law) more than usual lately, so I had to attend this. Discussions of normative ethics at a machine learning conference? Yes.&lt;/p&gt;
&lt;p&gt;I'd consider this symposium a law-oriented follow-on to the 'Algorithms Among Us: the Societal Impacst of Machine Learning' symposium at NIPS 2015 (see my summary &lt;a href="ml/2015-12-14-nips2015.html"&gt;here&lt;/a&gt;. Having a focus is good. The impacts of machine learning on society are widespread, so trying to cover too many all forces a shallower treatment. High level talk is well and good, but &lt;em&gt;getting stuff done&lt;/em&gt; requires being specific. This is actually a point that was raised during one of the panel discussions: how do we balance the need in computational science to formulate very specific, quantified definitions of things (like discrimination) with the requirement of margin of interpretation in law? I was surprised, as a non-lawyer, to hear that such ambiguity could be tolerated, much less &lt;em&gt;desired&lt;/em&gt;. The example given for this was in discussions where compromise may only be attained through baking some ambiguity into an agreement, which would then (I suppose) later be argued over as necessary. This leads to another point which was made - law is not a monolith, laws are not absolute immutable statements - law is a &lt;em&gt;process&lt;/em&gt;, an argumentative tradition (at least in the US), evolving and iterating and requiring justification at all times (get it - &lt;em&gt;justice pun&lt;/em&gt;!). How to integrate algorithms into this process is not as simple as treating them as Truth Functions (shout out to my main man Wittgenstein) on Evidence ... &lt;em&gt;or is it?&lt;/em&gt; I get ahead of myself.&lt;/p&gt;
&lt;h3&gt;Legal Perspectives&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.iankerr.ca/"&gt;Ian Kerr&lt;/a&gt;, &lt;em&gt;Learned justice: prediction machines and big picture privacy&lt;/em&gt;. The 'learned' in the title is partially a reference to the US judge &lt;a href="https://en.wikipedia.org/wiki/Learned_Hand"&gt;Learned Hand&lt;/a&gt; (&lt;em&gt;what a name&lt;/em&gt;). A quote from him, "If we are to keep our democracy, there must be one commandment: Thou shalt not ration justice". As an example of a 'learned AI' he mentioned &lt;a href="www.donotpay.co.uk/"&gt;'The World's First Robot Lawyer'&lt;/a&gt;, which helps people generate appeal letters. It's actually a pretty standard chat bot, but it's helped to overturn over 160,000 parking tickets in London and New York, which is a &lt;em&gt;massive&lt;/em&gt; impact ('helping to protecte vulnerable people from state coercion'). What could we do with more powerful algorithms? He then spoke about &lt;em&gt;prediction&lt;/em&gt;, highlighting the links between prediction, preemption, and presumption. This brought us to the &lt;a href="https://en.wikipedia.org/wiki/Prediction_theory_of_law"&gt;prediction theory of law&lt;/a&gt;, an idea coming from the legal scholar &lt;a href="https://en.wikipedia.org/wiki/Oliver_Wendell_Holmes_Jr."&gt;Oliver Wendell Holmes&lt;/a&gt;. This is the idea that 'the law' is simply about predicting what the courts will do, and nothing else. So the study of law is the study of prediction, not morality or anything else. He went on to talk about the 'reasonable expectation of privacy' which is required to understand the scope of the 4th Amendment of the US Constitution. The difficult part is &lt;em&gt;not&lt;/em&gt; defining 'reasonable', but rather 'expectation'. What does this word mean? There are two interpretations: it could be &lt;em&gt;normative&lt;/em&gt;, or &lt;em&gt;predictive&lt;/em&gt;. The US courts have taken the latter stance, and one's 'expectation' of privacy therefore depends on what is &lt;em&gt;possible&lt;/em&gt; with generally-available technology. This is terrifying - if I know my phone microphone is always on, and my phone is at risk of being hacked, do I lose the expectation of privacy whenever my phone is on me?&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.vub.ac.be/LSTS/members/hildebrandt/"&gt;Mireille Hildebrandt&lt;/a&gt;, &lt;em&gt;No Free Lunch&lt;/em&gt;. One particularly pertinent thing she spoke about was 'Data &amp;amp; Pattern Obesitas'. That is, there is a general desire to collect as much data as possible, to look for as many patterns as possible, simply &lt;em&gt;because&lt;/em&gt;. This is dangerous for several reasons, the most obvious of which being that any personal data that is stored is a security risk (looking at you, Big Healthcare Databases). And so she highlighted the importance of &lt;em&gt;salience of purpose&lt;/em&gt;, citing the security adage of 'select before you collect'. I think this idea likely goes against the inclinations of many researchers in machine learning/data science, who would rather grab everything, and do some sort of automated relevance detection later. This may be fine in certain domains, but when the data you're operating on is sensitive in some way, it can be fatal.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Prediction_theory_of_law"&gt;Deirdre Mulligan&lt;/a&gt; - &lt;em&gt;Governance and Machine Learning&lt;/em&gt;: there was not &lt;em&gt;so much&lt;/em&gt; machine learning in this talk, but she spoke about various ways technology and governance interact. Voting machines are one obvious place (and topical!). She spoke about how electronic voting systems failed to reproduce the traditional voting system. In pen-and-paper voting, the ballot is a physical artefact of the vote, but in these systems, apparently it was rendered on the fly and not saved. There was no storage of the ballot image, it simply incremented a counter somewhere in the backend. This is obviously a terrible system, but these machines were closed-source (!?!?!), so I guess nobody realised they were working like this until they reverse-engineered them? The mind boggles. Other examples are automobiles - you can hack them (like everything on the IoT), they were avoiding regulation (Volkswagen), product safety was compromised by software updates. The last case highlights the need for certification and verification of post-purchase software updates. If you want to run Windows XP on your computer that's your own business, but unsafe cars (from either software or hardware) are public safety risks.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Technical Perspectives&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.cis.upenn.edu/~aaroth/"&gt;Aaron Roth&lt;/a&gt;: &lt;em&gt;Quantitative tradeoffs between fairness and accuracy in machine learning&lt;/em&gt; - Rawls provides a definition of fairness, which is "fair equality of opportunity", which he formalised using a 'discrimination index' - the probability of victimisation (not being selected despite being the most qualified, I &lt;em&gt;think&lt;/em&gt;) conditional on being present at a bad round (a round in which a sub-optimal applicant is selected). This was all formulated in a contextual bandit setting, and he described an algorithm called 'fairUCB' (from UCB - upper confidence bound, a standard bandit algorithm) and gave its regret bound.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://people.mpi-sws.org/~gummadi/"&gt;Krishna P. Gummadi&lt;/a&gt;: &lt;em&gt;Measures of fairness, and mechanisms to mitigate unfairness&lt;/em&gt; - the focus here was on &lt;em&gt;discrimination&lt;/em&gt;, which is a specific kind of unfairness. So what is discrimination? A definition is "wrongfully imposing relative disadvantage based on membership in socially salient groups". One could ask what most of these terms mean &lt;em&gt;exactly&lt;/em&gt; (and indeed, we must, if we want to computationally model anything), but he focused on the phrase "based on". Some attributes are sensitive, and some are not. Can you simply ignore them? The problem is that, people in different sensitive attribute groups may have &lt;em&gt;different&lt;/em&gt; non-sensitive feature distributions, which risks disparate mistreatment and disparate impact. One can test disparity of impact through, for example, proportionality tests, e.g. "an 80% rule" - if 50% of men are accepted, then 40% of women should too. And a shout-out to &lt;a href="http://www.fatml.org/"&gt;Fairness, Accountability and Transparency in ML&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There were more talks, but I was drifting into the semi-delirious pre-fever stages of the Conference Flu at this point.&lt;/p&gt;
&lt;h3&gt;Panel Discussions&lt;/h3&gt;
&lt;p&gt;The discussion spotlight was 'Regulation by Machine' from &lt;a href="http://www.law.utoronto.ca/faculty-staff/full-time-faculty/benjamin-alarie"&gt;Benjamin Alarie&lt;/a&gt;. A question - how to use AI to make better laws? My notes are sparse but a recurring theme (also in MLHC) is that we should use machine learning to &lt;em&gt;help and augment&lt;/em&gt; humans, not to replace them. So he was speaking about using ML to - for example - help to predict if it's 'worth' taking a case to court. Apparently many cases go to court which are 'overdetermined given the facts', and it's somewhat easy (citation needed) for an algorithm to identify which these are.&lt;/p&gt;
&lt;p&gt;My notes on the actual panel are &lt;em&gt;sketchy at best&lt;/em&gt;. It may have been the time or how sick I was but, it felt like people were saying a lot of interesting things without obvious argumentative structure or direction, so it's hard to summarise any &lt;em&gt;salient points&lt;/em&gt;. Here are some decontextualised, paraphrased snippets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deirde Mulligan: the judicial system is not always about applying the same law the same way. You must know the facts, the context... The law wants you to come in and argue about what it means. You can go to court to change the law (she asked how many people had been to court - a couple raised their hands - I've only been to court as a juror). Any algorithm for the law must be both performative and output-focused.&lt;/li&gt;
&lt;li&gt;Neil Lawrence: how do judges come to opinions? Also, "I don't want to talk too much as I'm not on the panel."&lt;/li&gt;
&lt;li&gt;??? (unknown panel member) - we're assuming the law will furnish us with specific definitions, but actually, policies breed on, thrive on, require a lack of specificity and precision - ambiguity is &lt;em&gt;not&lt;/em&gt; an accident!&lt;/li&gt;
&lt;li&gt;Ian Kerr: &lt;a href="https://en.wikipedia.org/wiki/Paul_the_Octopus"&gt;Paul the Octopus&lt;/a&gt; was highly accurate, but does that mean we should trust it?&lt;/li&gt;
&lt;li&gt;Deirde: shout-out to &lt;a href="https://www.nolo.com/"&gt;Nolo press&lt;/a&gt;, making the law easier to understand. Especially important in areas where the cost of fighting something isn't worth it...&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And a final shoutout to &lt;a href="http://robots.law.miami.edu/2014/wp-content/uploads/2013/06/Chief-Justice-John-Roberts-is-a-Robot-March-13-.pdf"&gt;Chief Justice John Roberts is a Robot&lt;/a&gt; - &lt;em&gt;Ian Kerr and Carissima Mathen&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;&lt;a name="mlhc"&gt;&lt;/a&gt;Machine Learning for Healthcare Workshop&lt;/h2&gt;
&lt;p&gt;With the caveat that these are &lt;em&gt;workshop contributions&lt;/em&gt;, here are some interesting papers/posters (with accompanying arXiv papers, so I have a chance to remember anything about them):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1612.02460"&gt;Demographical Priors for Health Conditions Diagnosis Using Medicare Data&lt;/a&gt; - &lt;em&gt;Fahad Alhasoun, May Alhazzani, Marta C. González&lt;/em&gt; - they look at insurance claims data from Brazil over a 15 month period - about 6.6 million visits. They represent ICD-10 codes by their distribution over ages (a 100-dimensional normalised vector) and do clustering on this representation.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1610.08735"&gt;Stratification of patient trajectories using covariate latent variable models&lt;/a&gt; - &lt;em&gt;Kieran R. Campbell, Christopher Yau&lt;/em&gt; - they describe a kind of linear latent variable model taking patient covariates into account, and use it on a TCGA RNAseq dataset.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1611.07663"&gt;Learning Cost-Effective and Interpretable Regimes for Treatment Recommendation&lt;/a&gt; - &lt;em&gt;Himabindu Lakkaraju, Cynthia Rudin&lt;/em&gt; - related (possibly extended version) paper here: &lt;a href="https://arxiv.org/abs/1610.06972"&gt;Learning Cost-Effective Treatment Regimes using Markov Decision Processes&lt;/a&gt;. The 'interpretability' comes in here because their &lt;em&gt;state space&lt;/em&gt; (of the MDP) consists of the &lt;em&gt;effects&lt;/em&gt; on their patient population of decision lists - ordered lists of rules, each consisting of tuples of predicates (like, properties a patient must fulfill) and actions.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1612.01055"&gt;Modeling trajectories of mental health: challenges and opportunities&lt;/a&gt; - &lt;em&gt;Lauren Erdman, Ekansh Sharma, Eva Unternahrer, Shantala Hari Dass, Kieran ODonnell, Sara Mostafavi, Rachel Edgar, Michael Kobor, Helene Gaudreau, Michael Meaney, Anna Goldenberg&lt;/em&gt; - they're interested identifying subtypes of mental illness using time series, and predicting future phenotypic values. They use a Dirichlet Process-Gaussian Process and compare with latent class mixed models, finding that the LCMMs are actually as good as the DP-GP, although neither model is yet good enough for clinical use.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1612.00475"&gt;Transfer Learning Across Patient Variations with Hidden Parameter Markov Decision Processes&lt;/a&gt; - &lt;em&gt;Taylor Killian, George Konidaris, Finale Doshi-Velez&lt;/em&gt; - they're concerned with patient heterogeneity, and cast this as a multitask learning problem, where different tasks are different patients. They share information between tasks using a GP-LVM, removing the requirement to visit every state to learn the dynamics (which is, of course, infeasible in medicine). -&lt;a href="https://arxiv.org/abs/1612.00611"&gt;Predictive Clinical Decision Support System with RNN Encoding and Tensor Decoding&lt;/a&gt; - &lt;em&gt;Yinchong Yang, Peter A. Fasching, Markus Wallwiener, Tanja N. Fehm, Sara Y. Brucker Volker Tresp&lt;/em&gt; - they represent the patient's time series with a LSTM encoder and concatenate the static information into a representation.As a decoder, they use tensor factorisation. I'm not entirely clear on what is actually contained in this tensor, so the paper will need to be read more carefully.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://affect.media.mit.edu/pdfs/16.Jaques-Taylor-et-al-PredictingHealthStressHappiness.pdf"&gt;Multi-task Learning for Predicting Health, Stress, and Happiness&lt;/a&gt; - &lt;em&gt;Natasha Jaques, Sara Taylor, Ehimwenma Nosakhare, Akane Sano, Rosalind Picard&lt;/em&gt; - they have wearable sensors and smartphone logs from 30 days of monitoring. They looked at three multi-task approaches: multi-task multi-kernel learning, hierarchical bayes with Dirichlet process priors, neural networks (sharing hidden layers), and single-task versions of all of these.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mandatory shout-out to my contribution to the workshop: - &lt;a href="https://arxiv.org/abs/1612.00467"&gt;Neural Document Embeddings for Intensive Care Patient Mortality Prediction&lt;/a&gt; - &lt;em&gt;Paulina Grnarova, Florian Schmidt, Stephanie L. Hyland, Carsten Eickhoff&lt;/em&gt; - we used document embeddings to predict patient mortality in MIMIC-III, purely using text notes. The embedding procedure uses two layers of CNNs - word vectors are combined into sentence vectors (with a CNN), and sentence vectors are combined into patient vectors (with a CNN), and we use target replication to improve predictive accuracy. This was fairly preliminary (there are many other factors to consider, as ever), but we beat previous work using topic modelling on the task, which is encouraging, and perhaps unsurprising given LDA's inability to deal with multi-word phrases.&lt;/p&gt;
&lt;p&gt;This is only a snippet of the interesting work presented at the workshop. I unfortunately came down with Conference Flu about half way through NIPS, and was at my sickest during the MLHC workshop (ironically), so I didn't get to speak to as many poster presenters as I would have liked.&lt;/p&gt;
&lt;h2&gt;&lt;a name="misc"&gt;&lt;/a&gt;Miscellaneous Comments/Observations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Generative Adversarial Networks are super hot right now, and by saying this I am contributing to the hype.&lt;/li&gt;
&lt;li&gt;Despite having around 6000 attendees, NIPS didn't feel overcrowded (contrast with ICML this year). I'm guessing this was a combination of having an appropriately-sized venue and good crowd-control from the venue staff (they were closing off the top floor when it got too full), or maybe everyone was just busy enjoying Barcelona.&lt;/li&gt;
&lt;li&gt;Being a vegetarian in Spain sucks. Given my diet was largely eggs, potatoes and bread for the week, I feel sorry for the vegans in the NIPS community. I for one devolved into a patatas-bravas guzzling monster and don't want to even think about tapas for the foreseeable future.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a name="conclusion"&gt;&lt;/a&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I feel less obviously exuberant about NIPS than I did last year, which I attribute to a combination of having been (and continuing to be somewhat) ill, and being in the development stage of several new projects where I just want to be &lt;em&gt;getting stuff done&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As I've mentioned before, I think about approaching research in an exploration-exploitation framework. At this NIPS I realised that even within the exploration mode, one can explore exploitatively. That is, you can distinguish between diversity-increasing exploration (seeing areas of the state space/field you've never been in before) and depth-increasing exploration (refining your knowledge of partially-explored states/topics). The latter is arguably a kind of exploitation, because it's exploration with the aim to increase knowledge of things you are &lt;em&gt;intending&lt;/em&gt; to use later. You hope.&lt;/p&gt;
&lt;p&gt;Bringing this strained analogy back to conferences, this makes the difference between going to talks on things you already sort of know and going to &lt;em&gt;totally new&lt;/em&gt; topics. I tried a bit of the latter, because chances are I'm going to read papers relevant to me &lt;em&gt;regardless&lt;/em&gt;, but I found spotlight talks suboptimal for learning new ideas without sufficient background knowledge. An alternative approach would be to be incredibly exploitative, pre-emptively read the relevant papers and then talk to the authors at the poster sessions. Perhaps next year I'll be organised enough to do that, because unless you go to the tutorials, 15-minute talks of questionable presentation quality on cutting edge research are not good ways to learn new topics.&lt;/p&gt;
&lt;p&gt;What &lt;em&gt;is&lt;/em&gt; a good way to learn a new topic (personally), is to write about it. I've been working on a pedagogical post about sparse Gaussian process classification, which will be up next, after a brief diversion into roller derby.&lt;/p&gt;</content><category term="ml"></category><category term="nips"></category><category term="conference"></category><category term="barcelona"></category><category term="spain"></category><category term="AI"></category><category term="MLHC"></category><category term="law"></category></entry><entry><title>ICML 2016 not by the day</title><link href="ml/2016-07-05-icml2016.html" rel="alternate"></link><published>2016-07-05T00:00:00+01:00</published><updated>2016-07-05T00:00:00+01:00</updated><author><name>corcra</name></author><id>tag:None,2016-07-05:ml/2016-07-05-icml2016.html</id><summary type="html">&lt;p&gt;The &lt;a href="icml.cc"&gt;International Conference on Machine Learning (ICML)&lt;/a&gt; was in NYC this year! Unfortunately(?) for me, I moved from NYC to Zürich two months ago. Fortunately for me, I was able to return to attend the conference. Instead of doing a day-by-day breakdown (as I did for &lt;a href="ml/2015-12-14-nips2015.html"&gt;NIPS&lt;/a&gt; and &lt;a href="ml/2016-02-17-aaai2016.html"&gt;AAAI&lt;/a&gt;), this …&lt;/p&gt;</summary><content type="html">&lt;p&gt;The &lt;a href="icml.cc"&gt;International Conference on Machine Learning (ICML)&lt;/a&gt; was in NYC this year! Unfortunately(?) for me, I moved from NYC to Zürich two months ago. Fortunately for me, I was able to return to attend the conference. Instead of doing a day-by-day breakdown (as I did for &lt;a href="ml/2015-12-14-nips2015.html"&gt;NIPS&lt;/a&gt; and &lt;a href="ml/2016-02-17-aaai2016.html"&gt;AAAI&lt;/a&gt;), this post will be arranged thematically. Let's see how I deal with the hard group assignment problem... Skip to the bit you care about.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Caveats&lt;/em&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I missed some non-trivial fraction of ICML due to finishing my poster, helping collaborators with a grant application, and coming down with illness&lt;ul&gt;
&lt;li&gt;Future conference goal: finish my poster &lt;em&gt;before&lt;/em&gt; I travel. &lt;/li&gt;
&lt;li&gt;Also don't try to print A0 posters in the USA. It ain't pretty.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;I took very patchy notes, haven't read all the papers deeply.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Volunteering at ICML&lt;/h2&gt;
&lt;p&gt;I was a student volunteer for ICML, which consisted of working two ~five-hour shifts at the conference. For me these were both Registration Desk. I had 07.30-12.30 on the first and last days, which was possible purely by my being in European time for much of the trip. I woke up at 4am on the first day. Here are some observations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;people actually register on the last day,  but more people just want to get their badge reprinted&lt;ul&gt;
&lt;li&gt;protip: don't forget your name badge!&lt;/li&gt;
&lt;li&gt;you paid hundreds of dollars to get that piece of paper&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;some people turn up really early to register&lt;/li&gt;
&lt;li&gt;90% of ICML attendees were DeepMind employees&lt;/li&gt;
&lt;li&gt;registration desk workers could easily be replaced by name-badge-printing kiosks&lt;/li&gt;
&lt;li&gt;conference attendees expect a pile of swag upon registration: pens and bags and mugs and programs booklets. Not receiving these items is cause for thinly-veiled indignation&lt;/li&gt;
&lt;li&gt;queues for registration are worst in the gap between sessions, naturally&lt;/li&gt;
&lt;li&gt;people manage to make it to the top of a line without attempting to find the documents they need&lt;ul&gt;
&lt;li&gt;I have also observed this phenomenon in airports and banks&lt;/li&gt;
&lt;li&gt;why&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;I registered a bunch of people whose papers I have read, and I maintained composure&lt;/li&gt;
&lt;li&gt;if I were running the registration desk with excessive time to spare, we would have had a graph of cumulative registrations over time, maybe with a breakdown for geographic origin/broad affiliation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall it was surprisingly fun. Apparently I rather enjoy that kind of work, so if this whole research thing doesn't work out I have a bright future as a vending machine.&lt;/p&gt;
&lt;h2&gt;Tutorial on Deep Reinforcement Learning&lt;/h2&gt;
&lt;p&gt;I was only able to attend one tutorial due to volunteering, and it was Deep RL. It was so popular there were &lt;em&gt;two&lt;/em&gt; overflow rooms. Intense community interest in deep RL continues. Here's an abbreviated version:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/__hylandSL/status/744602517275803648"&gt;&lt;img src="images/icml2016_deeprl.png" style="width: 40vw;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The deep part comes into play when you use a deep neural network to approximate your value function, policy, environment etc.&lt;/p&gt;
&lt;h2&gt;Interesting Papers/Talks&lt;/h2&gt;
&lt;p&gt;These are the papers I flagged in the conference app. Did I attend all of these talks? No. Did I attend all of the posters? Also no. In hopefully-meaningful categories:&lt;/p&gt;
&lt;h3&gt;Neural Networks&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/lie16.pdf"&gt;Learning to Generate with Memory&lt;/a&gt;: &lt;em&gt;Chongxuan Li, Jun Zhu, Bo Zhang&lt;/em&gt;: a deep generative model with external memory and attention mechanism. The deepness comes in through some nonlinear functions on latent variables which are defined by (deterministic) deep neural networks. Each layer in the network has access to its own external memory, which is seemingly novel in this model. In each layer lower-layer information is combined with the memory to produce the output, using some attention function taking as input the information from the lower layer. I'm not entirely convinced by the experiments that the memory mechanism actually helps that much, although they say it gives better 'qualitative' results.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/arjovsky16.pdf"&gt;Unitary Evolution Recurrent Neural Networks&lt;/a&gt;: &lt;em&gt;Martin Arjovsky, Amar Shah, Yoshua Bengio&lt;/em&gt;: The idea here is to use a unitary matrix as the evolution operator in an RNN, with a hope to avoid exploding gradients. It seems to result in an RNN which can retain information for longer than a LSTM, and while gradients do vanish slowly, they do so more slowly than other models, and don't explode. I'm working on something of an extension to this work right now, and I had the pleasure of speaking with the authors at length. More details in forthcoming paper, I guess? Or blog post, we'll see.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/balduzzi16.pdf"&gt;Strongly-Typed Recurrent Neural Networks&lt;/a&gt;: &lt;em&gt;David Balduzzi, Muhammad Ghifary&lt;/em&gt;: I really like the spirit of this work. Let's try to understand RNNs! And take inspiration from functional programming and physics, because why not? The physics part is roughly to preserve 'dimensions' (think units) by preserving the &lt;em&gt;basis&lt;/em&gt; of the space. I took issue with this because I think any map from a space to itself is already preserving something (preserving being in the space, that is), but what that means for the model is less clear. The part from functional programming is about separating state and computation, a separation into &lt;em&gt;learnware&lt;/em&gt; (with parameters) and &lt;em&gt;firmware&lt;/em&gt; (having no parameters, but having state).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/cohenc16.pdf"&gt;Group Equivariant Convolutional Networks&lt;/a&gt;: &lt;em&gt;Taco Cohen, Max Welling&lt;/em&gt;: Wild simplification/mild understatement: they extend convolutional layers to other kinds of symmetries, not just translational.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/taylor16.pdf"&gt;Training Neural Networks Without Gradients: A Scalable ADMM Approach&lt;/a&gt;: &lt;em&gt;Gavin Taylor, Ryan Burmeister, Zheng Xu, Bharat Singh, Ankit Patel, Tom Goldstein&lt;/em&gt;:  ADMM stands for Alternating Direction Method of Multipliers. They use this with Bregman iteration to train networks &lt;em&gt;without SGD&lt;/em&gt;! This method scales linearly over cores, and they compare this to an asynchronous SGD model called Downpour, which scales very strangely. SGD, having &lt;em&gt;many&lt;/em&gt; small computations is good for GPUs, whereas CPUs are better for a smaller number of &lt;em&gt;expensive&lt;/em&gt; calculations, preferably involving a lot of data. This approach also combats the vanishing gradient problem (unsurprising given there are no gradients to vanish: gradients come pre-vanished), and SGD's tendency towards lingering near saddle-points.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Reinforcement Learning / Bandits&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/he16.pdf"&gt;Opponent Modeling in Deep Reinforcement Learning&lt;/a&gt;: &lt;em&gt;He He, Jordan Boyd-Graber, Kevin Kwok, Hal Daume III&lt;/em&gt;: They develop a model called DRON: Deep Reinforcement Opponent Network, which is close enough to TRON to make me happy. It's based on Mnih's deep Q-networks. DRON has both policy-learning module and opponent-learning module. It's essentially two networks, and they look at ways of combining them: concatenation and using mixtures-of-experts.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/simsek16.pdf"&gt;Why Most Decisions Are Easy in Tetris—And Perhaps in Other Sequential Decision Problems, As Well&lt;/a&gt;: &lt;em&gt;Ozgur Simsek, Simon Algorta, Amit Kothiyal&lt;/em&gt;: by 'easy' they mean: "one can choose well among the available actions without knowing an evaluation function that scores well in the game". The idea is that comparison becomes easy when some criteria are met, and the relationship between features and criterion (of the comparison) is linear. This linearity requirement seems restrictive, but holds true for the best known tetris player (BCTS).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/le16.pdf"&gt;Smooth Imitation Learning for Online Sequence Prediction&lt;/a&gt;: &lt;em&gt;Hoang Le, Andrew Kang, Yisong Yue, Peter Carr&lt;/em&gt;: They're looking at imitation learning where actions and the environment are continuous, but the environment is exogenous (not affected by actions). They consider the state space to be both environment and actions (so the policy considers the previous action taken), and enforce smoothness of &lt;em&gt;actions&lt;/em&gt;. The application is smooth camera control (the paper is from Disney research), hence smooth actions. Their approach learns a fully deterministic stationary policy, and they have some other contributions whose gravity are somewhat lost on me, but are presumably important.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/mniha16.pdf"&gt;Asynchronous Methods for Deep Reinforcement Learning&lt;/a&gt;: &lt;em&gt;Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu&lt;/em&gt;: As an alternative to experience replay, they asychronously run multiple agents in different instances of the environment, in parallel. This can then be run on a multi-core CPU rather than a GPU, and is more resource efficient. Some nice ggplots, too.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/wu16.pdf"&gt;Conservative Bandits&lt;/a&gt;: &lt;em&gt;Yifan Wu, Roshan Shariff, Tor Lattimore, Csaba Szepesvári&lt;/em&gt;: a multi-armed bandit problem where a company wants to maximise revenue while keeping revenue above a constant baseline. In this setting there exists a 'conservative default action', and they propose an extension to UCB (upper confidence bound) where a budget is accumulated using the conservative arm, and when large enough allows for 'safe' exploration.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Representation Learning&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/steeg16.pdf"&gt;The Information Sieve&lt;/a&gt;: &lt;em&gt;Greg Ver Steeg, Aram Galstyan&lt;/em&gt;: What an intriguing title. This is about representation-learning. The idea seems to be to iteratively 'sieve' the data, extracting a latent feature at a time, then passing on a version of the data with the contribution from that feature somehow removed, and so on. Sieving. It relies on the total correlation, or multivariate mutual information, and they describe a way for finding the factors which cause this total correlation to decompose into non-negative contributions.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/trouillon16.pdf"&gt;Complex Embeddings for Simple Link Prediction&lt;/a&gt;: &lt;em&gt;Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, Guillaume Bouchard&lt;/em&gt;: a scoring function for link prediction (subject, predicate, object type triples) which uses &lt;em&gt;complex&lt;/em&gt;-valued embeddings for entities. Using the inner product in complex space amounts to taking dot products with complex conjugates, which handles asymmetry of the triples. The relationships appear to be parametrised with complex-valued vectors. At a glance it looks like a complex version of DistMult.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Other / ???&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/yoon16.pdf"&gt;ForecastICU: A Prognostic Decision Support System for Timely Prediction of Intensive Care Unit Admission&lt;/a&gt;: &lt;em&gt;Jinsung Yoon, Ahmed Alaa, Scott Hu, Mihaela van der Schaar&lt;/em&gt;: the application here is predicting when/if a patient needs to be admitted to the ICU. They cast it as an optimal stopping problem, and try to learn the unknown stopping rule of the stochastic process: how the physician decides (on the basis of the stream of data) to admit the patient to ICU. They assume patients belong to 'stable' or 'deteriorating' classes, which describe different distributions over physiological streams.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/gal16.pdf`"&gt;Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning&lt;/a&gt;: &lt;em&gt;Yarin Gal, Zoubin Ghahramani&lt;/em&gt;: I'm not going to give this paper justice by skim-summarising it, so I'll just quote a sentence: _"In this paper we give a complete theoretical treatment of the link between Gaussian processes and dropout, and develop the tools necessary to represent uncertainty in deep learning". Cool cool cool.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/gilad-bachrach16.pdf"&gt;CryptoNets: Applying Neural Networks to Encrypted Data with High Throughput and Accuracy&lt;/a&gt;: &lt;em&gt;Ran Gilad-Bachrach, Nathan Dowlin, Kim Laine, Kristin Lauter, Michael Naehrig, John Wernsing&lt;/em&gt;: Homomorphic encryption! Homomorphic encryption only allows for addition and multiplication, and ideally with low-degree polynomials, so they have to approximate the usual max pool, sigmoid etc. transformations. One also has to be careful as all operations in the cryptosystem are applied modulo some number. A key thing to note here is that they're not &lt;em&gt;training&lt;/em&gt; on encrypted data, just predicting.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v48/bauer16.pdf"&gt;The Arrow of Time in Multivariate Time Series&lt;/a&gt;: &lt;em&gt;Stefan Bauer, Bernhard Schölkopf, Jonas Peters&lt;/em&gt;: Non-Gaussian noise breaks time symmetry in multivariate autoregressive moving average (VARMA) models.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;a href="https://sites.google.com/site/gimliworkshop/"&gt;Geometry in Machine Learning Workshop&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Is the title of this workshop an &lt;em&gt;intentional&lt;/em&gt; Lord of the Rings reference? I sure hope so.&lt;/p&gt;
&lt;p&gt;I spent the whole day at this workshop, since I was presenting a poster and also &lt;em&gt;yay differential geometry&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;So why care about geometry for machine learning? Firstly, by geometry we're talking about &lt;em&gt;differential&lt;/em&gt; geometry, which is focused on differentiable manifolds (manifolds which &lt;em&gt;locally&lt;/em&gt; look flat). Data &lt;em&gt;usually&lt;/em&gt; lies on a manifold. We often assume this manifold is Euclidean space (nice and flat), but it often isn't. A simple example is data which lies on a &lt;em&gt;circle&lt;/em&gt;, which if you've encountered if you've ever dealt with angular measurements. &lt;a href="http://me.jhu.edu/faculty/gregory-s-chirikjian/"&gt;Gregory S. Chirikjian&lt;/a&gt; gave a really nice illustrating example in his talk "Learning and Lie Groups": if you consider the range of motions available to a simple noisy robot, after a certain number of steps its possible location will be given by some probability distribution (this is called the 'banana distribution'). This distribution is &lt;em&gt;not&lt;/em&gt; Gaussian in &lt;em&gt;x&lt;/em&gt; and &lt;em&gt;y&lt;/em&gt; (the coordinates of the Euclidean manifold a.k.a. the plane the robot was moving on), but if you recall that its motions were constrained to come from a Lie group (specifically the planar special Euclidean group, SE(2), consisting of translations and rotations in the plane), you can define a Gaussian distribution relative to coordinates in &lt;em&gt;that&lt;/em&gt; group space (since Lie groups are manifolds), and &lt;em&gt;this&lt;/em&gt; distribution describes its location. For more details, see the paper: &lt;a href="http://www.roboticsproceedings.org/rss08/p34.pdf"&gt;The Banana Distribution is Gaussian: A Localization Study in Exponential Coordinates&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Reasons to be careful when your data lies on a manifold seem to be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;doing statistics requires a notion of distance, so you must use the distance &lt;em&gt;on the manifold&lt;/em&gt;  &lt;/li&gt;
&lt;li&gt;gradient-based optimisation requires, well, gradients, so you must use the gradient &lt;em&gt;on the manifold&lt;/em&gt;  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This second point is actually highly relevant to the work I was presenting at the workshop, which will become entirely clear once I put the paper on the arXiv.&lt;/p&gt;
&lt;p&gt;I think machine learning as a field already cares about manifolds a lot, particularly when it comes to finding low-dimensional subspaces within a dataset. This workshop was however primarily concerned with cases where the (sub-)manifold is already known.&lt;/p&gt;
&lt;p&gt;And now, the content: (also, you can get the slides for these talks on the &lt;a href="https://sites.google.com/site/gimliworkshop/schedule"&gt;workshop page&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://web.math.princeton.edu/~nboumal/"&gt;Nicolas Boumal&lt;/a&gt; spoke about &lt;strong&gt;Optimisation on Manifolds&lt;/strong&gt;. &lt;a href="https://web.math.princeton.edu/~nboumal/papers/boumal_optimization_and_estimation_on_manifolds_phd_thesis.pdf"&gt;Here&lt;/a&gt; is his PhD thesis on the topic. The take-homes were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we have some convergence guarantees for non-convex optimisation on manifolds, see the paper: &lt;a href="https://arxiv.org/abs/1605.08101"&gt;Global rates of convergence for nonconvex optimisation on manifolds&lt;/a&gt;, &lt;em&gt;Boumal, Absil and Cartis&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;he has developed a Matlab toolbox for optimisation on manifolds: &lt;a href="http://www.manopt.org"&gt;Manopt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;free book, &lt;a href="http://press.princeton.edu/chapters/absil/"&gt;Optimization Algorithms on Matrix Manifolds&lt;/a&gt;,  &lt;em&gt;Absil, Mahony, Sepulchre&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://web.eecs.umich.edu/~girasole/"&gt;Laura Balzano&lt;/a&gt; spoke about &lt;strong&gt;Subspace Learning by Incremental Gradient Descent on the Grassmannian&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the Grassmannian is a manifold comprised of all low-dimensional subspaces of a particular ambient space, I believe with a pre-specified dimension (so it could be the space of all lines, for example)&lt;/li&gt;
&lt;li&gt;her focus area is streaming data, where you want to use first-order methods (not enough data to estimate hessians, for example)&lt;/li&gt;
&lt;li&gt;doing SVD where the learned matrices are elements of the Grassmannian (that is, living in a lower-dimensional space), so gradients are on the Grassmannian&lt;/li&gt;
&lt;li&gt;more details probably in this paper: &lt;a href="http://arxiv.org/abs/1506.07405"&gt;Global Convergence of a Grassmannian Gradient Descent Algorithm for Subspace Estimation&lt;/a&gt;, &lt;em&gt;Zhang &amp;amp; Balzano&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;also featuring a live demonstration of separating foreground from background in video! using a laptop and a webcam! More here: &lt;a href="http://arxiv.org/abs/1309.6964"&gt;Online Algorithms for Factorization-Based Structure from Motion&lt;/a&gt; - &lt;em&gt;Kennedy, Balzano, Wright, Taylor&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://me.jhu.edu/faculty/gregory-s-chirikjian/"&gt;Gregory S. Chirikjian&lt;/a&gt; spoke about &lt;strong&gt;Learning and Lie Groups&lt;/strong&gt; as I mentioned above:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;paper again; &lt;a href="http://www.roboticsproceedings.org/rss08/p34.pdf"&gt;The Banana Distribution is Gaussian: A Localization Study in Exponential Coordinates&lt;/a&gt;, &lt;em&gt;Long, Wolfe, Mashner, Chirikjian&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;also a book (although not free ;_;): &lt;a href="http://www.springer.com/us/book/9780817648022"&gt;Stochastic Models, Information Theory, and Lie Groups&lt;/a&gt;, &lt;em&gt;Chirikjian&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://www.sci.utah.edu/~fletcher/"&gt;Tom Fletcher&lt;/a&gt; spoke about &lt;strong&gt;Probabilistic Geodesic Models&lt;/strong&gt;. The motivation is shape analysis (with a medical application in brains), particularly for dimensionality reduction and regression.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;he gave a nice introduction to the idea of shape: basically, geometry of object invariant of position, orientation, size: when you remove these things you are on the &lt;em&gt;SHAPE MANIFOLD&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Kendall's Shape Space: defined in a complex space. The idea here is that multiplication by a complex value is a rotation and scaling in complex space, so if you 'quotient' that out, you get Kendall's Shape Space, a complex projective space. (and amusingly for me, Projective Geometry is a class I used to sneak into)&lt;/li&gt;
&lt;li&gt;back to the idea that statistics requires a notion of distance, he defined for us the &lt;a href="https://en.wikipedia.org/wiki/Fr%C3%A9chet_mean"&gt;fréchet mean&lt;/a&gt;, allowing points to be 'averaged' on a manifold, and allowing you to define something that looks like a Gaussian-on-a-manifold...&lt;/li&gt;
&lt;li&gt;but a different one than that proposed by Chirikjian, because: there are many ways to arrive at a Gaussian distribution (as a solutions to heat and diffusion equations, as maximum-entropy distributions, the central limit theorem, maximum likelihood solutions to least squares, etc.) and while these seemingly converge on the much-loved Normal distribution in Euclidean space, this doesn't happen on other manifolds... so we end up having 'normal distributions' that look different depending on which definition we started with... oh dear.&lt;/li&gt;
&lt;li&gt;I think it was at this point that someone voiced the concern that in an arbitrary manifold, the distance metric is &lt;em&gt;locally defined&lt;/em&gt; (because it is defined on the tangent space at a point), so the normalisation constant in your Gaussian-on-a-manifold actually depends on the centre of the distribution. The solution to this is to only look at &lt;em&gt;homogeneous manifolds&lt;/em&gt;, manifolds whose isometry group acts transitively, so the manifold 'looks the same' everywhere.&lt;/li&gt;
&lt;li&gt;some homgeneous manifolds: spaces with constant curvature, Lie groups, Stiefel manifolds, Grassmiannians, dot dot dot&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.oasis-brains.org/"&gt;Open Access Series of Imaging Studies (OASIS)&lt;/a&gt;: open access brain (MRI) images!&lt;/li&gt;
&lt;li&gt;then it got into geodesic regression and the manifold of diffeomorphisms, with a shout-out to the &lt;a href="https://en.wikipedia.org/wiki/Sobolev_space"&gt;Sobolev metric&lt;/a&gt;, and a mention of Gaussian processes, thus ensuring my interest was piqued&lt;/li&gt;
&lt;li&gt;generalisation of probabilistic PCA on a Riemannian manifold: &lt;a href="https://www.sci.utah.edu/publications/zhang13/Zhang_NIPS2013.pdf"&gt;Probabilistic Principle Geodesic Analysis&lt;/a&gt;, &lt;em&gt;Zhang and Fletcher&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;another relevant paper: &lt;a href="http://link.springer.com/article/10.1007/s11263-012-0591-y"&gt;Geodesic Regression and the Theory of Least Squares on Riemannian Manifolds&lt;/a&gt;, &lt;em&gt;Fletcher&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://comet.lehman.cuny.edu/stjohn/"&gt;Katherine St. John&lt;/a&gt; spoke about &lt;strong&gt;Dimensionality Reduction on Treespaces&lt;/strong&gt;, specifically evolutionary trees. Hey, biology! Phylogenetics! The core issue is: you see a set of organisms (their genomes, rather) and want to find the optimal evolutionary tree, out of a very very large set of trees. What to do? Metrics on trees usually look at things like rearrangements ("remember balancing red-black trees?"), distances which are NP-hard to compute. I apparently didn't take many notes during this talk, so have some likely-relevant references:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://comet.lehman.cuny.edu/stjohn/research/treespaceReview.pdf"&gt;The Shape of Phylogenetic Trees (Review Paper)&lt;/a&gt;, &lt;em&gt;St John&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://comet.lehman.cuny.edu/stjohn/research/hillClimbing.pdf"&gt;Characterizing Local Optima for Maximum Parsimony&lt;/a&gt;, &lt;em&gt;Urheim, Ford, St. John&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://web.cse.ohio-state.edu/~mbelkin/"&gt;Mikhail Belkin&lt;/a&gt; spoke about &lt;strong&gt;Eigenvectors of Orthogonally Decomposable Functions: Theory and Applications&lt;/strong&gt;. This was partially lost on me, but what I got was:
- we have a well-defined notion of eigenvectors and eigenvalues for matrices, but what of &lt;em&gt;tensors&lt;/em&gt; (multilinear forms)? There's no spectral theorem here, the idea of rank is different, 'things are just sort of unpleasant'
- focusing on orthogonally-decomposable tensors makes things easier (sort of an analogue of eigen-decomposition)
- then the trick is to recover the 'basis' the tensor is orthogonally-decomposable on
- he said this was primarily about work with Rademacher and Voss, so this paper is likely the reference: &lt;a href="http://arxiv.org/abs/1411.1420"&gt;Basis Learning as an Algorithimic Primitive&lt;/a&gt;, &lt;em&gt;Belkin, Rademacher, Voss&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Finally, &lt;a href="http://seat.massey.ac.nz/personal/s.r.marsland/"&gt;Stephen Marsland&lt;/a&gt; spoke about &lt;strong&gt;Principal Autoparallel Analysis: Data Analysis in Weitzenbock Space&lt;/strong&gt;. This talk got into discussion of connections (maps between elements of tangent spaces), and their curvature, and torsion. It had the same effect that looking at my copy of Spivak's 'A Comprehensive Introduction to Differential Geometry' has: excitement to (re)learn these things but the vague guilt of indulgence in intellectually stimulating but &lt;em&gt;maybe&lt;/em&gt; not so directly applicable mathematics. But so cool. Also the sense of having come so close to &lt;em&gt;getting&lt;/em&gt; fibre bundles. One of these days.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;this talk included an entertaining story about the history of Weitzenbocks spaces, Cartan not receiving recognition, and racist messages hidden in books. Forgetting the umlaut in Weitzenböck's name is OK, because he was a racist.&lt;/li&gt;
&lt;li&gt;we usually look at the Levi-Civita connection, which is unique and torsion-free. This one weird non-zero torsion tensor. Mathematicians &lt;em&gt;hate&lt;/em&gt; it!&lt;/li&gt;
&lt;li&gt;intuitive explanation of curvature: the amount you've rotated upon returning to your original position&lt;/li&gt;
&lt;li&gt;intuitive explanation of torsion: the amount you've failed to return to your original position, sort of, or, 'how hard it is to stay on the manifold'&lt;/li&gt;
&lt;li&gt;Riemann-Cartan space reduces to: Riemannian if torsion is 0, and Weitzenbock if curvature is 0&lt;/li&gt;
&lt;li&gt;cryptic statement in my notes: 'prior over tangent spaces?'&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And that's where my notes end.&lt;/p&gt;
&lt;p&gt;The poster session was really good in that I got to speak about my work a lot, but really bad in that it ended before I got to see anyone else's work, or talk much about my work at all. I had so many more things to say! Good thing I have a blog. I'm also working on a manuscript which is very &lt;em&gt;almost&lt;/em&gt; ready to go on the arXiv, honestly.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://sites.google.com/site/icml2016ersonalization/"&gt;Computational Frameworks for Personalisation Workshop&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Mistakes were made. I spent the first quarter of this workshop working the registration desk, and the second quarter standing &lt;em&gt;outside&lt;/em&gt; the workshop. The afternoon I spent at &lt;a href="https://sites.google.com/site/icml2016data4goodworkshop/"&gt;Machine Learning in Social Good Applications&lt;/a&gt;, which was not a mistake (although I arrived too late to get a t-shirt in my size), as I &lt;em&gt;think&lt;/em&gt; I had already seen the work from &lt;a href="http://www.cs.columbia.edu/~blei/"&gt;David Blei's&lt;/a&gt; talk present at the New York Academy of Sciences Machine Learning Symposium.&lt;/p&gt;
&lt;p&gt;The name of the workshop got truncated to 'Computational Frameworks' on the sign outside, so I got to feel vaguely useful providing disambiguation services while trying to glimpse content. &lt;/p&gt;
&lt;p&gt;The content I was most interested in (and managed to catch part of) was &lt;a href="http://cs.mcgill.ca/~jpineau/"&gt;Joelle Pineau&lt;/a&gt; speaking about &lt;strong&gt;Contextual Bandits for Effective Discovery of Personalized Adaptive Treatment Strategies&lt;/strong&gt;. The focus here is on &lt;em&gt;adaptive&lt;/em&gt; protocols, such as adaptive clinical trials or adaptive treatment strategies. In each case, earlier outcomes influence subsequent decisions: it's, you know, adaptive. The computational framework they use is the multi-armed bandit: you have a set of &lt;em&gt;K&lt;/em&gt; actions with probabilistic outcomes. You don't know the outcomes or the probabilities, but you have to select actions to maximise some expected utility. This poses the classic exploration-exploitation trade-off so integral to sequential decision making. Once you discover an 'ok' action, do you choose it repeatedly (exploiting it), or do you attempt to find yet better actions, risking stumbling upon inferior outcomes (exploration)? This also raises questions about whether it's possible to explore 'safely', which was the subject of &lt;a href="https://las.inf.ethz.ch/krausea"&gt;Andreas Krause's&lt;/a&gt; keynote at AAAI this year. &lt;/p&gt;
&lt;p&gt;Back to exploration-exploitation: In adaptive Bayesian trials, they use &lt;a href="https://en.wikipedia.org/wiki/Thompson_sampling"&gt;Thompson Sampling&lt;/a&gt;. This requires having a posterior over models, sampling one and selecting the action with highest expected utility relative to &lt;em&gt;that&lt;/em&gt; model. So you act greedily given your belief (exploiting), but your belief is random (exploring). Another approach is to define an upper confidence bound &lt;a href="http://homes.di.unimi.it/~cesabian/Pubblicazioni/ml-02.pdf"&gt;(Auer 2002)&lt;/a&gt;, where you estimate the confidence of the estimate of the expected utility of an action using how many times the action has been tried, and select arms maximising the estimate + the confidence bound. In this way, you select actions which are either &lt;em&gt;very&lt;/em&gt; good, decent and uncertain, or &lt;em&gt;very&lt;/em&gt; uncertain. The third example in her slides is BESA: Best Empirical Sampled Average &lt;a href="http://link.springer.com/chapter/10.1007/978-3-662-44848-9_8"&gt;(Baranski, Maillard, Mannor, 2014)&lt;/a&gt;, which seems to involve subsampling the arm which has more data, then selecting the one with highest expected reward.&lt;/p&gt;
&lt;p&gt;The specific application was &lt;strong&gt;cancer&lt;/strong&gt;, specifically trying to minimise tumour volume in mice. They did a pure exploration phase, where mice with induced tumours had random treatments of combinations of two drugs (fluorouracil and imiquimod). They then considered the adaptive problem of selecting treatments given the current tumour size. This makes it a &lt;em&gt;contextual&lt;/em&gt; bandit problem. They used Gaussian Processes to model the reward function over the space of continuous contexts (tumour sizes) and arms (discrete treatments). Then, given a specific context, you can select the arm maximising the expected reward, using these earlier-described methods. At this point there's a reference to Durand &amp;amp; Pineau 2015 for the GP extension of BESA but I somehow cannot find it. The idea seems to be to re-estimate the GP using a sub-sample of the data, then using that GP to estimate the maximum expected reward. Preliminary results using the adaptive approach look promising, and they're interested in doing sequential reinforcement learning (rather than bandits) in the future.&lt;/p&gt;
&lt;h2&gt;&lt;a href="https://sites.google.com/site/icml2016data4goodworkshop/"&gt;Machine Learning In Social Good Applications&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I approximately made it to the &lt;strong&gt;Disease&lt;/strong&gt; section of this workshop, which is unfortunate because I would have liked to see &lt;a href="https://arxiv.org/abs/1606.06121"&gt;Quantifying and Reducing Stereotypes in Word Embeddings&lt;/a&gt;, &lt;em&gt;Bolukbasi et al.&lt;/em&gt; I'd consider this under the umbrella task of removing &lt;em&gt;unwanted&lt;/em&gt; patterns from data, or perhaps more accurately, training a model such that it doesn't pick up on these patterns. See also 'racist algorithms' and this &lt;a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"&gt;ProPublica piece on Machine Bias&lt;/a&gt;. Will there be a conference summary where I don't mention Fairness, Accountability and Transparency in Machine Learning? Probably not.&lt;/p&gt;
&lt;p&gt;Anyway, I have an especially strong memory of &lt;a href="http://www.hanlab.science/"&gt;Barbara Han's&lt;/a&gt; talk on &lt;strong&gt;Predicting Novel Tick Vectors of Zoonotic Diseases&lt;/strong&gt;, possibly because it contained many horrifying images of ticks. This work is part a project to use &lt;a href="http://www.caryinstitute.org/science-program/research-projects/machine-learning-predict-zoonotic-disease"&gt;machine learning to predict zoonotic diseases&lt;/a&gt;, and also featured a (iirc) undergraduate researcher! The problem is basically: ticks act as disease vectors, but not all of them carry zoonoses. They mined entomological literature (and maybe other sources) to come up with feature sets for ticks, trained a supervised classifier (if I recall they used boosted regression trees), and predicted novel vectors. They also did some feature analysis to understand what differentiates these classes of tick. It turns out that a strong predictor is the number of hosts the tick feeds on. It seems like this could be confounded with the need to feed on a &lt;em&gt;specific&lt;/em&gt; host (since that host has to be reservoir of the zoonosis), I asked and they hadn't done a breakdown looking at the specific species. Anyway, a straight-forward machine learning task but an important problem in ecology and epidemiology.&lt;/p&gt;
&lt;h2&gt;A Rant about the Venue&lt;/h2&gt;
&lt;p&gt;Times Square is the worst. Times Square is why people hate NYC. Tunnels should be built under Times Square so we never have to look at it. I acknowledge its utility to tourists and I reserve through gritted teeth some respect for their bloody-minded dedication to milling at junctions, drifting absent-mindedly across sidewalks, and stopping suddenly. I just don't enjoy being the person trying to weave between them on my way to lunch, especially when it's summer in NYC and I'm an inappropriately-attired Irishwoman. (We don't do 'direct sunlight' very well.)&lt;/p&gt;
&lt;p&gt;I thought of some reasons to locate a conference on Times Square:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the rest of the world has been destroyed&lt;ul&gt;
&lt;li&gt;Times Square stands alone in the void, a final stand for humanity against the encroaching oblivion&lt;/li&gt;
&lt;li&gt;there is nothing left to do but hold conferences&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;there are no other appropriate venues in New York City&lt;/li&gt;
&lt;li&gt;conferences require a density of hotels only offered by Times Square&lt;/li&gt;
&lt;li&gt;holding a conference in what is probably a &lt;em&gt;very&lt;/em&gt; expensive hotel is a demonstration of power and status&lt;ul&gt;
&lt;li&gt;for... someone. ML researchers maybe? 😎&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The venue itself was interesting because the conference was distributed across multiple floors. This meant lots of using the futuristic elevator system. I was involved in more than one 'what algorithm does this elevator system use' conversation. And hey, here's the &lt;a href="https://webdocs.cs.ualberta.ca/~sutton/book/ebook/node111.html"&gt;chapter of the Sutton Reinforcement Learning book about Elevator Dispatching&lt;/a&gt;.  I wonder how many interesting methods have been developed to solve simple problems arising in the work environment of engineer/scientist types. I certainly used to think about the optimal road-crossing strategy when I lived in NYC (the problem is slightly interesting because east/west and north/south aren't symmetric due to differing block lengths and crossing times, so always going with the go sign isn't an optimal policy[citation required]).&lt;/p&gt;
&lt;p&gt;The negative side-effect of this layout was (to me) a lack of general 'focal point' for the conference, especially since there were various other things going on in the hotel. (Excitingly, on the final day there was an Edward Tufte seminar on the &lt;em&gt;same floor&lt;/em&gt; as us.)&lt;/p&gt;
&lt;p&gt;TL;DR limit registrations to a number your venue can comfortably accommodate. Turning people away is sad (especially if they are, like me, students who only knew they were going once their workshop submission was accepted), but overcrowding is detrimental to good conferencing.&lt;/p&gt;
&lt;h2&gt;In Conclusion&lt;/h2&gt;
&lt;p&gt;Despite missing about half the conference between volunteering, working and being sick, I saw a lot of good work and had some great discussions with people. I'm a bit disappointed there was no proper closing ceremony with summary statistics like at NIPS (unless it was at the party on the Wednesday, which I spent coughing in my hotel room). The multi-track format makes it a little hard to get an overview of the broader field, ad there was a strange lack of closure on the last day. I'd say I'm looking forward to next year, but I &lt;em&gt;think&lt;/em&gt;* it's going to be in Sydney, so we'll see about that.&lt;/p&gt;
&lt;p&gt;*I don't know why I think this and I can't find any evidence supporting it. I did however learn that ICML also stands for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;international conference on minority languages&lt;/li&gt;
&lt;li&gt;international congress of medical librarians&lt;/li&gt;
&lt;li&gt;international conference on chronic myeloid leukaemia&lt;/li&gt;
&lt;li&gt;international conference on malignant lymphoma&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The more you know.&lt;/p&gt;</content><category term="ml"></category><category term="icml"></category><category term="conference"></category><category term="nyc"></category><category term="geometry"></category><category term="reinforcement learning"></category><category term="personalistion"></category></entry><entry><title>AAAI 2016 by the day</title><link href="ml/2016-02-17-aaai2016.html" rel="alternate"></link><published>2016-02-17T00:00:00+00:00</published><updated>2016-02-17T00:00:00+00:00</updated><author><name>corcra</name></author><id>tag:None,2016-02-17:ml/2016-02-17-aaai2016.html</id><summary type="html">&lt;p&gt;I started writing this in Phoenix airport, so if the &lt;a href="ml/2015-12-14-nips2015.html"&gt;current trend&lt;/a&gt; (n=2) continues, I'll start recounting my next conference half-way through, with interesting implications for the latter half of the post. This was my first time attending the Association for the Advancement of Artificial Intelligence Conference &lt;a href="https://www.aaai.org/Conferences/AAAI/aaai16.php"&gt;(AAAI)&lt;/a&gt;, so …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I started writing this in Phoenix airport, so if the &lt;a href="ml/2015-12-14-nips2015.html"&gt;current trend&lt;/a&gt; (n=2) continues, I'll start recounting my next conference half-way through, with interesting implications for the latter half of the post. This was my first time attending the Association for the Advancement of Artificial Intelligence Conference &lt;a href="https://www.aaai.org/Conferences/AAAI/aaai16.php"&gt;(AAAI)&lt;/a&gt;, so I made sure to spend most of it comparing it to NIPS. I stopped taking notes towards the end, so this coverage is a bit skewed.&lt;/p&gt;
&lt;h2&gt;Thursday&lt;/h2&gt;
&lt;p&gt;Shameless plug for a great vegan restaurant in Phoenix: &lt;a href="http://greenvegetarian.com/"&gt;Green&lt;/a&gt;. I would have eaten there a lot more if it were a bit closer to the conference centre. I ended up going to &lt;a href="http://www.veganhouseaz.com/"&gt;Vegan House&lt;/a&gt; a few times. A fair runner up in the list of Best Vegan(-ish) Restaurants in Downtown Phoenix (there are two).&lt;/p&gt;
&lt;h2&gt;Friday&lt;/h2&gt;
&lt;p&gt;Shortly before dawn, it became cold enough to sleep. I appreciated the vastness of the Arizona sky and the eerie absence of fellow pedestrians as I relocated to my downtown hotel. Coming from Dublin and then New York City, I find empty paths unsettling, especially coupled with wide roads and low buildings. I passed by a man selling paintings of owls from a rucksack, and order was restored.&lt;/p&gt;
&lt;p&gt;Friday and Saturday of the conference were tutorial/workshop days (the distinction between these categories is not clear). On Friday morning I went to...&lt;/p&gt;
&lt;h3&gt;&lt;a href="https://www.cs.cmu.edu/~sandholm/organExchangeTutorials/organExchangeTutorial.aaai16.html"&gt;Organ Exchanges: A Success Story of AI in Healthcare: John Dickerson and Tuomas Sandholm&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I'd seen John Dickerson speaking at the &lt;a href="https://sites.google.com/site/nipsmlhc15/"&gt;NIPS 2015 Workshop on Machine Learning in Healthcare&lt;/a&gt; (some thoughts on MLHC in my &lt;a href="https://corcra.github.io/ml/2015/12/14/NIPS2015.html"&gt;NIPS 2015 post&lt;/a&gt;), so I was already somewhat familiar with this work. I think he's a good speaker, so even though this topic is not &lt;em&gt;entirely&lt;/em&gt; relevant to me, I figured I'd get something out of the tutorial. This was true to some extent - my attention started to flag at some point into what was essentially a 3.5 hour lecture.&lt;/p&gt;
&lt;p&gt;The link to the slides is above and &lt;a href="https://www.cs.cmu.edu/~sandholm/organExchangeTutorials/organExchangeTutorial.aaai16.html"&gt;here&lt;/a&gt;, so I will just outline the main idea and skip the algorithmic details.&lt;/p&gt;
&lt;p&gt;Kidney exchanges: you need a kidney, and a family member/friend/loved one is willing to donate one. Unfortunately, they may not be compatible. The solution is to 'trade' donors with someone else: "I'll give you my mother's kidney for your girlfriend's kidney", or, "I'll give you my mother's kidney so your girlfriend can give her kidney to that other person, and their friend can give &lt;em&gt;me&lt;/em&gt; their kidney", and so on. This amounts to finding cycles in a graph (the second example being a 3-cycle), which brings us into the wonderful world of combinatorial optimisation. The exchange actually requires everyone to go under the knife at the same time (something about trading organs I don't quite recall), so there are physical and logistical limits on the length of the cycle.&lt;/p&gt;
&lt;p&gt;They mentioned some other barter-exchange markets, such as&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;holiday homes (&lt;a href="www.intervac-homeexchange.com/"&gt;intervac&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;books (&lt;a href="http://www.paperbackswap.com/index.php"&gt;paperback swap&lt;/a&gt;, &lt;a href="http://www.bookcrossing.com/"&gt;book crossing&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;odd shoes (&lt;a href="http://www.oddshoe.org/"&gt;national (US) odd shoe exchange&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are neat. People exchanging used items instead of buying new/throwing away is obviously great, and I approve of anyone supporting such efforts. It's what the 'sharing economy' should have been... and now back to organs.&lt;/p&gt;
&lt;p&gt;An interesting (and amazing!) thing can happen in these kidney exchanges: sometimes an altruistic donor will show up; someone who just has too many kidneys and wants to help out. These produce 'never-ending altruistic donor' chains ("a gift that gives forever"), and have apparently become more important than cycles for the kidney-matching problem.&lt;/p&gt;
&lt;p&gt;I zoned out of the tutorial for a bit to discuss the feasibility of simultaneous translation, prompted by this article: &lt;a href="http://www.wsj.com/articles/the-language-barrier-is-about-to-fall-1454077968"&gt;The Language Barrier is About to Fall&lt;/a&gt;. My gut reaction is to say 'it's too hard', but that's motivated by my enjoyment of learning languages - part of me (selfishly) doesn't &lt;em&gt;want&lt;/em&gt; this problem solved. I'm however learning to temper my skepticism when it comes to what machine learning can achieve, and we're actually getting pretty good at translation (for &lt;em&gt;some&lt;/em&gt; language pairs) so I'm pretty optimistic about this. And breaking language barriers, if it can be done cheaply, could be immense. I emphasize the relevance of cost because I see language most prohibitive not for holiday-goers but for migrants, who may not have the resources to buy a &lt;a href="https://en.wikipedia.org/wiki/List_of_races_and_species_in_The_Hitchhiker's_Guide_to_the_Galaxy#Babel_fish"&gt;babelfish&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There are a lot of subtleties to consider in the kidney exchange problem, and much work has been done: see the slides.&lt;/p&gt;
&lt;p&gt;They concluded the tutorial with a discussion of other organ exchanges. Kidneys are sort of 'easy' because the cost to the donor is quite minimal, unlike in e.g. lung exchanges where the donor's quality of life (and life expectancy) are impacted. One can also do living donor liver exchanges, where some &lt;em&gt;fraction&lt;/em&gt; of the donor's liver is removed. There are essentially no altruistic donors here. Dickerson suggested combining multiple organs, so you thread a liver and kidney chain together. Perhaps a kidney patient's donor would be willing to donate liver to someone whose donor would give a kidney, and so on.&lt;/p&gt;
&lt;p&gt;My plan was to go to &lt;a href="http://www.inf.kcl.ac.uk/staff/danmag/aaai16tutorial_aips.html"&gt;&lt;strong&gt;AI Planning and Scheduling for Real-World Applications&lt;/strong&gt; (Steve Chien and Daniele Magazzeni)&lt;/a&gt; in the afternoon, but I made the mistake of being outside for slightly too long during lunch, and I spent the rest of the afternoon recovering in a dark and cool hotel room. Irish people: handle with care, keep out of direct sunlight.&lt;/p&gt;
&lt;h3&gt;Student Welcome Reception&lt;/h3&gt;
&lt;p&gt;One really nice thing about AAAI was the student activities. Being a student at a conference can be bewildering: there are so many people who seem to know each other, talking about things they seem to know about! I was also there by myself (my group does not typically attend AAAI), so the icebreakers they ran saved me from spending the rest of the conference lurking in corners and hissing at people.&lt;/p&gt;
&lt;p&gt;The actual ice-breaker activity was weird (although seemingly effective): we had to take photographs with a AI/AAAI/Phoenix theme (artificially intelligent &lt;em&gt;fire&lt;/em&gt;, maybe) featuring ourselves. A ploy to get pictures for a website? Possibly. We never did find out who won the fabled prize.&lt;/p&gt;
&lt;h2&gt;Saturday&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/aaai2016_01.png" class="floatl" style="width: 24vw;"&gt;&lt;/p&gt;
&lt;p&gt;Excluding a brief foray into the tutorial about 'Learning and Inference in Structured Prediction Models', and fruitless wandering in search of coffee shops open on a Sunday, I spent much of the day at...&lt;/p&gt;
&lt;h3&gt;&lt;a href="https://www.cse.unsw.edu.au/~tw/aiethics/AI_Ethics/Introduction.html"&gt;Workshop on AI, Ethics, and Society&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;This workshop had overlap in content/speakers/organisers with the 'Algorithms Among Us' symposium at NIPS 2015 (some thoughts &lt;a href="https://corcra.github.io/ml/2015/12/14/NIPS2015.html"&gt;here&lt;/a&gt;). My interests might be obvious by now.&lt;/p&gt;
&lt;p&gt;This was an interesting workshop. There was a mix of machine learners, AI researchers, (possibly) philosophers and miscellaneous other. There were fewer arguments than I would have expected. It's not that that I particularly &lt;em&gt;wanted&lt;/em&gt; to see (verbal) fighting, but people seem quite passionate about, e.g. whether or not The Singularity is something to worry about, so I expected more gloves on the floor.&lt;/p&gt;
&lt;p&gt;People are concerned about dangerous (powerful) AIs - how do we ensure they don't enslave us all in pursuit of paperclip-making? Do we have moral responsibility towards them? Should they feel pain? Should we be allowed to turn them off, once they're active/alive(?)? Are simulations of humans humans? These were some questions raised.&lt;/p&gt;
&lt;p&gt;Some more, uhh, &lt;em&gt;short-term&lt;/em&gt; concerns included the risks of adversarial machine learning, the effects of AI on labour markets (more on this later), the difficulty of measuring progress towards AGI, and enough other things that I didn't leave the workshop thinking &lt;em&gt;everyone&lt;/em&gt; is feeling Existentially Threatened. I certainly am not. &lt;/p&gt;
&lt;p&gt;I'm glad some people are thinking about long term threats (diversity of tactics!), but I am much more worried about the present and near future. AI (rather machine learning) already influences people, in potentially &lt;a href="http://arstechnica.co.uk/security/2016/02/the-nsas-skynet-program-may-be-killing-thousands-of-innocent-people/"&gt;irreversibly life-altering ways&lt;/a&gt; (to put it mildly), and I fear the technology is becoming integrated into society faster than anyone can measure its harm (see also: vaping). It's also quite easy for us as researchers to pretend our work is apolitical, that we simply explore and create things, blissfully ignorant of negative consequences should our creations be &lt;em&gt;misused&lt;/em&gt;. Positive applications presumably motivate much great work, and I don't wish that people &lt;em&gt;stop&lt;/em&gt; this work, necessarily. We just need to acknowledge that we cannot &lt;i&gt;un&lt;/i&gt;-discover things, and that people who don't understand the limitations of technology may still use it. &lt;/p&gt;
&lt;p&gt;I am meandering to a point: efforts such as the &lt;a href="https://www.stopkillerrobots.org/"&gt;Campaign to Stop Killer Robots&lt;/a&gt; are good and should be publicised and discussed. Perhaps the &lt;a href="http://www.ucsusa.org/"&gt;Union of Concerned Scientists&lt;/a&gt; should start thinking about 'algorithmic/autonomous threats' (to human lives, livelihoods and the environment). My ideas here are half-formed, which is all the more reason I'd like to see discussions about such issues at similar workshops. It's certainly important that AIs have ethics, but what about the ethics of AI &lt;em&gt;researchers&lt;/em&gt;?&lt;/p&gt;
&lt;h2&gt;Sunday&lt;/h2&gt;
&lt;p&gt;The conference begins in earnest!&lt;/p&gt;
&lt;h3&gt;Steps Toward Robust Artificial Intelligence - Thomas G. Dietterich&lt;/h3&gt;
&lt;p&gt;Quantifying our uncertainty (as probabilistic approaches to AI attempt to do) is about &lt;em&gt;known unknowns&lt;/em&gt;: rather, the thing we know we are uncertain about has to appear somewhere in the model. Dietterich drew attention to &lt;em&gt;unknown unknowns&lt;/em&gt;: things outside the model, perhaps outside our algorithm's model of the environment.&lt;/p&gt;
&lt;p&gt;One way to tackle this is to expand the model: keep adding terms to account for things &lt;a href="https://xkcd.com/793/"&gt;we just thought of&lt;/a&gt;. A risk of this is that these terms may introduce errors if we mismodel them. He suggested that we instead build &lt;em&gt;causal models&lt;/em&gt;, because causal relations are more likely to be robust, require less data and transfer to new situations more easily.&lt;/p&gt;
&lt;p&gt;Regarding new situations: what happens if at 'test' (deployment, perhaps) time, our algorithm encounters something wildly different to what it has seen before? Perhaps instead of allowing it to perform suboptimally (and worse still, to not know it is performing badly), it should recognise this &lt;em&gt;anomaly&lt;/em&gt; and seek assistance. This prompts an open question, "when an agent decides it has entered an anomalous state, what should it do? Is there a general theory of safety?"&lt;/p&gt;
&lt;h3&gt;Session: Learning Preferences and Behaviour&lt;/h3&gt;
&lt;p&gt;I'll not lie: I went to this session because it sounded creepy in a Skynet, Minority Report sort of way.&lt;/p&gt;
&lt;p&gt;My favourite talk of the session was &lt;a href="https://www.aaai.org/Conferences/AAAI/2016/Papers/03Evans12476.pdf"&gt;Learning the Preferences of Ignorant, Inconsistent Agents&lt;/a&gt; - &lt;em&gt;Owain Evans, Andreas Stuhlmueller and Noah D. Goodman&lt;/em&gt;. Roughly, they are concerned with inverse reinforcement learning (IRL) (so learning utility/reward functions) from &lt;em&gt;suboptimal&lt;/em&gt; agents, as humans often might be. A specific case they look at is time inconsistency, which is where agents make plans they later abandon. Seemingly any non-exponential discounting implies time-inconsistency, if my notes are correct. See paper for details. And a related project page: &lt;a href="http://agentmodels.org/"&gt;agentmodels.org&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I spent the early afternoon finishing up my 'plain English explanation' for the work I was presenting at AAAI, see the page &lt;a href="https://corcra.github.io/bf2/"&gt;here&lt;/a&gt;. I wanted to have something to point my family/friends at when they ask what I work on. Also, making science accessible is good, probably.&lt;/p&gt;
&lt;h3&gt;Session: Word/Phrase Embedding&lt;/h3&gt;
&lt;p&gt;I went to this because I was speaking (briefly) at it. Also, because it is relevant to my interests, so I'll list everything.&lt;/p&gt;
&lt;p&gt;The oral spotlights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/15Sun11783.pdf"&gt;Inside Out: Two Jointly Predictive Models for Word Representations and Phrase Representations&lt;/a&gt; - &lt;em&gt;Fei Sun, Jiafeng Guo, Yanyan Lan, Jun Xu and Xueqi Cheng&lt;/em&gt;: Modification of the word2vec-style skip-gram/continuous-bag-of-words model including morphology, project page: &lt;a href="http://ofey.me/projects/InsideOut/"&gt;InsideOut&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/15Wick12464.pdf"&gt;Minimally-Constrained Multilingual Embeddings via Artificial Code-Switching&lt;/a&gt; - &lt;em&gt;Michael Wick, Pallika Kanani and Adam Pocock&lt;/em&gt;: using artificial code-switching to help rapidly create multilingual tools, borrowing information across languages essentially.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/12Derczynski11779.pdf"&gt;Generalised Brown Clustering and Roll-Up Feature Generation&lt;/a&gt; - &lt;em&gt;Leon Derczynski and Sean Chester&lt;/em&gt;: I am shamefully ignorant about Brown clustering, so a lot of this was lost on me. &lt;a href="https://github.com/sean-chester/generalised-brown"&gt;Link to project repository, anyway.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://github.com/corcra/bf2/tree/master/media"&gt;&lt;img src="https://raw.githubusercontent.com/corcra/bf2/master/media/aaai_spotlight_p2.png" class="floatr" style="width: 25vw;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The poster spotlights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/15Zhang12227.pdf"&gt;Building Earth Mover's Distance on Bilingual Word Embeddings for Machine Translation&lt;/a&gt; - &lt;em&gt;Meng Zhang, Yang Liu, Huanbo Luan, Maosong Sun, Tatsuya Izuha and Jie Hao&lt;/em&gt;: I may have spent this spotlight worrying about my spotlight.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/14Hyland12446.pdf"&gt;A Generative Model of Words and Relationships from Multiple Sources&lt;/a&gt; - &lt;em&gt;Stephanie L. Hyland&lt;/em&gt; (that's me) , &lt;em&gt;Theofanis Karaletsos and Gunnar Rätsch&lt;/em&gt;: People seemed to like the slides I made for this spotlight, so I put them in the project repository with some other 'media', see &lt;a href="https://github.com/corcra/bf2/tree/master/media"&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/14Goikoetxea11777.pdf"&gt;Single or Multiple? Combining Word Representations Independently Learned from Text and WordNet&lt;/a&gt; - &lt;em&gt;Josu Goikoetxea, Eneko Agirre and Aitor Soroa&lt;/em&gt;: work in a similar vein to mine, in the sense of combining information from 'free text' and 'structured data' (in this case WordNet).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;From Proteins to Robots: Learning to Optimize with Confidence - Andreas Krause&lt;/h3&gt;
&lt;p&gt;Some interesting and important questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how can an AI system autonomously explore while guaranteeing &lt;em&gt;safety?&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;how can we do optimised information gathering?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The former question is quite important for 'learning in the wild', and moving beyond the existing (rather successful) paradigm of test/train/validation that we have in machine learning - what happens when the data the algorithm sees depends on actions it takes?&lt;/p&gt;
&lt;p&gt;The latter is quite interesting for cases where we want to probe some nearly-black-box system, but probing is expensive. One can use the framework of &lt;em&gt;Bayesian Optimisation&lt;/em&gt; (Močkus, 1978), and score possible locations (to probe) by their utility in resolving the exploration/exploitation trade-off (via some kind of acquisition function, of which many have been proposed).&lt;/p&gt;
&lt;p&gt;He discussed how one can use Gaussian processes and confidence bounds to help with this, and I'll include a pointer to &lt;a href="http://arxiv.org/abs/0912.3995"&gt;Srinivas et al, 2010.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some more paper pointers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://colt2008.cs.helsinki.fi/papers/80-Dani.pdf"&gt;Stochastic Linear Optimization under Bandit Feedback&lt;/a&gt; - Varsha Dani, Thomas P. Hayes, Sham M. Kakade&lt;/li&gt;
&lt;li&gt;&lt;a href="https://las.inf.ethz.ch/files/gotovos13active-long.pdf"&gt;Active Learning for Level Set Estimation&lt;/a&gt; - Alkis Gotovos, Nathalie Casati, Gregory Hitz, Andreas Krause&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jmlr.org/proceedings/papers/v37/sui15.pdf"&gt;Safe Exploration for Optimization with Gaussian Processes&lt;/a&gt; - Yanan Sui, Alkis Gotovos, Joel Burdick, Andreas Krause &lt;/li&gt;
&lt;li&gt;&lt;a href="https://las.inf.ethz.ch/files/krause11contextual.pdf"&gt;Contextual Gaussian Process Bandit Optimization&lt;/a&gt; - Andreas Krause, Cheng Soon Ong&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(I am quite fond of Gaussian processes, in case that wasn't already obvious.)&lt;/p&gt;
&lt;p&gt;The conclusions were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;feedback loops abound in modern ML applications  &lt;/li&gt;
&lt;li&gt;exploration is central but also delicate, and safety is crucial  &lt;/li&gt;
&lt;li&gt;statistical confidence bounds allow navigating exploration-exploitation tradeoffs in a principled manner&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Poster Session 1&lt;/h3&gt;
&lt;p&gt;I was presenting at this session (see my poster &lt;a href="https://github.com/corcra/bf2/blob/master/media/aaai_poster.pdf"&gt;here&lt;/a&gt;), so I didn't get to look at anything else. I struggled to eat bean tacos one-handed, and I talked a &lt;em&gt;lot&lt;/em&gt;.&lt;/p&gt;
&lt;h2&gt;Monday&lt;/h2&gt;
&lt;h3&gt;Learning Treatment Policies in Mobile Health - Susan Murphy&lt;/h3&gt;
&lt;p&gt;I have Susan Murphy's paper &lt;a href="http://dept.stat.lsa.umich.edu/~samurphy/papers/optimal.pdf"&gt;Optimal dynamic treatment regimes&lt;/a&gt; on my desk &lt;em&gt;as I write this&lt;/em&gt;, so I was pretty excited to see her speaking. And on mHealth, too! Double excitement.&lt;/p&gt;
&lt;p&gt;It turns out that she is also involved in the &lt;a href="http://www.psc.isr.umich.edu/research/project-detail/36366"&gt;Heart Steps&lt;/a&gt; project with Ambuj Tewari, which I wrote about a little in my &lt;a href="https://corcra.github.io/ml/2015/12/14/NIPS2015.html"&gt;NIPS post&lt;/a&gt;, so I'm not going to repeat myself.&lt;/p&gt;
&lt;p&gt;The 'treatment optimisation' aspects of mHealth are interesting because it gets into the realm of HCI and psychology. You want to send the patient reminders to do a thing, but you don't want them to become habituated and ignore them, or irritated, or distracted. She mentioned the need to avoid pointlessly reminding the patient to go for a walk while they're &lt;em&gt;already&lt;/em&gt; walking, or dangerously alerting them while they're driving. I find it uncomfortable to be reminded that my phone knows when I'm walking/driving, but if the information is being recorded &lt;em&gt;anyway&lt;/em&gt;, you might as well use it, right? Insert something about dragnets here.&lt;/p&gt;
&lt;p&gt;But really, mHealth provides some very exciting opportunities to do reinforcement learning. She mentioned non-stationarity as a general challenge, and suggested one could perhaps do transfer learning within a user to tackle it.&lt;/p&gt;
&lt;h3&gt;Session: Active Learning&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/17Wray12000.pdf"&gt;A POMDP Formulation of Proactive Learning&lt;/a&gt; &lt;em&gt;(Kyle Hollins Wray and Shlomo Zilberstein)&lt;/em&gt; was interesting. The idea is that the agent must decide which &lt;em&gt;oracle&lt;/em&gt; to query to label a particular data point, where the underlying state is the &lt;em&gt;correctness&lt;/em&gt; of the current set of labels. I'm not familiar enough with the active learning field to say if this formulation is especially novel, but I liked it, possibly because I like POMDPs.&lt;/p&gt;
&lt;h3&gt;Session: Privacy&lt;/h3&gt;
&lt;p&gt;I experimented with taking no notes during this session to see how it would influence my recall of the material. The trade-off here is that taking notes is a little distracting for me (as well as providing many opportunities to notice Slack/email/etc.), but does provide a lasting record.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/10CuencaGrau12253.pdf"&gt;Logical Foundations of Privacy-Preserving Publishing of Linked Data&lt;/a&gt; &lt;em&gt;(Bernardo Cuenca Grau and Egor V. Kostylev)&lt;/em&gt; was strangely fascinating. They were talking about anonymisations of RDF graphs (a data type I'd been working with for my word embedding work). I'm also quite interested in information linkage (see e.g. &lt;a href="https://corcra.github.io/sec/2015/10/27/radical-networks.html"&gt;my talk at Radical Networks 2015&lt;/a&gt;), so this was up my alley.&lt;/p&gt;
&lt;p&gt;Not sure how the experiment worked out, further data required.&lt;/p&gt;
&lt;h3&gt;Session: Cognitive Systems&lt;/h3&gt;
&lt;p&gt;I was &lt;em&gt;heavily&lt;/em&gt; overbooked for this time-slot: I wanted to see Deep Learning 1, Discourse and Question Answering (NLP 6), the RSS talks (for my friend &lt;a href="https://cs.stanford.edu/people/asaxena/papers/sener_saxena_rCRF_rss15.pdf"&gt;Ozan's talk&lt;/a&gt;), Cognitive Systems (largely for Kazjon's talk - see below), and Machine Learning/Data Mining in Healthcare. Time turners have yet to be invented, unfortunately.&lt;/p&gt;
&lt;p&gt;One of the recurring themes of my AAAI v. NIPS pronouncements was that AAAI has, well... more &lt;strong&gt;AI&lt;/strong&gt; stuff. This session was probably the closest I got to that (unless you count the AI and Ethics workshop: I'd consider it meta-AI). People were doing reasoning &lt;em&gt;without&lt;/em&gt; probability distributions, using first order logic! One of the presentations included &lt;a href="https://www.youtube.com/watch?v=n9TWwG4SFWQ"&gt;this video&lt;/a&gt; which I found strangely distressing (to me it is - spoilers! - clearly about domestic abuse).&lt;/p&gt;
&lt;p&gt;The talk I had come to see, &lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/22Grace12456.pdf"&gt;Surprise-Triggered Reformulation of Design Goals&lt;/a&gt; &lt;em&gt;(Kazjon Grace and Mary Lou Maher)&lt;/em&gt;, along with numerous chats with Kazjon throughout the conference made me realise that computational creativity is a &lt;em&gt;thing&lt;/em&gt;. OK, full disclosure: I am loosely involved with some &lt;a href="https://twitter.com/hashtag/botally"&gt;generative art folks&lt;/a&gt; so I did sort of know this, but it hadn't occurred to me that one might use machine learning to represent or understand mental processes surrounding creativity. Neat! The idea here is that the way humans design things is iterative: you have some loosely-formed idea, and through the process of realising it, notice things you hadn't expected (experience &lt;em&gt;surprise&lt;/em&gt;, as it were), and modify your idea accordingly. So there is interplay between the internal representation (perhaps this is the design goal) and the external representation (the realisation). So they're interested in understanding &lt;em&gt;surprises&lt;/em&gt;: perhaps an element of a design is &lt;em&gt;unusual&lt;/em&gt; given other elements of the design, for example. I am going to have to actually read the paper before I elaborate any further on this, but the experiments involved generating weird (but edible) recipes so I'm looking forward to it.&lt;/p&gt;
&lt;p&gt;Very deep question raised by all of this: "can computers be creative?"&lt;br&gt;
Related: what is creativity? What is art? What are computers?&lt;/p&gt;
&lt;h3&gt;AI's Impact on Labor Markets - Nick Bostrom, Erik Brynjolfsoon, Oren Etzioni, Moshe Vardi&lt;/h3&gt;
&lt;p&gt;I managed to take no notes during this panel (my notes from AAAI actually dry up around here, I hit peak exasperation with keeping my devices charged).&lt;/p&gt;
&lt;p&gt;I have a lot of feelings about AI and labour, but I'm first going to direct attention to the Panel on Near-term Issues from the &lt;a href="https://corcra.github.io/ml/2015/12/14/NIPS2015.html"&gt;NIPS Algorithms Among Us Symposium&lt;/a&gt;, which had a similar lineup. &lt;/p&gt;
&lt;p&gt;Ultimately, it is hard to solve social and political issues using technology alone, especially if those issues arise as a result of the technology itself. I'd love to automate away all the mind-numbingly boring and unfulfilling jobs humans currently do, but I don't want to remove anyone's livelihood in the process. I don't think it's sufficient to say that society will 'figure it out somehow', especially in countries such as the USA where there is so little protection from poverty and homelessness. That said, I don't know what the solution is (except for some rather radical ideas with limited empirical support for their efficacy), and I don't know if it will, or should, come from the AI research community.&lt;/p&gt;
&lt;h3&gt;Poster Session 2&lt;/h3&gt;
&lt;p&gt;I got slightly side-tracked by ranting about how broken academic publishing is. Shoutout to the &lt;a href="https://www.mozillascience.org/contributorship-badges-a-new-project"&gt;Mozilla Contributorship Badges project&lt;/a&gt; for trying to deal with the credit-assignment problem, for one.&lt;/p&gt;
&lt;h2&gt;Tuesday&lt;/h2&gt;
&lt;h3&gt;Towards Artificial General Intelligence - Demis Hassabis&lt;/h3&gt;
&lt;p&gt;Google DeepMind are arguably the machine learning success story of the last year, given their &lt;a href="www.nature.com/nature/journal/v518/n7540/full/nature14236.html"&gt;Atari Nature paper&lt;/a&gt; and &lt;a href="http://deepmind.com/alpha-go.html"&gt;AlphaGo&lt;/a&gt; result (although the match against Lee Sedol in March will be more interesting). I'm very happy to see computer games featuring so prominently for evaluating and developing AGI: so much that I spent the session after this talk sketching out a project involving &lt;a href="https://en.wikipedia.org/wiki/Dota_2"&gt;Dota 2&lt;/a&gt;, which I think could be a very interesting application of deep reinforcement learning, if only the metagame would stabilise long enough to allow for acquisition of sufficient training data!&lt;/p&gt;
&lt;p&gt;Anyway, this talk mostly convinced me that DeepMind are doing cool stuff, which I imagine was the intended effect. Hassabis was coming from a pleasantly principled place. They do seem genuinely interested in AGI, rather than for example, beating benchmarks with &lt;em&gt;yet deeper&lt;/em&gt; networks. I don't mean to imply that beating benchmarks isn't important, but I think the types of discoveries one makes in the pursuit of larger/more abstract goals are quite important for the intellectual development of a field which can easily become dominated by engineering successes. So yes, the talk had the intended effect.&lt;/p&gt;
&lt;h3&gt;Session: Reinforcement Learning I&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://twitter.com/__hylandSL/status/699716539147137024"&gt;&lt;img src="images/aaai_GIRL.png" class="floatl" style="width: 25vw;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/19Burchfiel11917.pdf"&gt;Distance Minimization for Reward Learning from Scored Trajectories&lt;/a&gt; - &lt;em&gt;Benjamin Burchfiel, Carlo Tomasi and Ronald Parr&lt;/em&gt;: this is about IRL with suboptimal experts (a popular and interesting topic). In this case, the 'demonstrator' need not be an expert but can operate as a judge, assigning scores to demonstrators. The real-world example would be of a sports coach who's no longer capable of creating expert trajectories (that is, demonstrating optimally) but who can still accurately &lt;em&gt;rate&lt;/em&gt; demonstrations from others, if they're available. They also study the case where the judge's scores are noisy and find the algorithm robust.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/12Pirotta12482.pdf"&gt;Inverse Reinforcement Learning through Policy Gradient Minimization&lt;/a&gt; - &lt;em&gt;Matteo Pirotta and Marcello Restelli&lt;/em&gt;: more IRL through parametrising the expert's reward function, but here it is no longer necessarily to repeatedly compute optimal policies, so this should be quite efficient. Also, this algorithm is called GIRL.&lt;/p&gt;
&lt;h3&gt;Poster Session 3&lt;/h3&gt;
&lt;p&gt;Some interesting posters (highly non-exhaustive list, but I'm exhausted):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/01Luo11843.pdf"&gt;Predicting ICU Mortality Risk by Grouping Temporal Trends from a Multivariate Panel of Physiologic Measurements&lt;/a&gt; - &lt;em&gt;Yuan Luo, Yu Xin, Rohit Joshi, Leo Celi and Peter Szolovits&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/12Masson11981.pdf"&gt;Reinforcement Learning with Parameterized Actions&lt;/a&gt; - &lt;em&gt;Warwick Masson, Pravesh Ranchod and George Konidaris&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/15Mueller12195.pdf"&gt;Siamese Recurrent Architectures for Learning Sentence Similarity&lt;/a&gt; - &lt;em&gt;Jonas Mueller and Aditya Thyagarajan&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Wednesday&lt;/h2&gt;
&lt;h3&gt;Sessions: Reinforcement Learning II &amp;amp; III&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/12Wirth12247.pdf"&gt;Model-Free Preference-Based Reinforcement Learning&lt;/a&gt; - &lt;em&gt;Christian Wirth, Johannes Fürnkranz and Gerhard Neumann&lt;/em&gt;: I didn't actually see this talk, but the paper has a number of interesting words in its title, so it must be good.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/12Bellemare12428.pdf"&gt;Increasing the Action Gap: New Operators for Reinforcement Learning&lt;/a&gt; - &lt;em&gt;Marc G. Bellemare, Georg Ostrovski, Arthur Guez, Philip S. Thomas and Remi Munos&lt;/em&gt;: this was a good talk. Basically, during value iteration one applies the Bellman operator to the state-action value function (Q-function). The fixed point of the operator is the optimal Q-function, which induces (greedily) the optional policy. They argue that this operator is &lt;em&gt;inconsistent&lt;/em&gt;, in that it suggests &lt;em&gt;nonstationary&lt;/em&gt; policies. They resolve this by definining a 'consistent Bellman operator' which preserves local stationarity and show that it increases the &lt;em&gt;action gap&lt;/em&gt; (the value difference between the best and second best actions). The action gap is relevant because it can allow for selecting the same (optimal) action even when estimates of the value function are noisy. And a link to the &lt;a href="http://www.arcadelearningenvironment.org/"&gt;Arcade Learning Environment&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.instagram.com/p/BBqx2fHDQM6/?taken-by=c0rcr4"&gt;&lt;img src="images/aaai2016_phoenix.jpg" class="floatr" style="width: 25vw;"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.aaai.org/Conferences/AAAI/2016/Papers/12vanHasselt12389.pdf"&gt;Deep Reinforcement Learning with Double Q-Learning&lt;/a&gt; - &lt;em&gt;Hado van Hasselt, Arthur Guez and David Silver&lt;/em&gt;: more from DeepMind. I swear I am not a DeepMind fangirl. Setup here: Q-learning can result in overestimates for some action values. Using DQN (deep Q-learning algorithm) they find that this happens often and impacts performance. They solve the problem by showing how to generalise Double Q-learning to arbitrary function approximation (rather than just tabular Q functions). So this paper seems like a natural progression for Double Q-learning.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Exploration-exploitation trade-offs are everywhere. At this stage in my career, I consider going to conferences a largely exploratory activity: I can learn a little (or more) about a lot of things and get an idea for the kinds of research going on. For the people who spend conferences meeting with their collaborators, it's more about exploitation. &lt;em&gt;(For the appropriate interpretation of that word.)&lt;/em&gt; I am a little fatigued of exploration right now - I'm still processing things I saw at NIPS, so I was not well positioned to make the most out of AAAI. I kept wanting to run off and write code in a corner, but who does that? Well, I do that. I do that right now.&lt;/p&gt;</content><category term="ml"></category><category term="phoenix"></category><category term="conference"></category><category term="aaai"></category><category term="ethics"></category></entry><entry><title>NIPS 2015 by the day</title><link href="ml/2015-12-14-nips2015.html" rel="alternate"></link><published>2015-12-14T00:00:00+00:00</published><updated>2015-12-14T00:00:00+00:00</updated><author><name>corcra</name></author><id>tag:None,2015-12-14:ml/2015-12-14-nips2015.html</id><summary type="html">&lt;p&gt;I got back from Montreal yesterday. I was at the &lt;a href="https://nips.cc/"&gt;Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS)&lt;/a&gt; - a rather large gathering of people interested in machine learning, neuroscience, artificial intelligence, and related topics. It's an academic conference, and it is intense. Many wonderful conversations were had, things learned …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I got back from Montreal yesterday. I was at the &lt;a href="https://nips.cc/"&gt;Twenty-ninth Annual Conference on Neural Information Processing Systems (NIPS)&lt;/a&gt; - a rather large gathering of people interested in machine learning, neuroscience, artificial intelligence, and related topics. It's an academic conference, and it is intense. Many wonderful conversations were had, things learned, insights gained, ideas developed, coffees consumed. Old friends met and new friends made. I left physically exhausted, and this post is an attempt to summarise &lt;em&gt;some&lt;/em&gt; of what went down. This was also my first time attending NIPS, so next time I might be a &lt;em&gt;little&lt;/em&gt; more conservative with my energy.&lt;/p&gt;
&lt;p&gt;If it seems like my level of detail varies wildly, it's because sometimes I took
notes, sometimes I couldn't, and sometimes I didn't want to.&lt;/p&gt;
&lt;h2&gt;Sunday&lt;/h2&gt;
&lt;p&gt;&lt;img src="images/nips2015_01.png" class="floatr"&gt;&lt;/p&gt;
&lt;p&gt;When I flew from Dublin to Hamburg for &lt;a href="https://events.ccc.de/category/31c3/"&gt;31C3&lt;/a&gt;
last year, the plane was full of vaguely unusual-looking people (myself
included, no doubt) clearly destined for Congress. Who else would fly to Hamburg 
on St. Stephen's day? The flight from NYC to Montreal for NIPS was a little less 
homogeneous, and machine learners are harder to spot (posters are strong 
evidence), but I nonetheless had the same vague feeling of unified purpose with 
my co-passengers. Conversation about optimisation broke out on the bus to the
city centre, and knowing glances were exchanged between strangers. And so NIPS 
began as it would continue, a bubble where the social convention of silence is
broken by mutual knowledge of shared purpose (this purpose being bringing about the robot apocalypse).&lt;/p&gt;
&lt;p&gt;Tip: don't try to register the day the conference starts. Angry Monday
morning tweets mentioned waiting times some multiples of how long I spent on
Sunday evening. ¯\_(ツ)_/¯&lt;/p&gt;
&lt;h2&gt;Monday&lt;/h2&gt;
&lt;p&gt;Because I forgot to register for the &lt;a href="http://wimlworkshop.org/"&gt;Women in Machine Learning workshop&lt;/a&gt;,
I went to tutorials.&lt;/p&gt;
&lt;h3&gt;Deep Learning: Yoshua Bengio &amp;amp; Yann LeCun&lt;/h3&gt;
&lt;p&gt;Topics mentioned were: curse-of-dimensionality, backpropagation, convolutional nets, 
recurrent nets, details about backprop (e.g. with ReLUs and max pooling,
GPUs), distributed training (e.g. asynchronous stochastic gradient descent), 
applications (eg. vision, more about vision, speech, natural language),
attention mechanisms, encoder/decoder networks (e.g. for machine translation),
multi-task learning, unsupervised learning, undirected graphical models,
more about auto-encoders (e.g. probabilistic interpretation, helmholtz
machines), semi-supervised learning (e.g. ladder networks), and some challenges
and open problems. The future questions/areas of interest highlighted were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unsupervised learning, and how to evaluate it?  &lt;/li&gt;
&lt;li&gt;how to include long-term dependencies?  &lt;/li&gt;
&lt;li&gt;NLP, generally  &lt;/li&gt;
&lt;li&gt;optimisation  &lt;/li&gt;
&lt;li&gt;distributed training?  &lt;/li&gt;
&lt;li&gt;bridging the gap to biology  &lt;/li&gt;
&lt;li&gt;deep reinforcement learning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Overall, I wanted to see more gorey  details, but &lt;em&gt;deeper&lt;/em&gt; coverage of any one 
topic would have limited breadth, so it was more like a lit review/series of
pointers to publications in this field. There was criticism that it placed too 
much attention on the work of its presenters (also Hinton, who was meant to be 
there but couldn't make it unfortunately), and gave an incomplete treatment of 
the history of the field. I'm not in a position to comment intelligently on
that. Anyone giving an overview-style talk has a responsibility to adequately 
cover both history and breadth of research, so I can see why it might have been
made.&lt;/p&gt;
&lt;h3&gt;Probabilistic Programming: Frank Wood&lt;/h3&gt;
&lt;p&gt;I had already heard some of this content at MLSS 2015 Tübingen so didn't take
notes. Check out &lt;a href="https://bitbucket.org/probprog/mlss2015"&gt;this repo&lt;/a&gt; for the 
material from the practicals on Anglican. TL;DR:&lt;/p&gt;
&lt;blockquote&gt;&lt;p lang="en" dir="ltr"&gt;Goals of probabilistic programming: reduce coding burden, commodify inference, create weird new models, make it widely usable &lt;a href="https://twitter.com/hashtag/NIPS2015?src=hash"&gt;#NIPS2015&lt;/a&gt;&lt;/p&gt;&amp;mdash; Stephanie Hyland (@__hylandSL) &lt;a href="https://twitter.com/__hylandSL/status/673929524958990336"&gt;December 7, 2015&lt;/a&gt;&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3&gt;Introduction to Reinforcement Learning with Function Approximation: Rich Sutton&lt;/h3&gt;
&lt;p&gt;&lt;img src="images/nips2015_02.png" class="floatl" style="width: 35vw;"&gt;&lt;/p&gt;
&lt;p&gt;I took &lt;em&gt;physical notes&lt;/em&gt; for this tutorial, because there was a severe lack
of power outlets in the convention centre. Tip: sometimes it's better
to have a notebook with a long battery life than a retina screen.&lt;/p&gt;
&lt;p&gt;I think reinforcement learning is really cool (and according to how popular
the deep RL workshop was, so do other people (or maybe they just like 'deep')).&lt;/p&gt;
&lt;p&gt;This tutorial was much more focused than deep learning: it was concerned with
policy-learning through first getting an action-value function. This function
gives you the expected reward (usually with discounting) upon taking a
particular action from a particular state, and can therefore be used to define a
policy (e.g., greedily, given your state choose the action with highest value). &lt;/p&gt;
&lt;p&gt;He spoke about on- and off-policy learning, where the agent is obtaining
information for its estimate of the action-value function while either following
the policy given by such a function (on-policy) or some other policy (off-policy),
such as a random policy. I hadn't properly appreciated the significance of this
difference before, so I found the exposition illuminating. He gave an example
where on-policy learning resulted in the highest average reward across 
episodes, but its learned policy was worse than that of an off-policy learner, since
the off-policy learner was able to explore 'riskier' actions. My intuition here
is that this result could be altered by tweaking rewards and the inclination 
towards exploration in the 'off' policy, and I'm sure there is loads of 
(ancient) work already done on the topic. More papers to read, eh.&lt;/p&gt;
&lt;p&gt;Another neat thing about off-policy learning is that you can gather information
about many potential policies simultaneously. This might seem 'trivially obvious'
(exploration leads to information about the system and its rewards which enables
policy-learning) but it is always reassuring to hear one's intuitions restated 
by an expert in the field.&lt;/p&gt;
&lt;p&gt;Overall this was the most lecture-like of the tutorials and hopefully it will
appear online soon, because it was well-paced, well-motivated and overall the
most useful, even if it wasn't all-encompassing for reinforcement learning (it 
wasn't trying to be). Sutton is a good educator.&lt;/p&gt;
&lt;h3&gt;Poster Session 1&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;I did this session 'wrong'. I tried navigating through an impassable crowd of
humans and coats and bags to peer at each poster and then decide if I wanted to
hear more. Tip: do not do this. For everyone's sake.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5717-taming-the-wild-a-unified-analysis-of-hogwild-style-algorithms"&gt;Taming the Wild: A Unified Analysis of Hogwild-Style Algorithms&lt;/a&gt;- &lt;em&gt;Christopher M. De Sa, Ce Zhang, Kunle Olukotun, Christopher Ré&lt;/em&gt; - I need more asynchronous
SGD in my life. They look at the noise you get from asynchronous updates,
derive some results and describe a lower-precision SGD algorithm. I am disproportionately likely to pay attention to posters/papers with cool titles.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.princeton.edu/~ms44/nips2015/"&gt;A Theory of Decision Making Under Dynamic Context&lt;/a&gt; - &lt;em&gt;Michael Shvartsman, Vaibhav Srivastava, Jonathan D. Cohen&lt;/em&gt; -  Neuroscience! Decision making! I have apparently forgotten the main message of this poster, possibly because we rapidly started talking about psycholinguistics. The danger of NIPS is exhaustion through too many interesting conversations. Added bonus for this poster: he made it + code + paper available (see link).&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5635-grammar-as-a-foreign-language"&gt;Grammar as a Foreign Language&lt;/a&gt; - &lt;em&gt;Oriol Vinyals, Łukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, Geoffrey Hinton&lt;/em&gt; - by the time I made it to this poster the session was over so I didn't get to speak to any of the authors. Main idea: parsing with LSTM + attention! The 'foreign language' part comes in because it's sequence-to-sequence (sentence to linearised parse tree), which is typically found in machine translation settings.&lt;/p&gt;
&lt;h2&gt;Tuesday&lt;/h2&gt;
&lt;p&gt;I was unreasonably tired and questioned the wisdom of staying at a poster session until after midnight. &lt;a href="http://mlg.eng.cam.ac.uk/zoubin/"&gt;Zoubin Ghahramani&lt;/a&gt; spoke about &lt;strong&gt;Probabilistic Machine Learning&lt;/strong&gt; while I ate pastries with a fork in the overflow room. The overflow room would have been perfect if it had any power outlets in it. I've heard some variant of Zoubin's talk roughly twice already, thanks to &lt;a href="http://mlss.tuebingen.mpg.de/"&gt;MLSS 2015&lt;/a&gt; and &lt;a href="http://gpss.cc/"&gt;GPSS 2014&lt;/a&gt;, so I lost focus and probably missed something new and important. He mentioned probabilistic programming and the &lt;a href="http://www.automaticstatistician.com/index/"&gt;automatic statistician&lt;/a&gt;. One of the questions was about whether this (the automatic statistician) will replace machine learners : a terrible thought, and ironic for a discipline which (to some extent) aims to automate away many other jobs. The answer was (as you might expect, may have even given yourself); 'this will just make our jobs easier, allowing us to focus on more interesting problems'.&lt;/p&gt;
&lt;p&gt;The talk after Zoubin was rather technical and about singular value decomposition. I missed some critical thread of understanding at the start (see missing focus) and sort of give up following, although I note that the speaker was just &lt;em&gt;quite good&lt;/em&gt;, even if the topic is not directly relevant to me.&lt;/p&gt;
&lt;p&gt;Spotlights as a concept are interesting, and their intended purpose is a little unclear to me. If the poster is personally relevant and interesting, I will (possibly) already know about it and go to it. If it's not relevant, a three-minute summary is &lt;em&gt;unlikely&lt;/em&gt; to change my mind. The intended benefits I could imagine (for the presenters) are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;convincing other members of your field that your poster is interesting/worthwhile&lt;/li&gt;
&lt;li&gt;convincing people from outside your area that your poster is relevant  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;However, each of these necessitates a very different three-minute presentation (detailed versus high-level), and it's hard to say what the presenters went with. Further possible benefit:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;be able to state that one's poster was selected for highlight  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In which case, the audience need not pay any attention. This is another way of saying that while I did listen, most of the spotlighted posters didn't make it into my cut for later. However, the final benefit (for the audience) was appreciated:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;exposure to entirely different sub-field and its different priorities and problems  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I spent much of the afternoon charging my laptop in a corner of the convention centre and doing some work, so there are some &lt;em&gt;deleted scenes&lt;/em&gt; from the conference here. I got an especially foul latte and suffered it for too long. What sort of monster uses artificial sweetener without asking first?&lt;/p&gt;
&lt;h3&gt;Poster Session 2:&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;New poster session policy: consult conference book, select posters, target.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1506.05751"&gt;Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks&lt;/a&gt; - &lt;em&gt;Emily Denton, Soumith Chintala, Arthur Szlam, Rob Fergus&lt;/em&gt; - 
Emily Denton was part of the way into an explanation of adversarial networks when I arrived at this poster. I feel like I've heard a lot about them in recent days, but it's probably just the &lt;a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases#Frequency_illusion"&gt;Baader-Meinhof phenomenon&lt;/a&gt;. I like the idea, although I feel like there's probably a way to show that the procedure is equivalent to some other contrastive objective or falls out naturally from an appropriate model choice, but these idle thoughts are better substantiated later/elsewhere/in prior art.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5776-expressing-an-image-stream-with-a-sequence-of-natural-sentences"&gt;Expressing an Image Stream with a Sequence of Natural Sentences&lt;/a&gt; - &lt;em&gt;Cesc C. Park, Gunhee Kim&lt;/em&gt; - fairly complicated deep network architecture, the idea is to create a reasonable-looking set of sentences to describe a sequence of images. Training data is blog posts containing pictures, assumed related (they break it into image/text-block segments). Some possibly-interesting pre-processing on the text data (I am biased to find text more interesting than images!), too.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.eecs.berkeley.edu/~igor.mordatch/policy/index.html"&gt;Interactive Control of Diverse Complex Characters with Neural Networks&lt;/a&gt; -&lt;em&gt;Igor Mordatch, Kendall Lowrey, Galen Andrew, Zoran Popović, Emanuel Todorov&lt;/em&gt; - using a recurrent neural network to learn the dynamics under a control policy; seemingly mapping from the state to the velocities (dynamics) caused by an action.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5792-efficient-learning-of-continuous-time-hidden-markov-models-for-disease-progression"&gt;Efficient Learning of Continuous-Time Hidden Markov Models for Disease Progression&lt;/a&gt; - &lt;em&gt;Yu-Ying Liu, Shuang Li, Fuxin Li, Le Song, James M. Rehg&lt;/em&gt; - a medically-focused paper! The advance seems to be making continuous-time HMMs more feasible. How much? I'm not sure, I didn't stay too long.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5751-asynchronous-parallel-stochastic-gradient-for-nonconvex-optimization"&gt;Asynchronous Parallel Stochastic Gradient for Nonconvex Optimization&lt;/a&gt; - &lt;em&gt;Xiangru Lian, Yijun Huang, Yuncheng Li, Ji Liu&lt;/em&gt; - this is a theory paper about asynchronous SGD. I was initially confused because I didn't know the state of the theory here, and wasn't sure what their actual contribution was. The contribution is about the convergence rate. The take-home for me is roughly 'you can use asynchronous SGD'. See also the poster from Monday on Hogwild!.&lt;/p&gt;
&lt;h2&gt;Wednesday&lt;/h2&gt;
&lt;p&gt;I missed Tibhshirani's talk, &lt;em&gt;Post-selection Inference for Forward Stepwise Rregression, Lasso and other Adaptive Statistical Procedures&lt;/em&gt;. This was unfortunate given the topic of lunchtime discussion was adaptive statistical procedures (among other things). Being interdisciplinary is interesting: I can simultaneously observe biology's obsession with p-values and machine learning's apparent lack of interest (to generalise &lt;em&gt;wildly&lt;/em&gt;). I am not sure how many papers demonstrate &lt;em&gt;statistically significant&lt;/em&gt; improvement over state-of-the-art, and while I should back up this speculation with reality, at the present moment (1:19am on Thursday) I'll say 'not many' and leave a generic pointer to Gelman's paper &lt;a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf"&gt;The garden of forking paths: Why multiple comparisons can be a problem, even when there is no “fishing expedition” or “p-hacking” and the research
hypothesis was posited ahead of time&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Some of the talks/spotlights ended up being poster picks of mine, so I'll describe them below.&lt;/p&gt;
&lt;p&gt;I was strangely entranced by &lt;a href="http://arxiv.org/abs/1412.7091"&gt;Efficient Exact Gradient Update for training Deep Networks with Very Large Sparse Targets&lt;/a&gt;. I have a soft spot for linear algebra tricks. The idea is basically that when you have a very large, but sparse target - as you might get in a language modelling task (trying to predict which of O(100,000) words comes next) - you can do &lt;em&gt;smart things&lt;/em&gt; to obtain gradients without actually calculating the horrible non-sparse, high-dimensional output. Lovely. The problem is that this only works for &lt;em&gt;certain classes&lt;/em&gt; of loss functions, &lt;em&gt;not&lt;/em&gt; including the traditional log softmax one sees in these language applications. So possibly limited benefit, but worthy of further investigation.&lt;/p&gt;
&lt;h3&gt;Poster Session 3&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Refining the poster-session policy, I made it to too many posters and fried my brain.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5845-deep-visual-analogy-making"&gt;Deep Visual Analogy Making&lt;/a&gt; - &lt;em&gt;Scott E. Reed, Yi Zhang, Yuting Zhang, Honglak Lee&lt;/em&gt; - this was a full oral presentation so the poster was crowded. Oh, to be tall. Analogy idea: A 'is to' B as C 'is to' D, given (or simultaneously with) representations of A, ..., D, what does 'is to' mean? Oft-cited example from language modelling is the 'king is to queen as man is to woman' example (from &lt;a href="http://arxiv.org/abs/1310.4546"&gt;word2vec&lt;/a&gt;) where 'is to' is apparently a constant offset vector in the representation space (which is a vector space). This is a very general problem and one I could rant about for quite a long time (indeed, I have &lt;a href="http://arxiv.org/abs/1510.00259"&gt;a paper&lt;/a&gt; on a related topic) so I'll say that the new thing here seems to be the application to images, and nice results/experiments... and probably other details that will only emerge when I read the paper. Cool bonus: they used free (as in Free) game art from the &lt;a href="http://lpc.opengameart.org/"&gt;Liberated Pixel Cup&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5850-training-very-deep-networks"&gt;Training Very Deep Networks&lt;/a&gt; - &lt;em&gt;Rupesh K. Srivastava, Klaus Greff, Juergen Schmidhuber&lt;/em&gt; - (disclosure: Rupesh and Klaus are friends of mine) 
Deeper networks are more better, but training them is hard (vanishing gradients and whatnot) - what to do? Highway networks tackle this by putting gates on layers, choosing between 'transporting' and 'transforming' data. Transporting is just an identity operation and therefore doesn't complicate gradients at all. There are (probably very obvious, for those who know LSTMs) connections to LSTMs here also. Keeping in line wih Klaus's Kubrik-inspired paper titles (previous ones being &lt;a href="http://arxiv.org/abs/1402.3511"&gt;A Clockwork RNN&lt;/a&gt;) and &lt;a href="http://arxiv.org/abs/1503.04069"&gt;LSTM: A Search Space Odyssey&lt;/a&gt;) I'd suggest 'Highway Networks or: How I Learned to Stop Worrying and Transport the Data', but admit further work is needed in this direction.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5846-end-to-end-memory-networks"&gt;End-to-end Memory Networks&lt;/a&gt; - &lt;em&gt;Sainbayar Sukhbaatar, arthur szlam, Jason Weston, Rob Fergus&lt;/em&gt; -  continuous extension of &lt;a href="http://arxiv.org/abs/1410.3916"&gt;memory networks&lt;/a&gt;, thus can be trained end-to-end (that is, without direct supervision at each layer, just from input-output pairs). The basic idea of a memory network is that you have some &lt;em&gt;memory component&lt;/em&gt; (surprisingly enough) which the model &lt;em&gt;learns&lt;/em&gt; to read and write to. Obvious applications is question-answering: feed it some text describing a scene, situation etc., then ask questions. I wondered how difficult these tasks could become before the methods started to break down and suggested (I think it was to szlam) that the GRE logic puzzles might be interesting for that, but alas, restricted-access data. One of many reasons we cannot have nice things.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5860-on-the-job-learning-with-bayesian-decision-theory"&gt;On-the-job Learning with Bayesian Decision Theory&lt;/a&gt; - &lt;em&gt;Keenon Werling, Arun Tejasvi Chaganty, Percy S. Liang, Christopher D. Manning&lt;/em&gt; - humans are quite good at tasks you might want an algorithm to perform, but employing humans is expensive (in many ways). Algorithms scale much better in this regard, but they have unacceptably bad performance until they've seen enough data. Solution: combine both. Get the algorithm to assess its certainty on the task, and ask for help when it needs it (using Amazon Mechanical Turk). Seems quite cool/useful, although I have some Complicated Feelings about turking (is it fine? is it creepy? is it exploitative somehow?).&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5873-a-framework-for-individualizing-predictions-of-disease-trajectories-by-exploiting-multi-resolution-structure"&gt;A Framework for Individualising Predictions of Disease Trajectories by Exploiting Multi-Resolution Structure&lt;/a&gt; - &lt;em&gt;Peter Schulam, Suchi Saria&lt;/em&gt; - carefully constructed hierarchical model of disease trajectory to identify patient subgroups. In particular, using a noise model (gaussian process with particular kernel choice) which allows for transient trends such as infection, medication etc. I think the disease severity is measured by lung capacity, so it's a 1-dimensional state space (although patients have covariates etc.), but I don't see any reason why a similar model couldn't handle other state-spaces. It makes for nice graphs, anyway. I'm glad to see probabilistic graphical models for healthcare represented at NIPS.&lt;/p&gt;
&lt;h2&gt;Thursday&lt;/h2&gt;
&lt;p&gt;Some last minute poster-printing shenanigans occupied the morning. For future reference: &lt;a href="http://www.copienova.com/"&gt;Copie Nova&lt;/a&gt; printed my A1 poster in 15 minutes.&lt;/p&gt;
&lt;h3&gt;Poster Session 4&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Update to policy: bump into a friend, end up chatting about twitter bots and other side projects. Miss half the poster session.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5949-semi-supervised-sequence-learning"&gt;Semi-supervised Sequence Learning&lt;/a&gt; - &lt;em&gt;Andrew M. Dai, Quoc V. Le&lt;/em&gt; - I marked this and have no memory of actually reading the poster. I suspect it was mobbed and I gave up. Things in the direction of unsupervised learning are interesting, so the paper is probably interesting.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5950-skip-thought-vectors"&gt;Skip-Thought Vectors&lt;/a&gt; - &lt;em&gt;Ryan Kiros, Yukun Zhu, Ruslan R. Salakhutdinov, Richard Zemel, Raquel Urtasun, Antonio Torralba, Sanja Fidler&lt;/em&gt; - this is the only paper I had already read before coming to the conference, so it was neat to get to talk to Kiros about it briefly! The idea is basically: as in word2vec, you learn a representation of 'meaning' by trying to predict context. This time, the prediction is of the preceding and subsequent &lt;em&gt;sentences&lt;/em&gt;, using RNN encoders/decoders. They also use an interesting trick to augment their underlying word representations by learning a mapping from pre-trained word2vec vectors into their mapping space. This allows for any word2vec-learned word to be used in their setup. I was surprised that this worked well, since the problem should be over-determined (they solve this approximately with a L2 loss, but still). The title is also very eye-catching (the term was coined by Hinton, according to Kiros), although I think we're still a ways away from actually representing &lt;em&gt;thoughts&lt;/em&gt;. Sentences are closer than words, but are they close enough?&lt;/p&gt;
&lt;h3&gt;Symposium: Algorithms Among Us: the Societal Impacts of Machine Learning&lt;/h3&gt;
&lt;p&gt;I am so excited to see the field talking about this. It is very easy as a scientist to divorce oneself from the social, ethical, economic etc. consequences of one's work. I was glad to see a large crowd turn out to this, although there's certainly an element of 'self preservation' here - that is, how do we make sure machine learning (and artificial intelligence) retains a positive status in the eyes of everyone else, and some element of sensationalism regarding 'scary killer robots of the future' (aka 'the children of the singularity are going to murder us all and something about Roko's basilisk'). Nonetheless, cool discussions were had.&lt;/p&gt;
&lt;h4&gt;Economic Issues&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://ebusiness.mit.edu/erik/"&gt;Erik Brynjolfsson&lt;/a&gt; spoke about the &lt;strong&gt;Economic Implications of Machine Intelligence&lt;/strong&gt;. He was proposing that we are in a 'second machine age'; where previously machines were used to replace physical power (as in the industrial revolution), we now see computers providing &lt;em&gt;mental power&lt;/em&gt;, which possibly threatens not to complement humans but replace us. This has implications for the economy (what doesn't?). He showed some graphs about income trends in the USA, which were (as usual) horrifying and enraging. It's uncertain how we can use machine learning to combat this without simultaneously bringing about other changes in society/the economy.&lt;/p&gt;
&lt;h4&gt;Legal Issues&lt;/h4&gt;
&lt;p&gt;&lt;a href="www.iankerr.ca"&gt;Ian Kerr&lt;/a&gt; spoke about &lt;strong&gt;Machine Learning and the Law&lt;/strong&gt;, which was fascinating. Question: can computers &lt;em&gt;make contracts&lt;/em&gt;? Apparently yes! What about &lt;em&gt;product liability&lt;/em&gt;? The manufacturer is usually responsible if there's a &lt;em&gt;defect&lt;/em&gt; in a product, but what if your autonomous vehicle drives into a wall to save a small child? It's doing what it was programmed to do - who's to blame? On that point, &lt;em&gt;should&lt;/em&gt; it do that? He mentions &lt;em&gt;volenti non fit injuria&lt;/em&gt;, that people who enter into risky activities should assume the risk (and entering a self-driving car is a risky activity, arguably). More questions: how much &lt;em&gt;faith&lt;/em&gt; should we put in the output of an algorithm? What if an automated medical diagnosis disagrees with a human? Who do we trust? There are questions of both &lt;em&gt;moral&lt;/em&gt; and &lt;em&gt;legal&lt;/em&gt; liability. If your instinct is to respond with 'trust the human, of course' - what if the algorithm's track record is provably much better than that of the human?&lt;/p&gt;
&lt;h4&gt;Panel on Near-Term Issues&lt;/h4&gt;
&lt;p&gt;(with &lt;em&gt;Tom Dietterich, Ian Kerr, Erik Brynjolfsson, Finale Doshi-Velez, Neil Lawrence, Cynthia Dwork&lt;/em&gt;.) &lt;/p&gt;
&lt;p&gt;I didn't write down who said what, so to anonymously summarise some of the points raised:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the philosophical problems (e.g. trolley/tunnel problem) aren't so clear-cut, because there is &lt;em&gt;uncertainty&lt;/em&gt; and also split-second decision-making which may render 'consulting the human driver' an untenable option.  &lt;/li&gt;
&lt;li&gt;re: people losing jobs to automation: this has been happening for a long time, but that doesn't necessarily make it acceptable. However, arbitrarily banning/regulating things is also not desirable. Both under and over regulation are possibly dangerous.  &lt;/li&gt;
&lt;li&gt;we should look for ways that AI can &lt;em&gt;enhance&lt;/em&gt; human capabilities, rather than trying to &lt;em&gt;replicate&lt;/em&gt; it - this might result in very different-looking research and outcomes.  &lt;/li&gt;
&lt;li&gt;sometimes there just &lt;em&gt;isn't a right answer&lt;/em&gt; because we don't know what the objective function is (particularly in ethics), and encoding a single system of values maybe a fool's errand. (I'm reasonably confident Neil Lawrence said this.)  &lt;/li&gt;
&lt;li&gt;counter-point to the above: robust loss functions exist to allow us to optimise a possibly-misspecified objective function.  &lt;/li&gt;
&lt;li&gt;we are actually already quite forgiving of (human) mistakes in medicine!  &lt;/li&gt;
&lt;li&gt;skill/income gap: what about &lt;em&gt;developing countries&lt;/em&gt;? Someone pointed out that China has moved to a higher-income country, but mostly by doing the low-skilled labour no longer performed in The West.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Panel: Human-level AI... If, How, and When?&lt;/h4&gt;
&lt;p&gt;(with &lt;em&gt;Yann LeCun, Andrew Ng, Gary Marcus, Shane Legg, Tom Dietterich&lt;/em&gt;) &lt;/p&gt;
&lt;p&gt;More semi-anonymous points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;obviously&lt;/em&gt; artificial general intelligence (AGI) is a crude concept, but it's still useful... "I'll know it when I see it."  &lt;/li&gt;
&lt;li&gt;&lt;em&gt;generality&lt;/em&gt; is the main difference between task-oriented algorithms and AGI, but maybe human-level AGI is not so important.  &lt;/li&gt;
&lt;li&gt;reasons to pursuse AGI include better understanding human intelligence, and other questions of psychology.  &lt;/li&gt;
&lt;li&gt;someone questions how useful AGI is to society, as individualised systems already work very well.  &lt;/li&gt;
&lt;li&gt;counter-point to above: hand-crafted systems are being outperformed in some tasks by 'less engineered' ones.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="images/nips2015_03.png" class="floatr"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;quote from Andrew Ng: "working on AGI today is like working on colonising Alpha Centauri", although he isn't opposed to other people working on it.  &lt;/li&gt;
&lt;li&gt;LeCun emphasises the importance of unsupervised learning for approaching more intelligent machines.  &lt;/li&gt;
&lt;li&gt;Ng says that seeing into the future is hard if not impossible, and reiterates the importance of unsupervised learning for progress.  &lt;/li&gt;
&lt;li&gt;re: self-driving cars: Ng suggests starting with vehicles autonomous on &lt;em&gt;specific routes&lt;/em&gt;, and then expanding their range of activity, rather than starting with an everywhere-driving car which increases in autonomy.  &lt;/li&gt;
&lt;li&gt;"AGI will not be an event. It won't happen instantaneously. We will add capabilities. The hardware matters. Much of our meta-reasoning is about resource allocation. Different hardware infrastructures will lead to different trade-offs. We will see systems with different strengths and weaknesses to humans."  &lt;/li&gt;
&lt;li&gt;minor counter-point to above: maybe in the future, the point at which computers can read open-ended general-domain texts will be regarded as 'the turning point'&lt;/li&gt;
&lt;li&gt;Ng: (paraphrasing): "Forming a committee about evil AI robots is like worrying about overpopulation on Mars."&lt;/li&gt;
&lt;li&gt;LeCun: (approximately, my live-transcription has a non-zero error-rate): "We like to think of our mind as being a generally intelligent machine, but our brains are very very far from being general. We’re driven by basic instincts built into us by evolution for survival, our brains are very limited in their types of connections and functions/signals they can process/compute efficiently. We’re very slow at adding numbers together… it’s very difficult for us to imagine a different type of intelligence than human intelligence, because that’s the only example we have in front of us. Machines will look very different. They won’t have the drives which cause humans to do bad things to each other."&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Friday (&lt;a href="https://sites.google.com/site/nipsmlhc15/"&gt;Workshop on Machine Learning in Healthcare&lt;/a&gt;)&lt;/h2&gt;
&lt;p&gt;This is technically &lt;em&gt;how&lt;/em&gt; I was at NIPS, I was presenting a poster (and I got travel funding).&lt;/p&gt;
&lt;p&gt;&lt;img src="images/mlhc_poster_final.png" class="floatl"&gt;&lt;/p&gt;
&lt;p&gt;To my eternal shame and regret, I missed everything before the first poster session. I hope the talks will be online soon, because they sounded great:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Integrating Artificial Intelligence into Emergency Care - &lt;em&gt;Steven Horng&lt;/em&gt;  &lt;/li&gt;
&lt;li&gt;Data-driven Phenotyping of Autism Spectrum Disorders - &lt;em&gt;Finale Doshi Velez&lt;/em&gt;  &lt;/li&gt;
&lt;li&gt;Behavioral Analytics in Mental Health Care - &lt;em&gt;Gourab De&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I also accidentaly double-presented my poster, so didn't have time to thoroughly examine work from others.&lt;/p&gt;
&lt;p&gt;Rich Caruana spoke about &lt;strong&gt;Accuracy on the test set is not enough --- the risk of deploying unintelligible models in healthcare&lt;/strong&gt;: interpretability is important in healthcare! He gave an example of a rule-based model which, upon inspection, revealed that asthma appeared to predict &lt;em&gt;better&lt;/em&gt; outcomes for pneumonia patients. Further reflection yielded the explanation that such patients are more closely monitored and may go to the hospital earlier/more often.&lt;/p&gt;
&lt;p&gt;This reminds me of a lesson from my biostatistics class during Part III: from an entirely unspecified population, the information that a given individual has a diagnosis of breast cancer &lt;em&gt;improves&lt;/em&gt; their life expectancy relative to the population at large. Why? Such a diagnosis means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;patient is likely female  &lt;/li&gt;
&lt;li&gt;patient is from a country with breast cancer screening programs  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;... both of which improve one's life expectancy relative to global average. Couple this with reasonable-ish outcomes for breast cancer diagnoses and you have the seemingly counter-intuitive result. The lesson is to always be vigilant (for confounders).&lt;/p&gt;
&lt;p&gt;&lt;a href="http://shahlab.stanford.edu/"&gt;Nigam Shah&lt;/a&gt; spoke about &lt;strong&gt;Building [Machine] Learning Healthcare Systems&lt;/strong&gt;. Apparently 91% of the increase in healthcare costs in the USA is attributable to price increases, and not specific services or ageing. Citation required, obviously, but I didn't take it down. He spent some time discussing how existing data sources (EHRs, clinical trials, chemical databases, health forums, physician query logs, PubMed) can be used to do three things (this is probably an overview of the work done in his lab):&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;answer clinical questions, e.g. &lt;em&gt;does androgen therapy for prostate cancer influence risk of Alzheimer's, also as a function of age?&lt;/em&gt;  &lt;/li&gt;
&lt;li&gt;obtain insights from data, e.g. &lt;em&gt;here's a pile of data, tell me something I don't know&lt;/em&gt;  &lt;/li&gt;
&lt;li&gt;form predictive models, e.g.&lt;/li&gt;
&lt;li&gt;which patients will become expensive next year?&lt;/li&gt;
&lt;li&gt;which patients have wounds that won't heal?&lt;/li&gt;
&lt;li&gt;which patients may have latent diseases?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There were several &lt;strong&gt;contributed talks&lt;/strong&gt;. My favourite was from &lt;a href="http://jeannesauve.org/scholar/charles-onu/"&gt;Charles C. Onu&lt;/a&gt; about &lt;strong&gt;detecting asphyxia from a baby's cry&lt;/strong&gt;. Problem setting: asphyxia in newborns is potentially fatal or debilitating, but typical clinical diagnosis requires resources which are not always available (e.g. in rural locations in Nigeria). It turns out that babies with asphyxia &lt;em&gt;cry in a detectably different way&lt;/em&gt;. So he developed the tools (signal processing, classification) and &lt;a href="http://www.ubenwa.com/"&gt;an app&lt;/a&gt; to do this on smartphones (high penetration even in low-resource settings). This is one of the coolest applications of machine learning I've heard of, and it didn't require deep learning. He won the prize for best contribution, and deservedly so. This should be a reminder that impact comes from &lt;em&gt;solving important problems&lt;/em&gt;, not (necessarily) using high-tech solutions.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://dept.stat.lsa.umich.edu/~tewaria/"&gt;Ambuj Tewari&lt;/a&gt; spoke about &lt;strong&gt;Personalised mHealth&lt;/strong&gt;. I find this stuff really fascinating (and wish I had any spare time to work on it - all my spare time is occupied by lasers right now). He motivated the issue by pointing out the &lt;em&gt;dire&lt;/em&gt; state of mental health care in India: apparently there are 343 clinical psychologists (in the &lt;em&gt;country&lt;/em&gt;?), out of a required 13,259, and 290 psycho-social workers out of 19,064. Clearly, anything technology can do to bridge this gap is huge. He pointed out that since smartphone penetration is very high, mHealth has a lot of potential. Then my laptop battery died.&lt;/p&gt;
&lt;p&gt;The rough idea is to use reinforcement learning and expertise from human-computer interaction to devise apps which encourage &lt;em&gt;behaviour modification&lt;/em&gt; in their users. This idea is a little terrifying when you think of malicious actors (encouraging addiction to pay-per-use services/games for example), but their intentions here were noble (so the tech will never be misused, right?). The stated application was fitness for people at risk of heart disease, if I recall. Finding the right balance of push/pull notifications (including frequency and number) is important to encourage persistent engagement. I'm particularly excited for mHealth applications to mental health, especially for self-monitoring and anomaly-detection. These things already exist to an extent, but I'm not sure how much they rely on machine learning.&lt;/p&gt;
&lt;h2&gt;Saturday (&lt;a href="http://www.thespermwhale.com/jaseweston/ram/"&gt;Reasoning, Attention and Memory Workshop&lt;/a&gt;)&lt;/h2&gt;
&lt;p&gt;This workshop was very crowded, and I was only able to get a seat for the first session, so my notes are terrible/missing. The slides are on the workshop page, anyway, so I'm going to substitute an actual overview of this workshop with the following set of bad jokes:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://twitter.com/__hylandSL/status/675669409344671744"&gt;&lt;img src="images/nips2015_pun1.png" class="center"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/__hylandSL/status/675698712761511936"&gt;&lt;img src="images/nips2015_pun2.png" class="center"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/__hylandSL/status/675699512430764032"&gt;&lt;img src="images/nips2015_pun3.png" class="center"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/__hylandSL/status/675761837279965185"&gt;&lt;img src="images/nips2015_pun4.png" class="center"&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/__hylandSL/status/675817625876852736"&gt;&lt;img src="images/nips2015_pun5.png" class="center"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;No regrets.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Workshop bonus: free icecream.&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There are a lot of smart people working on a lot of interesting problems. Industry interest in machine learning is very high, and it is possible to do research outside of academia. (This is a curiosity for a former theoretical physicist.) The deep learning wave is &lt;em&gt;possibly&lt;/em&gt; cresting, although &lt;em&gt;deep reinforcement learning&lt;/em&gt; seems to be pretty hot. Models including memory are exciting and potentially very powerful, for performance on standard tasks and for (the non-orthogonal problem of) modelling &lt;em&gt;reasoning&lt;/em&gt;. Unsupervised learning is the future. Healthcare is clearly a wonderful match for &lt;em&gt;interpretable models&lt;/em&gt;, both as an application and a source of inspiration for theoretical development (&lt;em&gt;cf.&lt;/em&gt; &lt;a href="https://en.wikipedia.org/wiki/Cauchy%E2%80%93Riemann_equations#Physical_interpretation"&gt;complex analysis and physics&lt;/a&gt;). The community is vibrant (if hilariously gender-imbalanced), and I'm looking forward to next year.&lt;/p&gt;</content><category term="ml"></category><category term="nips"></category><category term="conference"></category><category term="montreal"></category><category term="canada"></category><category term="ethics"></category><category term="AI"></category></entry><entry><title>thoughts from mlss 2015 tübingen</title><link href="ml/2015-07-30-mlss2015.html" rel="alternate"></link><published>2015-07-30T13:37:00+01:00</published><updated>2015-07-30T13:37:00+01:00</updated><author><name>corcra</name></author><id>tag:None,2015-07-30:ml/2015-07-30-mlss2015.html</id><summary type="html">&lt;p&gt;I recently attended the &lt;a href="http://mlss.tuebingen.mpg.de/2015/index.html"&gt;Machine Learning Summer School at the MPI in Tübingen&lt;/a&gt;. This wasn't my first time at an event like this - I attended the &lt;a href="http://ml.dcs.shef.ac.uk/gpss/gpss14/"&gt;Gaussian Process 'Summer' School&lt;/a&gt; in September 2014 - but the MLSS is a lot bigger/diverse. I'm fairly sure I didn't even speak to all …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I recently attended the &lt;a href="http://mlss.tuebingen.mpg.de/2015/index.html"&gt;Machine Learning Summer School at the MPI in Tübingen&lt;/a&gt;. This wasn't my first time at an event like this - I attended the &lt;a href="http://ml.dcs.shef.ac.uk/gpss/gpss14/"&gt;Gaussian Process 'Summer' School&lt;/a&gt; in September 2014 - but the MLSS is a lot bigger/diverse. I'm fairly sure I didn't even speak to all the other participants (unfortunately).&lt;/p&gt;
&lt;p&gt;The basic format is lectures all day (9am til roughly 5pm) and various academic or social activities in the evenings. I foolishly though it would be possible to get lots of work done in the free time, which was wrong on two counts: free time was limited, and the hostel had essentially no WiFi. By that I mean it was impressively bad: pings of the order 5s, packet loss above 50%. Free café WiFi is also harder to find in Tübingen than in NYC (somehow!), so by the end of the two weeks, MLSS participants could be found sitting near eduroam hotspots across the town.&lt;/p&gt;
&lt;p&gt;Luckily there are better things to do at a summer school than struggle with laggy ssh tunnels. The lectures provided good exposure various topics within machine learning, although a 3-hour course is necessarily limited in depth. Most of the lectures were recorded and will probably be &lt;a href="http://webdav.tuebingen.mpg.de/mlss2013/2015/speakers.html"&gt;here&lt;/a&gt; eventually. Those from 2013 are still available &lt;a href="http://webdav.tuebingen.mpg.de/mlss2013/2013/index.html"&gt;here&lt;/a&gt;. There are also more from other MLSS venues &lt;a href="http://videolectures.net/site/search/?q=mlss"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My favourites were Tamara Broderick's &lt;em&gt;Bayesian Nonparametrics&lt;/em&gt; and Zoubin Ghahramani's &lt;em&gt;Bayesian Inference&lt;/em&gt; (note my bias). Michael Hirsch's &lt;em&gt;Computational Imaging&lt;/em&gt; and Michael Black's &lt;em&gt;Learning Human Body Shape&lt;/em&gt; were also enjoyable, largely due to demonstrations. The former briefly covered MIT's &lt;a href="https://people.csail.mit.edu/mrub/VisualMic/"&gt;visual microphone&lt;/a&gt; which prompted a similar level of disquiet as it did on infosec twitter, although more fascination. The unearthly sounds of the reconstructions do little to ease the creep level.&lt;/p&gt;
&lt;p&gt;My favourite session overall was the practical from Frank Wood and Brooks Paige on &lt;em&gt;Probabilistic Programming&lt;/em&gt; (&lt;a href="https://bitbucket.org/probprog/mlss2015"&gt;bitbucket repo&lt;/a&gt;), possibly because I am a nascent Clojure fan, or maybe I just love sampling. I'm also quite enthusiastic about abstracting away implementation details and focusing on models, which &lt;a href="http://www.robots.ox.ac.uk/~fwood/anglican/"&gt;Anglican&lt;/a&gt; facilitates. How much use I'll make of it in my own research has yet to be determined.&lt;/p&gt;
&lt;p&gt;Something which cannot be replicated via video lectures or git repos (yet) is interaction with other participants. As I mentioned, there were a lot of us (about 100), and the poster sessions were probably the best opportunity to talk science. I'm not sure how participants were selected but I was impressed by the diversity of research represented. It turns out not &lt;em&gt;everyone&lt;/em&gt; is throwing convnets at everything (but maybe they should be?). There was also a lot more theory than I was expecting, which is what happens when you assume your biased sample (of largely-applied colleagues) is representative of the whole. Lesson learned. I didn't take any notes at the poster sessions (nor did I read all of the posters), so I'll just mention a few that stand out in my memory (and have something concrete to link to).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.mpi-sws.org/~mzafar/"&gt;Muhammad Bilal Zafar&lt;/a&gt; had a poster about &lt;a href="http://www.mpi-sws.org/~mzafar/papers/fatml_15.pdf"&gt;Fairness Constraints: A Mechanism for Fair Classification&lt;/a&gt;. Quoting from the paper,  &lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;"Fairness prevents a classifier from outputting predictions correlated with certain sensitive attributes in the data."&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I was really excited to see a poster about fairness, especially having just read &lt;a href="http://jeremykun.com/2015/07/13/what-does-it-mean-for-an-algorithm-to-be-fair/"&gt;"What Does it Mean for an Algorithm to be Fair?"&lt;/a&gt;. The danger exists for people to believe that the recommendations from a machine learning algorithm are 'fair' (for some nebulous definition of fair, likely including 'not racist' and 'not sexist'), which could be used to avoid addressing systemic social injustices. It's important for machine learning researchers/users to stress that the output of learning algorithm is a function of its training data (madness, I know), and as long as our historical data contains biases, models trained on it will have them too. That is, unless we do something about it. I'm sure there are more subtle factors at play that I'm not aware of, but I'm glad that these issues are being considered by the research community.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://people.idsia.ch/~greff/index.html"&gt;Klaus Greff&lt;/a&gt; presented a poster about an experiment-management tool he created called &lt;a href="https://github.com/IDSIA/sacred"&gt;Sacred&lt;/a&gt;. (The name is a reference to Monty Python's &lt;a href="https://www.youtube.com/watch?v=fUspLVStPbk"&gt;Every Sperm is Sacred&lt;/a&gt;). This obviously isn't research, but it seems extremely useful. It records things like config options, a snapshot of the source code(!), runtime trace(s), and saves them in a (mongoDB) database. I already have a semi-elaborate setup for running reproducible experiments (the details of which are too gory and shameful to provide), but this seems more pleasant and sane.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://www.robots.ox.ac.uk/~twgr/"&gt;Tom Rainforth&lt;/a&gt; had a poster about &lt;a href="http://arxiv.org/pdf/1507.05444v2.pdf"&gt;Canonical Correlation Forests&lt;/a&gt; which I didn't actually get to look at (I was in the same poster session), but the gist I got from a chat in the pub is that they're better than random forests (my brain has a very aggressive compression algorithm, clearly). I'll need to read the paper. I have a picture of him explaining the poster to someone on the bus after the poster session, demonstrating that science never rests.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;My friend &lt;a href="http://www.maillard.it/"&gt;Jean Maillard&lt;/a&gt; had a poster on &lt;a href="https://aclweb.org/anthology/K/K15/K15-1035.pdf"&gt;Learning Adjective Meanings with a Tensor-Based Skip-Gram Model&lt;/a&gt;. This was by far the most similar to mine (my poster was also on distributional semantics), although this paper focuses moreso on language-modelling, by representing adjectives as matrices. I'm amused that Jean and I started off doing something entirely different (at the time, Part III in Mathematics at Cambridge, mostly flipping tables over quantum algorithms) and then converged (if only temporarily, for me) on something that is (at least by MLSS standards) &lt;em&gt;somewhat&lt;/em&gt; obscure. Maybe there was something in the water at St. John's.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There were also lots of opportunities to talk non-science. On the last afternoon, a straw poll was conducted on the viability of human-level AI during our lifetime. The majority present (n ~ 10) felt it wasn't going to happen, which seems to go against popular opinion on the matter (at least judging by recent articles about the threat of such AIs). Maybe grad students are too pessimistic (optimistic?) a group, or we succumbed to our small sample size. The poll wasn't even conducted in secret.&lt;/p&gt;
&lt;p&gt;Another outcome of the MLSS is that I reaffirmed my desire to write a &lt;em&gt;Gaussian Processes for Biologists&lt;/em&gt; tutorial. &lt;em&gt;Biologist&lt;/em&gt; here really means 'anyone lacking a strong mathematical background' (hopefully in the future it will be offensive for me to use biologist as a proxy for that). I'd originally planned to do this after the GPSS last year, partially out of GP evangelism (all the people doing simple linear regression could be doing GP regression!) and partially to deepen my own understanding (one learns much through teaching), but progress stalled due to lack of interest. Interest is briefly re-ignited, so maybe I'll actually do it this time[citation needed].&lt;/p&gt;</content><category term="ml"></category><category term="class"></category><category term="life"></category><category term="poster"></category><category term="AI"></category><category term="bayesian"></category></entry><entry><title>aligning vectors (animation)</title><link href="ml/2015-04-09-aligning-vectors-animation.html" rel="alternate"></link><published>2015-04-09T13:37:00+01:00</published><updated>2015-04-09T13:37:00+01:00</updated><author><name>corcra</name></author><id>tag:None,2015-04-09:ml/2015-04-09-aligning-vectors-animation.html</id><summary type="html">&lt;p&gt;I'm working on an embedding procedure for placing &lt;em&gt;things&lt;/em&gt; into vector spaces. Things which might not normally live in a vector space (although in a sense we all live in a Lorentzian manifold). The basic idea is to take a model, present a bunch of examples of these objects relating …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I'm working on an embedding procedure for placing &lt;em&gt;things&lt;/em&gt; into vector spaces. Things which might not normally live in a vector space (although in a sense we all live in a Lorentzian manifold). The basic idea is to take a model, present a bunch of examples of these objects relating to each other (outside of any notion of a metric), and then it figures out where to put them. &lt;em&gt;(In the event of me getting my model to do anything actually useful, I will provide excessive technical detail, but that's not the objective here)&lt;/em&gt;. This evening I remembered that 2 dimensions are very easy to visualise, so I made an animation of how the objects move in the space as training progresses (number of training examples is depicted in the plot title).&lt;/p&gt;
&lt;p&gt;The example here is exceedingly trivial - five objects, two pairs of which are designed (by way of engineering the training data) to end up together and apart (colour-coded), and one loner who goes wherever. So they're not so much learning to agree as learning to jealously cling to their partner.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://corcra.github.io/assets/w5.gif" class="center"/&gt;&lt;/p&gt;
&lt;p&gt;Look at them twitch! Stochastic gradient descent in action. I'm tempted to make more of these with different learning rates and see how badly I can get it to break, but I foolishly started doing this &lt;em&gt;too late&lt;/em&gt;, so I'll save it for next time. (Also next time: evolving energy surfaces).&lt;/p&gt;</content><category term="ml"></category><category term="animation"></category><category term="visualisation"></category><category term="embedding"></category><category term="nlp"></category></entry><entry><title>updating shared variables in theano</title><link href="ml/2014-09-30-updating-shared-variables-in-theano.html" rel="alternate"></link><published>2014-09-30T00:00:00+01:00</published><updated>2014-09-30T00:00:00+01:00</updated><author><name>corcra</name></author><id>tag:None,2014-09-30:ml/2014-09-30-updating-shared-variables-in-theano.html</id><summary type="html">&lt;p&gt;Background: I am running python with &lt;a href="http://deeplearning.net/software/theano/index.html"&gt;Theano&lt;/a&gt; on a GPU, and I care about speed.&lt;/p&gt;
&lt;p&gt;Scenario: I have a largeish matrix (&lt;code&gt;C&lt;/code&gt;) which is stored as a shared variable, and I need to update a subset of the rows (&lt;code&gt;modified_rows&lt;/code&gt;) by some other matrix (&lt;code&gt;C_delta&lt;/code&gt;). What should I do?&lt;/p&gt;
&lt;p&gt;Initialising …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Background: I am running python with &lt;a href="http://deeplearning.net/software/theano/index.html"&gt;Theano&lt;/a&gt; on a GPU, and I care about speed.&lt;/p&gt;
&lt;p&gt;Scenario: I have a largeish matrix (&lt;code&gt;C&lt;/code&gt;) which is stored as a shared variable, and I need to update a subset of the rows (&lt;code&gt;modified_rows&lt;/code&gt;) by some other matrix (&lt;code&gt;C_delta&lt;/code&gt;). What should I do?&lt;/p&gt;
&lt;p&gt;Initialising, e.g.:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;    &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;  
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;theano&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;function&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;  
    &lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;theano.tensor&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;fmatrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ivector&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;set_subtensor&lt;/span&gt;  
    &lt;span class="n"&gt;C&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;70000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;  
    &lt;span class="n"&gt;modified_rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="kp"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;low&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;high&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;70000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    &lt;span class="n"&gt;C_delta&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;normal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kp"&gt;size&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;modified_rows&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  
    &lt;span class="n"&gt;C_d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;fmatrix&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;C_delta&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
    &lt;span class="n"&gt;mod_rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ivector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;modified_rows&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Slow method: manually reset the values:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;    C_temp = C.get_value()&lt;/span&gt;
&lt;span class="err"&gt;    C_temp[modified_rows, :] = C_temp[modified_rows, :] + C_delta&lt;/span&gt;
&lt;span class="err"&gt;    C.set_value(C_temp)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Speed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;    32 function calls in 0.055 seconds&lt;/span&gt;
&lt;span class="err"&gt;    ncalls  tottime  percall  cumtime  percall filename:lineno(function)&lt;/span&gt;
&lt;span class="err"&gt;    ...&lt;/span&gt;
&lt;span class="err"&gt;    1 0.000 0.000 0.026 0.026 sharedvalue.py:100(set_value)&lt;/span&gt;
&lt;span class="err"&gt;    1 0.000 0.000 0.027 0.027 sharedvalue.py:80(get_value)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is bad because it requires unpacking and repacking the value in the shared variable (via &lt;code&gt;get_value&lt;/code&gt; and &lt;code&gt;set_value&lt;/code&gt;). We only need to modify a small number of the rows (200 out of 70k) so having to update every single one seems extremely wasteful.&lt;/p&gt;
&lt;p&gt;Part of the 'nice thing' about shared variables is that they can be updated by functions which use them, so you might try:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;    update_C = function([C_d, mod_rows], [],&lt;/span&gt;
&lt;span class="err"&gt;                        updates=[(C[mod_rows, :], C[mod_rows, :] + C_d)], &lt;/span&gt;
&lt;span class="err"&gt;                        allow_input_downcast=True)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(remember, &lt;code&gt;C_d&lt;/code&gt; and &lt;code&gt;mod_rows&lt;/code&gt; are &lt;em&gt;symbolic variables&lt;/em&gt; (specifically &lt;code&gt;fmatrix&lt;/code&gt; and ivector) defined above).
The &lt;code&gt;allow_input_downcast=True&lt;/code&gt; will deal with numpy's love of dealing in double-precision floats, which Theano rejects for GPU work. This loss of precision &lt;em&gt;may&lt;/em&gt; be important to you.&lt;/p&gt;
&lt;p&gt;So then a simple call to &lt;code&gt;update_C(C_delta, modified_rows)&lt;/code&gt; will do what you want, except that what I just wrote won't work. You can't update shared variables like that. I think it's because the first element of the tuple is not &lt;em&gt;really&lt;/em&gt; the shared variable, so Theano freaks out. (Full disclosure: little idea of theano's inner workings.)&lt;/p&gt;
&lt;p&gt;Focusing solely on the &lt;code&gt;updates=[...]&lt;/code&gt; part (everything else should be OK), you need to do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;updates&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;(C, set_subtensor(C[modified_rows&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C_delta&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="err"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So the full command (if you are lazily copying and pasting this into iPython to test speed):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;    update_C = function([C_d, mod_rows], [],  &lt;/span&gt;
&lt;span class="err"&gt;                        updates=[(C, set_subtensor(C[mod_rows, :] + C_d))],  &lt;/span&gt;
&lt;span class="err"&gt;                        allow_input_downcast=True)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Things which won't work (for reasons unknown to me):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;modified_rows&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;modified_rows, :&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;C_delta&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&amp;gt;&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;C_delta&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;:, :&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As for the speed for this method: well,&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="err"&gt;    28 function calls in 0.001 seconds&lt;/span&gt;
&lt;span class="err"&gt;    ncalls tottime percall cumtime percall filename:lineno(function)&lt;/span&gt;
&lt;span class="err"&gt;    ...&lt;/span&gt;
&lt;span class="err"&gt;    1 0.001 0.001 0.001 0.001 subtensor.py:1644(perform)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I think that solves the problem.&lt;/p&gt;
&lt;p&gt;Related:&lt;br&gt;
&lt;a href="https://stackoverflow.com/questions/24229361/theano-indexing-inside-a-compiled-function-gpu"&gt;https://stackoverflow.com/questions/24229361/theano-indexing-inside-a-compiled-function-gpu&lt;/a&gt;      &lt;br&gt;
&lt;a href="https://stackoverflow.com/questions/15917849/how-can-i-assign-update-subset-of-tensor-shared-variable-in-theano"&gt;https://stackoverflow.com/questions/15917849/how-can-i-assign-update-subset-of-tensor-shared-variable-in-theano&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Possibly relevant technical information:&lt;br&gt;
&lt;em&gt;Theano version is 0.6.0.&lt;br&gt;
Numpy version is 1.8.2, using Intel's Math Kernel Library (MKL) as part of Anaconda.&lt;br&gt;
GPU is a GeForce GTX 680.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; this post first appeared on my &lt;a href="https://jackofalljacks.wordpress.com/"&gt;wordpress blog.&lt;/a&gt;&lt;/p&gt;</content><category term="ml"></category><category term="python"></category><category term="theano"></category><category term="gpu"></category><category term="optimisation"></category></entry></feed>